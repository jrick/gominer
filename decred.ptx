//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19856038
// Cuda compilation tools, release 7.5, V7.5.17
// Based on LLVM 3.4svn
//

.version 4.3
.target sm_20
.address_size 64

	// .globl	_Z21decred_gpu_hash_noncejjPjj
.const .align 16 .b8 c_h[8];
.const .align 16 .b8 c_data[128];
.const .align 16 .b8 c_xors[860];

.visible .entry _Z21decred_gpu_hash_noncejjPjj(
	.param .u32 _Z21decred_gpu_hash_noncejjPjj_param_0,
	.param .u32 _Z21decred_gpu_hash_noncejjPjj_param_1,
	.param .u64 _Z21decred_gpu_hash_noncejjPjj_param_2,
	.param .u32 _Z21decred_gpu_hash_noncejjPjj_param_3
)
.maxntid 640, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<2008>;
	.reg .b64 	%rd<9>;


	ld.param.u32 	%r10, [_Z21decred_gpu_hash_noncejjPjj_param_0];
	ld.param.u32 	%r8, [_Z21decred_gpu_hash_noncejjPjj_param_1];
	mov.u32 	%r11, %ctaid.x;
	mov.u32 	%r12, %ntid.x;
	mov.u32 	%r13, %tid.x;
	mad.lo.s32 	%r1, %r11, %r12, %r13;
	setp.ge.u32	%p1, %r1, %r10;
	@%p1 bra 	BB0_4;

	ld.const.v4.u32 	{%r14, %r15, %r16, %r17}, [c_data];
	add.s32 	%r2, %r1, %r8;
	xor.b32  	%r22, %r2, 320440878;
	add.s32 	%r23, %r15, %r22;
	ld.const.v4.u32 	{%r24, %r25, %r26, %r27}, [c_data+48];
	xor.b32  	%r32, %r25, %r23;
	mov.u32 	%r33, 801;
	mov.u32 	%r34, 0;
	prmt.b32 	%r35, %r32, %r34, %r33;
	ld.const.v4.u32 	{%r36, %r37, %r38, %r39}, [c_data+32];
	add.s32 	%r44, %r37, %r35;
	ld.const.v4.u32 	{%r45, %r46, %r47, %r48}, [c_data+16];
	xor.b32  	%r53, %r46, %r44;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r53, 25;
	shr.b32 	%rhs, %r53, 7;
	add.u32 	%r54, %lhs, %rhs;
	}
	ld.const.v4.u32 	{%r55, %r56, %r57, %r58}, [c_xors];
	add.s32 	%r60, %r23, %r55;
	add.s32 	%r61, %r14, %r54;
	xor.b32  	%r62, %r60, %r24;
	mov.u32 	%r63, 4146;
	prmt.b32 	%r64, %r62, %r34, %r63;
	xor.b32  	%r65, %r61, %r27;
	prmt.b32 	%r66, %r65, %r34, %r63;
	add.s32 	%r67, %r39, %r64;
	add.s32 	%r68, %r38, %r66;
	xor.b32  	%r69, %r67, %r47;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r69, 20;
	shr.b32 	%rhs, %r69, 12;
	add.u32 	%r70, %lhs, %rhs;
	}
	xor.b32  	%r71, %r68, %r54;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r71, 20;
	shr.b32 	%rhs, %r71, 12;
	add.u32 	%r72, %lhs, %rhs;
	}
	add.s32 	%r74, %r70, %r56;
	add.s32 	%r75, %r74, %r60;
	add.s32 	%r77, %r72, %r57;
	add.s32 	%r78, %r77, %r61;
	xor.b32  	%r79, %r75, %r64;
	prmt.b32 	%r80, %r79, %r34, %r33;
	xor.b32  	%r81, %r78, %r66;
	prmt.b32 	%r82, %r81, %r34, %r33;
	add.s32 	%r83, %r67, %r80;
	add.s32 	%r84, %r68, %r82;
	xor.b32  	%r85, %r83, %r70;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r85, 25;
	shr.b32 	%rhs, %r85, 7;
	add.u32 	%r86, %lhs, %rhs;
	}
	xor.b32  	%r87, %r84, %r72;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r87, 25;
	shr.b32 	%rhs, %r87, 7;
	add.u32 	%r88, %lhs, %rhs;
	}
	add.s32 	%r90, %r48, %r58;
	add.s32 	%r91, %r90, %r16;
	ld.const.v4.u32 	{%r92, %r93, %r94, %r95}, [c_xors+16];
	add.s32 	%r97, %r45, %r92;
	add.s32 	%r98, %r97, %r17;
	xor.b32  	%r99, %r91, %r35;
	prmt.b32 	%r100, %r99, %r34, %r63;
	xor.b32  	%r101, %r98, %r26;
	prmt.b32 	%r102, %r101, %r34, %r63;
	add.s32 	%r103, %r36, %r100;
	add.s32 	%r104, %r44, %r102;
	xor.b32  	%r105, %r103, %r48;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r105, 20;
	shr.b32 	%rhs, %r105, 12;
	add.u32 	%r106, %lhs, %rhs;
	}
	xor.b32  	%r107, %r104, %r45;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r107, 20;
	shr.b32 	%rhs, %r107, 12;
	add.u32 	%r108, %lhs, %rhs;
	}
	add.s32 	%r110, %r106, %r93;
	add.s32 	%r111, %r110, %r91;
	add.s32 	%r113, %r108, %r94;
	add.s32 	%r114, %r113, %r98;
	xor.b32  	%r115, %r111, %r100;
	prmt.b32 	%r116, %r115, %r34, %r33;
	xor.b32  	%r117, %r114, %r102;
	prmt.b32 	%r118, %r117, %r34, %r33;
	add.s32 	%r119, %r103, %r116;
	add.s32 	%r120, %r104, %r118;
	xor.b32  	%r121, %r119, %r106;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r121, 25;
	shr.b32 	%rhs, %r121, 7;
	add.u32 	%r122, %lhs, %rhs;
	}
	xor.b32  	%r123, %r120, %r108;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r123, 25;
	shr.b32 	%rhs, %r123, 7;
	add.u32 	%r124, %lhs, %rhs;
	}
	add.s32 	%r126, %r78, %r95;
	add.s32 	%r127, %r126, %r124;
	ld.const.v4.u32 	{%r128, %r129, %r130, %r131}, [c_xors+32];
	add.s32 	%r133, %r88, %r128;
	add.s32 	%r134, %r133, %r75;
	xor.b32  	%r135, %r127, %r80;
	prmt.b32 	%r136, %r135, %r34, %r63;
	xor.b32  	%r137, %r134, %r116;
	prmt.b32 	%r138, %r137, %r34, %r63;
	add.s32 	%r139, %r119, %r136;
	add.s32 	%r140, %r120, %r138;
	xor.b32  	%r141, %r139, %r124;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r141, 20;
	shr.b32 	%rhs, %r141, 12;
	add.u32 	%r142, %lhs, %rhs;
	}
	xor.b32  	%r143, %r140, %r88;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r143, 20;
	shr.b32 	%rhs, %r143, 12;
	add.u32 	%r144, %lhs, %rhs;
	}
	add.s32 	%r146, %r142, %r129;
	add.s32 	%r147, %r146, %r127;
	add.s32 	%r149, %r144, %r130;
	add.s32 	%r150, %r149, %r134;
	xor.b32  	%r151, %r147, %r136;
	prmt.b32 	%r152, %r151, %r34, %r33;
	xor.b32  	%r153, %r150, %r138;
	prmt.b32 	%r154, %r153, %r34, %r33;
	add.s32 	%r155, %r139, %r152;
	add.s32 	%r156, %r140, %r154;
	xor.b32  	%r157, %r155, %r142;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r157, 25;
	shr.b32 	%rhs, %r157, 7;
	add.u32 	%r158, %lhs, %rhs;
	}
	xor.b32  	%r159, %r156, %r144;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r159, 25;
	shr.b32 	%rhs, %r159, 7;
	add.u32 	%r160, %lhs, %rhs;
	}
	add.s32 	%r162, %r86, %r131;
	add.s32 	%r163, %r162, %r111;
	ld.const.v4.u32 	{%r164, %r165, %r166, %r167}, [c_xors+48];
	add.s32 	%r169, %r122, %r164;
	add.s32 	%r170, %r169, %r114;
	xor.b32  	%r171, %r163, %r118;
	prmt.b32 	%r172, %r171, %r34, %r63;
	xor.b32  	%r173, %r170, %r82;
	prmt.b32 	%r174, %r173, %r34, %r63;
	add.s32 	%r175, %r84, %r172;
	add.s32 	%r176, %r83, %r174;
	xor.b32  	%r177, %r175, %r86;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r177, 20;
	shr.b32 	%rhs, %r177, 12;
	add.u32 	%r178, %lhs, %rhs;
	}
	xor.b32  	%r179, %r176, %r122;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r179, 20;
	shr.b32 	%rhs, %r179, 12;
	add.u32 	%r180, %lhs, %rhs;
	}
	add.s32 	%r182, %r178, %r165;
	add.s32 	%r183, %r182, %r163;
	add.s32 	%r185, %r180, %r166;
	add.s32 	%r186, %r185, %r170;
	xor.b32  	%r187, %r183, %r172;
	prmt.b32 	%r188, %r187, %r34, %r33;
	xor.b32  	%r189, %r186, %r174;
	prmt.b32 	%r190, %r189, %r34, %r33;
	add.s32 	%r191, %r175, %r188;
	add.s32 	%r192, %r176, %r190;
	xor.b32  	%r193, %r191, %r178;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r193, 25;
	shr.b32 	%rhs, %r193, 7;
	add.u32 	%r194, %lhs, %rhs;
	}
	xor.b32  	%r195, %r192, %r180;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r195, 25;
	shr.b32 	%rhs, %r195, 7;
	add.u32 	%r196, %lhs, %rhs;
	}
	add.s32 	%r198, %r160, %r167;
	add.s32 	%r199, %r198, %r147;
	ld.const.v4.u32 	{%r200, %r201, %r202, %r203}, [c_xors+64];
	add.s32 	%r205, %r194, %r200;
	add.s32 	%r206, %r205, %r150;
	xor.b32  	%r207, %r199, %r190;
	prmt.b32 	%r208, %r207, %r34, %r63;
	xor.b32  	%r209, %r206, %r152;
	prmt.b32 	%r210, %r209, %r34, %r63;
	add.s32 	%r211, %r191, %r208;
	add.s32 	%r212, %r192, %r210;
	xor.b32  	%r213, %r211, %r160;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r213, 20;
	shr.b32 	%rhs, %r213, 12;
	add.u32 	%r214, %lhs, %rhs;
	}
	xor.b32  	%r215, %r212, %r194;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r215, 20;
	shr.b32 	%rhs, %r215, 12;
	add.u32 	%r216, %lhs, %rhs;
	}
	add.s32 	%r218, %r214, %r201;
	add.s32 	%r219, %r218, %r199;
	add.s32 	%r221, %r216, %r202;
	add.s32 	%r222, %r221, %r206;
	xor.b32  	%r223, %r219, %r208;
	prmt.b32 	%r224, %r223, %r34, %r33;
	xor.b32  	%r225, %r222, %r210;
	prmt.b32 	%r226, %r225, %r34, %r33;
	add.s32 	%r227, %r211, %r224;
	add.s32 	%r228, %r212, %r226;
	xor.b32  	%r229, %r227, %r214;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r229, 25;
	shr.b32 	%rhs, %r229, 7;
	add.u32 	%r230, %lhs, %rhs;
	}
	xor.b32  	%r231, %r228, %r216;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r231, 25;
	shr.b32 	%rhs, %r231, 7;
	add.u32 	%r232, %lhs, %rhs;
	}
	add.s32 	%r234, %r196, %r203;
	add.s32 	%r235, %r234, %r183;
	ld.const.v4.u32 	{%r236, %r237, %r238, %r239}, [c_xors+80];
	add.s32 	%r241, %r158, %r236;
	add.s32 	%r242, %r241, %r186;
	xor.b32  	%r243, %r235, %r154;
	prmt.b32 	%r244, %r243, %r34, %r63;
	xor.b32  	%r245, %r242, %r188;
	prmt.b32 	%r246, %r245, %r34, %r63;
	add.s32 	%r247, %r155, %r244;
	add.s32 	%r248, %r156, %r246;
	xor.b32  	%r249, %r247, %r196;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r249, 20;
	shr.b32 	%rhs, %r249, 12;
	add.u32 	%r250, %lhs, %rhs;
	}
	xor.b32  	%r251, %r248, %r158;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r251, 20;
	shr.b32 	%rhs, %r251, 12;
	add.u32 	%r252, %lhs, %rhs;
	}
	add.s32 	%r254, %r250, %r237;
	add.s32 	%r255, %r254, %r235;
	xor.b32  	%r257, %r238, %r2;
	add.s32 	%r258, %r257, %r252;
	add.s32 	%r259, %r258, %r242;
	xor.b32  	%r260, %r255, %r244;
	prmt.b32 	%r261, %r260, %r34, %r33;
	xor.b32  	%r262, %r259, %r246;
	prmt.b32 	%r263, %r262, %r34, %r33;
	add.s32 	%r264, %r247, %r261;
	add.s32 	%r265, %r248, %r263;
	xor.b32  	%r266, %r264, %r250;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r266, 25;
	shr.b32 	%rhs, %r266, 7;
	add.u32 	%r267, %lhs, %rhs;
	}
	xor.b32  	%r268, %r265, %r252;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r268, 25;
	shr.b32 	%rhs, %r268, 7;
	add.u32 	%r269, %lhs, %rhs;
	}
	add.s32 	%r271, %r219, %r239;
	add.s32 	%r272, %r271, %r269;
	ld.const.v4.u32 	{%r273, %r274, %r275, %r276}, [c_xors+96];
	add.s32 	%r278, %r230, %r273;
	add.s32 	%r279, %r278, %r222;
	xor.b32  	%r280, %r272, %r226;
	prmt.b32 	%r281, %r280, %r34, %r63;
	xor.b32  	%r282, %r279, %r261;
	prmt.b32 	%r283, %r282, %r34, %r63;
	add.s32 	%r284, %r264, %r281;
	add.s32 	%r285, %r265, %r283;
	xor.b32  	%r286, %r284, %r269;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r286, 20;
	shr.b32 	%rhs, %r286, 12;
	add.u32 	%r287, %lhs, %rhs;
	}
	xor.b32  	%r288, %r285, %r230;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r288, 20;
	shr.b32 	%rhs, %r288, 12;
	add.u32 	%r289, %lhs, %rhs;
	}
	add.s32 	%r291, %r287, %r274;
	add.s32 	%r292, %r291, %r272;
	add.s32 	%r294, %r289, %r275;
	add.s32 	%r295, %r294, %r279;
	xor.b32  	%r296, %r292, %r281;
	prmt.b32 	%r297, %r296, %r34, %r33;
	xor.b32  	%r298, %r295, %r283;
	prmt.b32 	%r299, %r298, %r34, %r33;
	add.s32 	%r300, %r284, %r297;
	add.s32 	%r301, %r285, %r299;
	xor.b32  	%r302, %r300, %r287;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r302, 25;
	shr.b32 	%rhs, %r302, 7;
	add.u32 	%r303, %lhs, %rhs;
	}
	xor.b32  	%r304, %r301, %r289;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r304, 25;
	shr.b32 	%rhs, %r304, 7;
	add.u32 	%r305, %lhs, %rhs;
	}
	add.s32 	%r307, %r232, %r276;
	add.s32 	%r308, %r307, %r255;
	ld.const.v4.u32 	{%r309, %r310, %r311, %r312}, [c_xors+112];
	add.s32 	%r314, %r267, %r309;
	add.s32 	%r315, %r314, %r259;
	xor.b32  	%r316, %r308, %r263;
	prmt.b32 	%r317, %r316, %r34, %r63;
	xor.b32  	%r318, %r315, %r224;
	prmt.b32 	%r319, %r318, %r34, %r63;
	add.s32 	%r320, %r227, %r317;
	add.s32 	%r321, %r228, %r319;
	xor.b32  	%r322, %r320, %r232;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r322, 20;
	shr.b32 	%rhs, %r322, 12;
	add.u32 	%r323, %lhs, %rhs;
	}
	xor.b32  	%r324, %r321, %r267;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r324, 20;
	shr.b32 	%rhs, %r324, 12;
	add.u32 	%r325, %lhs, %rhs;
	}
	add.s32 	%r327, %r323, %r310;
	add.s32 	%r328, %r327, %r308;
	add.s32 	%r330, %r325, %r311;
	add.s32 	%r331, %r330, %r315;
	xor.b32  	%r332, %r328, %r317;
	prmt.b32 	%r333, %r332, %r34, %r33;
	xor.b32  	%r334, %r331, %r319;
	prmt.b32 	%r335, %r334, %r34, %r33;
	add.s32 	%r336, %r320, %r333;
	add.s32 	%r337, %r321, %r335;
	xor.b32  	%r338, %r336, %r323;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r338, 25;
	shr.b32 	%rhs, %r338, 7;
	add.u32 	%r339, %lhs, %rhs;
	}
	xor.b32  	%r340, %r337, %r325;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r340, 25;
	shr.b32 	%rhs, %r340, 7;
	add.u32 	%r341, %lhs, %rhs;
	}
	add.s32 	%r343, %r305, %r312;
	add.s32 	%r344, %r343, %r292;
	ld.const.v4.u32 	{%r345, %r346, %r347, %r348}, [c_xors+128];
	xor.b32  	%r350, %r345, %r2;
	add.s32 	%r351, %r350, %r339;
	add.s32 	%r352, %r351, %r295;
	xor.b32  	%r353, %r344, %r335;
	prmt.b32 	%r354, %r353, %r34, %r63;
	xor.b32  	%r355, %r352, %r297;
	prmt.b32 	%r356, %r355, %r34, %r63;
	add.s32 	%r357, %r336, %r354;
	add.s32 	%r358, %r337, %r356;
	xor.b32  	%r359, %r357, %r305;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r359, 20;
	shr.b32 	%rhs, %r359, 12;
	add.u32 	%r360, %lhs, %rhs;
	}
	xor.b32  	%r361, %r358, %r339;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r361, 20;
	shr.b32 	%rhs, %r361, 12;
	add.u32 	%r362, %lhs, %rhs;
	}
	add.s32 	%r364, %r360, %r346;
	add.s32 	%r365, %r364, %r344;
	add.s32 	%r367, %r362, %r347;
	add.s32 	%r368, %r367, %r352;
	xor.b32  	%r369, %r365, %r354;
	prmt.b32 	%r370, %r369, %r34, %r33;
	xor.b32  	%r371, %r368, %r356;
	prmt.b32 	%r372, %r371, %r34, %r33;
	add.s32 	%r373, %r357, %r370;
	add.s32 	%r374, %r358, %r372;
	xor.b32  	%r375, %r373, %r360;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r375, 25;
	shr.b32 	%rhs, %r375, 7;
	add.u32 	%r376, %lhs, %rhs;
	}
	xor.b32  	%r377, %r374, %r362;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r377, 25;
	shr.b32 	%rhs, %r377, 7;
	add.u32 	%r378, %lhs, %rhs;
	}
	add.s32 	%r380, %r341, %r348;
	add.s32 	%r381, %r380, %r328;
	ld.const.v4.u32 	{%r382, %r383, %r384, %r385}, [c_xors+144];
	add.s32 	%r387, %r303, %r382;
	add.s32 	%r388, %r387, %r331;
	xor.b32  	%r389, %r381, %r299;
	prmt.b32 	%r390, %r389, %r34, %r63;
	xor.b32  	%r391, %r388, %r333;
	prmt.b32 	%r392, %r391, %r34, %r63;
	add.s32 	%r393, %r300, %r390;
	add.s32 	%r394, %r301, %r392;
	xor.b32  	%r395, %r393, %r341;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r395, 20;
	shr.b32 	%rhs, %r395, 12;
	add.u32 	%r396, %lhs, %rhs;
	}
	xor.b32  	%r397, %r394, %r303;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r397, 20;
	shr.b32 	%rhs, %r397, 12;
	add.u32 	%r398, %lhs, %rhs;
	}
	add.s32 	%r400, %r396, %r383;
	add.s32 	%r401, %r400, %r381;
	add.s32 	%r403, %r398, %r384;
	add.s32 	%r404, %r403, %r388;
	xor.b32  	%r405, %r401, %r390;
	prmt.b32 	%r406, %r405, %r34, %r33;
	xor.b32  	%r407, %r404, %r392;
	prmt.b32 	%r408, %r407, %r34, %r33;
	add.s32 	%r409, %r393, %r406;
	add.s32 	%r410, %r394, %r408;
	xor.b32  	%r411, %r409, %r396;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r411, 25;
	shr.b32 	%rhs, %r411, 7;
	add.u32 	%r412, %lhs, %rhs;
	}
	xor.b32  	%r413, %r410, %r398;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r413, 25;
	shr.b32 	%rhs, %r413, 7;
	add.u32 	%r414, %lhs, %rhs;
	}
	add.s32 	%r416, %r365, %r385;
	add.s32 	%r417, %r416, %r414;
	ld.const.v4.u32 	{%r418, %r419, %r420, %r421}, [c_xors+160];
	xor.b32  	%r423, %r418, %r2;
	add.s32 	%r424, %r423, %r376;
	add.s32 	%r425, %r424, %r368;
	xor.b32  	%r426, %r417, %r372;
	prmt.b32 	%r427, %r426, %r34, %r63;
	xor.b32  	%r428, %r425, %r406;
	prmt.b32 	%r429, %r428, %r34, %r63;
	add.s32 	%r430, %r409, %r427;
	add.s32 	%r431, %r410, %r429;
	xor.b32  	%r432, %r430, %r414;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r432, 20;
	shr.b32 	%rhs, %r432, 12;
	add.u32 	%r433, %lhs, %rhs;
	}
	xor.b32  	%r434, %r431, %r376;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r434, 20;
	shr.b32 	%rhs, %r434, 12;
	add.u32 	%r435, %lhs, %rhs;
	}
	add.s32 	%r437, %r433, %r419;
	add.s32 	%r438, %r437, %r417;
	add.s32 	%r440, %r435, %r420;
	add.s32 	%r441, %r440, %r425;
	xor.b32  	%r442, %r438, %r427;
	prmt.b32 	%r443, %r442, %r34, %r33;
	xor.b32  	%r444, %r441, %r429;
	prmt.b32 	%r445, %r444, %r34, %r33;
	add.s32 	%r446, %r430, %r443;
	add.s32 	%r447, %r431, %r445;
	xor.b32  	%r448, %r446, %r433;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r448, 25;
	shr.b32 	%rhs, %r448, 7;
	add.u32 	%r449, %lhs, %rhs;
	}
	xor.b32  	%r450, %r447, %r435;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r450, 25;
	shr.b32 	%rhs, %r450, 7;
	add.u32 	%r451, %lhs, %rhs;
	}
	add.s32 	%r453, %r378, %r421;
	add.s32 	%r454, %r453, %r401;
	ld.const.v4.u32 	{%r455, %r456, %r457, %r458}, [c_xors+176];
	add.s32 	%r460, %r412, %r455;
	add.s32 	%r461, %r460, %r404;
	xor.b32  	%r462, %r454, %r408;
	prmt.b32 	%r463, %r462, %r34, %r63;
	xor.b32  	%r464, %r461, %r370;
	prmt.b32 	%r465, %r464, %r34, %r63;
	add.s32 	%r466, %r373, %r463;
	add.s32 	%r467, %r374, %r465;
	xor.b32  	%r468, %r466, %r378;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r468, 20;
	shr.b32 	%rhs, %r468, 12;
	add.u32 	%r469, %lhs, %rhs;
	}
	xor.b32  	%r470, %r467, %r412;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r470, 20;
	shr.b32 	%rhs, %r470, 12;
	add.u32 	%r471, %lhs, %rhs;
	}
	add.s32 	%r473, %r469, %r456;
	add.s32 	%r474, %r473, %r454;
	add.s32 	%r476, %r471, %r457;
	add.s32 	%r477, %r476, %r461;
	xor.b32  	%r478, %r474, %r463;
	prmt.b32 	%r479, %r478, %r34, %r33;
	xor.b32  	%r480, %r477, %r465;
	prmt.b32 	%r481, %r480, %r34, %r33;
	add.s32 	%r482, %r466, %r479;
	add.s32 	%r483, %r467, %r481;
	xor.b32  	%r484, %r482, %r469;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r484, 25;
	shr.b32 	%rhs, %r484, 7;
	add.u32 	%r485, %lhs, %rhs;
	}
	xor.b32  	%r486, %r483, %r471;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r486, 25;
	shr.b32 	%rhs, %r486, 7;
	add.u32 	%r487, %lhs, %rhs;
	}
	add.s32 	%r489, %r451, %r458;
	add.s32 	%r490, %r489, %r438;
	ld.const.v4.u32 	{%r491, %r492, %r493, %r494}, [c_xors+192];
	add.s32 	%r496, %r485, %r491;
	add.s32 	%r497, %r496, %r441;
	xor.b32  	%r498, %r490, %r481;
	prmt.b32 	%r499, %r498, %r34, %r63;
	xor.b32  	%r500, %r497, %r443;
	prmt.b32 	%r501, %r500, %r34, %r63;
	add.s32 	%r502, %r482, %r499;
	add.s32 	%r503, %r483, %r501;
	xor.b32  	%r504, %r502, %r451;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r504, 20;
	shr.b32 	%rhs, %r504, 12;
	add.u32 	%r505, %lhs, %rhs;
	}
	xor.b32  	%r506, %r503, %r485;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r506, 20;
	shr.b32 	%rhs, %r506, 12;
	add.u32 	%r507, %lhs, %rhs;
	}
	add.s32 	%r509, %r505, %r492;
	add.s32 	%r510, %r509, %r490;
	add.s32 	%r512, %r507, %r493;
	add.s32 	%r513, %r512, %r497;
	xor.b32  	%r514, %r510, %r499;
	prmt.b32 	%r515, %r514, %r34, %r33;
	xor.b32  	%r516, %r513, %r501;
	prmt.b32 	%r517, %r516, %r34, %r33;
	add.s32 	%r518, %r502, %r515;
	add.s32 	%r519, %r503, %r517;
	xor.b32  	%r520, %r518, %r505;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r520, 25;
	shr.b32 	%rhs, %r520, 7;
	add.u32 	%r521, %lhs, %rhs;
	}
	xor.b32  	%r522, %r519, %r507;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r522, 25;
	shr.b32 	%rhs, %r522, 7;
	add.u32 	%r523, %lhs, %rhs;
	}
	add.s32 	%r525, %r487, %r494;
	add.s32 	%r526, %r525, %r474;
	ld.const.v4.u32 	{%r527, %r528, %r529, %r530}, [c_xors+208];
	add.s32 	%r532, %r449, %r527;
	add.s32 	%r533, %r532, %r477;
	xor.b32  	%r534, %r526, %r445;
	prmt.b32 	%r535, %r534, %r34, %r63;
	xor.b32  	%r536, %r533, %r479;
	prmt.b32 	%r537, %r536, %r34, %r63;
	add.s32 	%r538, %r446, %r535;
	add.s32 	%r539, %r447, %r537;
	xor.b32  	%r540, %r538, %r487;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r540, 20;
	shr.b32 	%rhs, %r540, 12;
	add.u32 	%r541, %lhs, %rhs;
	}
	xor.b32  	%r542, %r539, %r449;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r542, 20;
	shr.b32 	%rhs, %r542, 12;
	add.u32 	%r543, %lhs, %rhs;
	}
	add.s32 	%r545, %r541, %r528;
	add.s32 	%r546, %r545, %r526;
	add.s32 	%r548, %r543, %r529;
	add.s32 	%r549, %r548, %r533;
	xor.b32  	%r550, %r546, %r535;
	prmt.b32 	%r551, %r550, %r34, %r33;
	xor.b32  	%r552, %r549, %r537;
	prmt.b32 	%r553, %r552, %r34, %r33;
	add.s32 	%r554, %r538, %r551;
	add.s32 	%r555, %r539, %r553;
	xor.b32  	%r556, %r554, %r541;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r556, 25;
	shr.b32 	%rhs, %r556, 7;
	add.u32 	%r557, %lhs, %rhs;
	}
	xor.b32  	%r558, %r555, %r543;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r558, 25;
	shr.b32 	%rhs, %r558, 7;
	add.u32 	%r559, %lhs, %rhs;
	}
	add.s32 	%r561, %r510, %r530;
	add.s32 	%r562, %r561, %r559;
	ld.const.v4.u32 	{%r563, %r564, %r565, %r566}, [c_xors+224];
	add.s32 	%r568, %r521, %r563;
	add.s32 	%r569, %r568, %r513;
	xor.b32  	%r570, %r562, %r517;
	prmt.b32 	%r571, %r570, %r34, %r63;
	xor.b32  	%r572, %r569, %r551;
	prmt.b32 	%r573, %r572, %r34, %r63;
	add.s32 	%r574, %r554, %r571;
	add.s32 	%r575, %r555, %r573;
	xor.b32  	%r576, %r574, %r559;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r576, 20;
	shr.b32 	%rhs, %r576, 12;
	add.u32 	%r577, %lhs, %rhs;
	}
	xor.b32  	%r578, %r575, %r521;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r578, 20;
	shr.b32 	%rhs, %r578, 12;
	add.u32 	%r579, %lhs, %rhs;
	}
	add.s32 	%r581, %r577, %r564;
	add.s32 	%r582, %r581, %r562;
	add.s32 	%r584, %r579, %r565;
	add.s32 	%r585, %r584, %r569;
	xor.b32  	%r586, %r582, %r571;
	prmt.b32 	%r587, %r586, %r34, %r33;
	xor.b32  	%r588, %r585, %r573;
	prmt.b32 	%r589, %r588, %r34, %r33;
	add.s32 	%r590, %r574, %r587;
	add.s32 	%r591, %r575, %r589;
	xor.b32  	%r592, %r590, %r577;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r592, 25;
	shr.b32 	%rhs, %r592, 7;
	add.u32 	%r593, %lhs, %rhs;
	}
	xor.b32  	%r594, %r591, %r579;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r594, 25;
	shr.b32 	%rhs, %r594, 7;
	add.u32 	%r595, %lhs, %rhs;
	}
	add.s32 	%r597, %r523, %r566;
	add.s32 	%r598, %r597, %r546;
	ld.const.v4.u32 	{%r599, %r600, %r601, %r602}, [c_xors+240];
	add.s32 	%r604, %r557, %r599;
	add.s32 	%r605, %r604, %r549;
	xor.b32  	%r606, %r598, %r553;
	prmt.b32 	%r607, %r606, %r34, %r63;
	xor.b32  	%r608, %r605, %r515;
	prmt.b32 	%r609, %r608, %r34, %r63;
	add.s32 	%r610, %r518, %r607;
	add.s32 	%r611, %r519, %r609;
	xor.b32  	%r612, %r610, %r523;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r612, 20;
	shr.b32 	%rhs, %r612, 12;
	add.u32 	%r613, %lhs, %rhs;
	}
	xor.b32  	%r614, %r611, %r557;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r614, 20;
	shr.b32 	%rhs, %r614, 12;
	add.u32 	%r615, %lhs, %rhs;
	}
	add.s32 	%r617, %r613, %r600;
	add.s32 	%r618, %r617, %r598;
	add.s32 	%r620, %r615, %r601;
	add.s32 	%r621, %r620, %r605;
	xor.b32  	%r622, %r618, %r607;
	prmt.b32 	%r623, %r622, %r34, %r33;
	xor.b32  	%r624, %r621, %r609;
	prmt.b32 	%r625, %r624, %r34, %r33;
	add.s32 	%r626, %r610, %r623;
	add.s32 	%r627, %r611, %r625;
	xor.b32  	%r628, %r626, %r613;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r628, 25;
	shr.b32 	%rhs, %r628, 7;
	add.u32 	%r629, %lhs, %rhs;
	}
	xor.b32  	%r630, %r627, %r615;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r630, 25;
	shr.b32 	%rhs, %r630, 7;
	add.u32 	%r631, %lhs, %rhs;
	}
	add.s32 	%r633, %r595, %r602;
	add.s32 	%r634, %r633, %r582;
	ld.const.v4.u32 	{%r635, %r636, %r637, %r638}, [c_xors+256];
	add.s32 	%r640, %r629, %r635;
	add.s32 	%r641, %r640, %r585;
	xor.b32  	%r642, %r634, %r625;
	prmt.b32 	%r643, %r642, %r34, %r63;
	xor.b32  	%r644, %r641, %r587;
	prmt.b32 	%r645, %r644, %r34, %r63;
	add.s32 	%r646, %r626, %r643;
	add.s32 	%r647, %r627, %r645;
	xor.b32  	%r648, %r646, %r595;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r648, 20;
	shr.b32 	%rhs, %r648, 12;
	add.u32 	%r649, %lhs, %rhs;
	}
	xor.b32  	%r650, %r647, %r629;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r650, 20;
	shr.b32 	%rhs, %r650, 12;
	add.u32 	%r651, %lhs, %rhs;
	}
	add.s32 	%r653, %r649, %r636;
	add.s32 	%r654, %r653, %r634;
	add.s32 	%r656, %r651, %r637;
	add.s32 	%r657, %r656, %r641;
	xor.b32  	%r658, %r654, %r643;
	prmt.b32 	%r659, %r658, %r34, %r33;
	xor.b32  	%r660, %r657, %r645;
	prmt.b32 	%r661, %r660, %r34, %r33;
	add.s32 	%r662, %r646, %r659;
	add.s32 	%r663, %r647, %r661;
	xor.b32  	%r664, %r662, %r649;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r664, 25;
	shr.b32 	%rhs, %r664, 7;
	add.u32 	%r665, %lhs, %rhs;
	}
	xor.b32  	%r666, %r663, %r651;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r666, 25;
	shr.b32 	%rhs, %r666, 7;
	add.u32 	%r667, %lhs, %rhs;
	}
	add.s32 	%r669, %r631, %r638;
	add.s32 	%r670, %r669, %r618;
	ld.const.v4.u32 	{%r671, %r672, %r673, %r674}, [c_xors+272];
	xor.b32  	%r676, %r671, %r2;
	add.s32 	%r677, %r676, %r593;
	add.s32 	%r678, %r677, %r621;
	xor.b32  	%r679, %r670, %r589;
	prmt.b32 	%r680, %r679, %r34, %r63;
	xor.b32  	%r681, %r678, %r623;
	prmt.b32 	%r682, %r681, %r34, %r63;
	add.s32 	%r683, %r590, %r680;
	add.s32 	%r684, %r591, %r682;
	xor.b32  	%r685, %r683, %r631;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r685, 20;
	shr.b32 	%rhs, %r685, 12;
	add.u32 	%r686, %lhs, %rhs;
	}
	xor.b32  	%r687, %r684, %r593;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r687, 20;
	shr.b32 	%rhs, %r687, 12;
	add.u32 	%r688, %lhs, %rhs;
	}
	add.s32 	%r690, %r686, %r672;
	add.s32 	%r691, %r690, %r670;
	add.s32 	%r693, %r688, %r673;
	add.s32 	%r694, %r693, %r678;
	xor.b32  	%r695, %r691, %r680;
	prmt.b32 	%r696, %r695, %r34, %r33;
	xor.b32  	%r697, %r694, %r682;
	prmt.b32 	%r698, %r697, %r34, %r33;
	add.s32 	%r699, %r683, %r696;
	add.s32 	%r700, %r684, %r698;
	xor.b32  	%r701, %r699, %r686;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r701, 25;
	shr.b32 	%rhs, %r701, 7;
	add.u32 	%r702, %lhs, %rhs;
	}
	xor.b32  	%r703, %r700, %r688;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r703, 25;
	shr.b32 	%rhs, %r703, 7;
	add.u32 	%r704, %lhs, %rhs;
	}
	add.s32 	%r706, %r654, %r674;
	add.s32 	%r707, %r706, %r704;
	ld.const.v4.u32 	{%r708, %r709, %r710, %r711}, [c_xors+288];
	add.s32 	%r713, %r665, %r708;
	add.s32 	%r714, %r713, %r657;
	xor.b32  	%r715, %r707, %r661;
	prmt.b32 	%r716, %r715, %r34, %r63;
	xor.b32  	%r717, %r714, %r696;
	prmt.b32 	%r718, %r717, %r34, %r63;
	add.s32 	%r719, %r699, %r716;
	add.s32 	%r720, %r700, %r718;
	xor.b32  	%r721, %r719, %r704;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r721, 20;
	shr.b32 	%rhs, %r721, 12;
	add.u32 	%r722, %lhs, %rhs;
	}
	xor.b32  	%r723, %r720, %r665;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r723, 20;
	shr.b32 	%rhs, %r723, 12;
	add.u32 	%r724, %lhs, %rhs;
	}
	add.s32 	%r726, %r722, %r709;
	add.s32 	%r727, %r726, %r707;
	add.s32 	%r729, %r724, %r710;
	add.s32 	%r730, %r729, %r714;
	xor.b32  	%r731, %r727, %r716;
	prmt.b32 	%r732, %r731, %r34, %r33;
	xor.b32  	%r733, %r730, %r718;
	prmt.b32 	%r734, %r733, %r34, %r33;
	add.s32 	%r735, %r719, %r732;
	add.s32 	%r736, %r720, %r734;
	xor.b32  	%r737, %r735, %r722;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r737, 25;
	shr.b32 	%rhs, %r737, 7;
	add.u32 	%r738, %lhs, %rhs;
	}
	xor.b32  	%r739, %r736, %r724;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r739, 25;
	shr.b32 	%rhs, %r739, 7;
	add.u32 	%r740, %lhs, %rhs;
	}
	add.s32 	%r742, %r667, %r711;
	add.s32 	%r743, %r742, %r691;
	ld.const.v4.u32 	{%r744, %r745, %r746, %r747}, [c_xors+304];
	add.s32 	%r749, %r702, %r744;
	add.s32 	%r750, %r749, %r694;
	xor.b32  	%r751, %r743, %r698;
	prmt.b32 	%r752, %r751, %r34, %r63;
	xor.b32  	%r753, %r750, %r659;
	prmt.b32 	%r754, %r753, %r34, %r63;
	add.s32 	%r755, %r662, %r752;
	add.s32 	%r756, %r663, %r754;
	xor.b32  	%r757, %r755, %r667;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r757, 20;
	shr.b32 	%rhs, %r757, 12;
	add.u32 	%r758, %lhs, %rhs;
	}
	xor.b32  	%r759, %r756, %r702;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r759, 20;
	shr.b32 	%rhs, %r759, 12;
	add.u32 	%r760, %lhs, %rhs;
	}
	add.s32 	%r762, %r758, %r745;
	add.s32 	%r763, %r762, %r743;
	xor.b32  	%r765, %r746, %r2;
	add.s32 	%r766, %r765, %r760;
	add.s32 	%r767, %r766, %r750;
	xor.b32  	%r768, %r763, %r752;
	prmt.b32 	%r769, %r768, %r34, %r33;
	xor.b32  	%r770, %r767, %r754;
	prmt.b32 	%r771, %r770, %r34, %r33;
	add.s32 	%r772, %r755, %r769;
	add.s32 	%r773, %r756, %r771;
	xor.b32  	%r774, %r772, %r758;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r774, 25;
	shr.b32 	%rhs, %r774, 7;
	add.u32 	%r775, %lhs, %rhs;
	}
	xor.b32  	%r776, %r773, %r760;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r776, 25;
	shr.b32 	%rhs, %r776, 7;
	add.u32 	%r777, %lhs, %rhs;
	}
	add.s32 	%r779, %r740, %r747;
	add.s32 	%r780, %r779, %r727;
	ld.const.v4.u32 	{%r781, %r782, %r783, %r784}, [c_xors+320];
	add.s32 	%r786, %r775, %r781;
	add.s32 	%r787, %r786, %r730;
	xor.b32  	%r788, %r780, %r771;
	prmt.b32 	%r789, %r788, %r34, %r63;
	xor.b32  	%r790, %r787, %r732;
	prmt.b32 	%r791, %r790, %r34, %r63;
	add.s32 	%r792, %r772, %r789;
	add.s32 	%r793, %r773, %r791;
	xor.b32  	%r794, %r792, %r740;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r794, 20;
	shr.b32 	%rhs, %r794, 12;
	add.u32 	%r795, %lhs, %rhs;
	}
	xor.b32  	%r796, %r793, %r775;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r796, 20;
	shr.b32 	%rhs, %r796, 12;
	add.u32 	%r797, %lhs, %rhs;
	}
	add.s32 	%r799, %r795, %r782;
	add.s32 	%r800, %r799, %r780;
	add.s32 	%r802, %r797, %r783;
	add.s32 	%r803, %r802, %r787;
	xor.b32  	%r804, %r800, %r789;
	prmt.b32 	%r805, %r804, %r34, %r33;
	xor.b32  	%r806, %r803, %r791;
	prmt.b32 	%r807, %r806, %r34, %r33;
	add.s32 	%r808, %r792, %r805;
	add.s32 	%r809, %r793, %r807;
	xor.b32  	%r810, %r808, %r795;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r810, 25;
	shr.b32 	%rhs, %r810, 7;
	add.u32 	%r811, %lhs, %rhs;
	}
	xor.b32  	%r812, %r809, %r797;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r812, 25;
	shr.b32 	%rhs, %r812, 7;
	add.u32 	%r813, %lhs, %rhs;
	}
	add.s32 	%r815, %r777, %r784;
	add.s32 	%r816, %r815, %r763;
	ld.const.v4.u32 	{%r817, %r818, %r819, %r820}, [c_xors+336];
	add.s32 	%r822, %r738, %r817;
	add.s32 	%r823, %r822, %r767;
	xor.b32  	%r824, %r816, %r734;
	prmt.b32 	%r825, %r824, %r34, %r63;
	xor.b32  	%r826, %r823, %r769;
	prmt.b32 	%r827, %r826, %r34, %r63;
	add.s32 	%r828, %r735, %r825;
	add.s32 	%r829, %r736, %r827;
	xor.b32  	%r830, %r828, %r777;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r830, 20;
	shr.b32 	%rhs, %r830, 12;
	add.u32 	%r831, %lhs, %rhs;
	}
	xor.b32  	%r832, %r829, %r738;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r832, 20;
	shr.b32 	%rhs, %r832, 12;
	add.u32 	%r833, %lhs, %rhs;
	}
	add.s32 	%r835, %r831, %r818;
	add.s32 	%r836, %r835, %r816;
	add.s32 	%r838, %r833, %r819;
	add.s32 	%r839, %r838, %r823;
	xor.b32  	%r840, %r836, %r825;
	prmt.b32 	%r841, %r840, %r34, %r33;
	xor.b32  	%r842, %r839, %r827;
	prmt.b32 	%r843, %r842, %r34, %r33;
	add.s32 	%r844, %r828, %r841;
	add.s32 	%r845, %r829, %r843;
	xor.b32  	%r846, %r844, %r831;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r846, 25;
	shr.b32 	%rhs, %r846, 7;
	add.u32 	%r847, %lhs, %rhs;
	}
	xor.b32  	%r848, %r845, %r833;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r848, 25;
	shr.b32 	%rhs, %r848, 7;
	add.u32 	%r849, %lhs, %rhs;
	}
	add.s32 	%r851, %r800, %r820;
	add.s32 	%r852, %r851, %r849;
	ld.const.v4.u32 	{%r853, %r854, %r855, %r856}, [c_xors+352];
	add.s32 	%r858, %r811, %r853;
	add.s32 	%r859, %r858, %r803;
	xor.b32  	%r860, %r852, %r807;
	prmt.b32 	%r861, %r860, %r34, %r63;
	xor.b32  	%r862, %r859, %r841;
	prmt.b32 	%r863, %r862, %r34, %r63;
	add.s32 	%r864, %r844, %r861;
	add.s32 	%r865, %r845, %r863;
	xor.b32  	%r866, %r864, %r849;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r866, 20;
	shr.b32 	%rhs, %r866, 12;
	add.u32 	%r867, %lhs, %rhs;
	}
	xor.b32  	%r868, %r865, %r811;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r868, 20;
	shr.b32 	%rhs, %r868, 12;
	add.u32 	%r869, %lhs, %rhs;
	}
	add.s32 	%r871, %r867, %r854;
	add.s32 	%r872, %r871, %r852;
	add.s32 	%r874, %r869, %r855;
	add.s32 	%r875, %r874, %r859;
	xor.b32  	%r876, %r872, %r861;
	prmt.b32 	%r877, %r876, %r34, %r33;
	xor.b32  	%r878, %r875, %r863;
	prmt.b32 	%r879, %r878, %r34, %r33;
	add.s32 	%r880, %r864, %r877;
	add.s32 	%r881, %r865, %r879;
	xor.b32  	%r882, %r880, %r867;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r882, 25;
	shr.b32 	%rhs, %r882, 7;
	add.u32 	%r883, %lhs, %rhs;
	}
	xor.b32  	%r884, %r881, %r869;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r884, 25;
	shr.b32 	%rhs, %r884, 7;
	add.u32 	%r885, %lhs, %rhs;
	}
	add.s32 	%r887, %r813, %r856;
	add.s32 	%r888, %r887, %r836;
	ld.const.v4.u32 	{%r889, %r890, %r891, %r892}, [c_xors+368];
	add.s32 	%r894, %r847, %r889;
	add.s32 	%r895, %r894, %r839;
	xor.b32  	%r896, %r888, %r843;
	prmt.b32 	%r897, %r896, %r34, %r63;
	xor.b32  	%r898, %r895, %r805;
	prmt.b32 	%r899, %r898, %r34, %r63;
	add.s32 	%r900, %r808, %r897;
	add.s32 	%r901, %r809, %r899;
	xor.b32  	%r902, %r900, %r813;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r902, 20;
	shr.b32 	%rhs, %r902, 12;
	add.u32 	%r903, %lhs, %rhs;
	}
	xor.b32  	%r904, %r901, %r847;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r904, 20;
	shr.b32 	%rhs, %r904, 12;
	add.u32 	%r905, %lhs, %rhs;
	}
	add.s32 	%r907, %r903, %r890;
	add.s32 	%r908, %r907, %r888;
	add.s32 	%r910, %r905, %r891;
	add.s32 	%r911, %r910, %r895;
	xor.b32  	%r912, %r908, %r897;
	prmt.b32 	%r913, %r912, %r34, %r33;
	xor.b32  	%r914, %r911, %r899;
	prmt.b32 	%r915, %r914, %r34, %r33;
	add.s32 	%r916, %r900, %r913;
	add.s32 	%r917, %r901, %r915;
	xor.b32  	%r918, %r916, %r903;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r918, 25;
	shr.b32 	%rhs, %r918, 7;
	add.u32 	%r919, %lhs, %rhs;
	}
	xor.b32  	%r920, %r917, %r905;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r920, 25;
	shr.b32 	%rhs, %r920, 7;
	add.u32 	%r921, %lhs, %rhs;
	}
	add.s32 	%r923, %r885, %r892;
	add.s32 	%r924, %r923, %r872;
	ld.const.v4.u32 	{%r925, %r926, %r927, %r928}, [c_xors+384];
	add.s32 	%r930, %r919, %r925;
	add.s32 	%r931, %r930, %r875;
	xor.b32  	%r932, %r924, %r915;
	prmt.b32 	%r933, %r932, %r34, %r63;
	xor.b32  	%r934, %r931, %r877;
	prmt.b32 	%r935, %r934, %r34, %r63;
	add.s32 	%r936, %r916, %r933;
	add.s32 	%r937, %r917, %r935;
	xor.b32  	%r938, %r936, %r885;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r938, 20;
	shr.b32 	%rhs, %r938, 12;
	add.u32 	%r939, %lhs, %rhs;
	}
	xor.b32  	%r940, %r937, %r919;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r940, 20;
	shr.b32 	%rhs, %r940, 12;
	add.u32 	%r941, %lhs, %rhs;
	}
	add.s32 	%r943, %r939, %r926;
	add.s32 	%r944, %r943, %r924;
	xor.b32  	%r946, %r927, %r2;
	add.s32 	%r947, %r946, %r941;
	add.s32 	%r948, %r947, %r931;
	xor.b32  	%r949, %r944, %r933;
	prmt.b32 	%r950, %r949, %r34, %r33;
	xor.b32  	%r951, %r948, %r935;
	prmt.b32 	%r952, %r951, %r34, %r33;
	add.s32 	%r953, %r936, %r950;
	add.s32 	%r954, %r937, %r952;
	xor.b32  	%r955, %r953, %r939;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r955, 25;
	shr.b32 	%rhs, %r955, 7;
	add.u32 	%r956, %lhs, %rhs;
	}
	xor.b32  	%r957, %r954, %r941;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r957, 25;
	shr.b32 	%rhs, %r957, 7;
	add.u32 	%r958, %lhs, %rhs;
	}
	add.s32 	%r960, %r921, %r928;
	add.s32 	%r961, %r960, %r908;
	ld.const.v4.u32 	{%r962, %r963, %r964, %r965}, [c_xors+400];
	add.s32 	%r967, %r883, %r962;
	add.s32 	%r968, %r967, %r911;
	xor.b32  	%r969, %r961, %r879;
	prmt.b32 	%r970, %r969, %r34, %r63;
	xor.b32  	%r971, %r968, %r913;
	prmt.b32 	%r972, %r971, %r34, %r63;
	add.s32 	%r973, %r880, %r970;
	add.s32 	%r974, %r881, %r972;
	xor.b32  	%r975, %r973, %r921;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r975, 20;
	shr.b32 	%rhs, %r975, 12;
	add.u32 	%r976, %lhs, %rhs;
	}
	xor.b32  	%r977, %r974, %r883;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r977, 20;
	shr.b32 	%rhs, %r977, 12;
	add.u32 	%r978, %lhs, %rhs;
	}
	add.s32 	%r980, %r976, %r963;
	add.s32 	%r981, %r980, %r961;
	add.s32 	%r983, %r978, %r964;
	add.s32 	%r984, %r983, %r968;
	xor.b32  	%r985, %r981, %r970;
	prmt.b32 	%r986, %r985, %r34, %r33;
	xor.b32  	%r987, %r984, %r972;
	prmt.b32 	%r988, %r987, %r34, %r33;
	add.s32 	%r989, %r973, %r986;
	add.s32 	%r990, %r974, %r988;
	xor.b32  	%r991, %r989, %r976;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r991, 25;
	shr.b32 	%rhs, %r991, 7;
	add.u32 	%r992, %lhs, %rhs;
	}
	xor.b32  	%r993, %r990, %r978;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r993, 25;
	shr.b32 	%rhs, %r993, 7;
	add.u32 	%r994, %lhs, %rhs;
	}
	add.s32 	%r996, %r944, %r965;
	add.s32 	%r997, %r996, %r994;
	ld.const.v4.u32 	{%r998, %r999, %r1000, %r1001}, [c_xors+416];
	add.s32 	%r1003, %r956, %r998;
	add.s32 	%r1004, %r1003, %r948;
	xor.b32  	%r1005, %r997, %r952;
	prmt.b32 	%r1006, %r1005, %r34, %r63;
	xor.b32  	%r1007, %r1004, %r986;
	prmt.b32 	%r1008, %r1007, %r34, %r63;
	add.s32 	%r1009, %r989, %r1006;
	add.s32 	%r1010, %r990, %r1008;
	xor.b32  	%r1011, %r1009, %r994;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1011, 20;
	shr.b32 	%rhs, %r1011, 12;
	add.u32 	%r1012, %lhs, %rhs;
	}
	xor.b32  	%r1013, %r1010, %r956;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1013, 20;
	shr.b32 	%rhs, %r1013, 12;
	add.u32 	%r1014, %lhs, %rhs;
	}
	add.s32 	%r1016, %r1012, %r999;
	add.s32 	%r1017, %r1016, %r997;
	add.s32 	%r1019, %r1014, %r1000;
	add.s32 	%r1020, %r1019, %r1004;
	xor.b32  	%r1021, %r1017, %r1006;
	prmt.b32 	%r1022, %r1021, %r34, %r33;
	xor.b32  	%r1023, %r1020, %r1008;
	prmt.b32 	%r1024, %r1023, %r34, %r33;
	add.s32 	%r1025, %r1009, %r1022;
	add.s32 	%r1026, %r1010, %r1024;
	xor.b32  	%r1027, %r1025, %r1012;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1027, 25;
	shr.b32 	%rhs, %r1027, 7;
	add.u32 	%r1028, %lhs, %rhs;
	}
	xor.b32  	%r1029, %r1026, %r1014;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1029, 25;
	shr.b32 	%rhs, %r1029, 7;
	add.u32 	%r1030, %lhs, %rhs;
	}
	add.s32 	%r1032, %r958, %r1001;
	add.s32 	%r1033, %r1032, %r981;
	ld.const.v4.u32 	{%r1034, %r1035, %r1036, %r1037}, [c_xors+432];
	xor.b32  	%r1039, %r1034, %r2;
	add.s32 	%r1040, %r1039, %r992;
	add.s32 	%r1041, %r1040, %r984;
	xor.b32  	%r1042, %r1033, %r988;
	prmt.b32 	%r1043, %r1042, %r34, %r63;
	xor.b32  	%r1044, %r1041, %r950;
	prmt.b32 	%r1045, %r1044, %r34, %r63;
	add.s32 	%r1046, %r953, %r1043;
	add.s32 	%r1047, %r954, %r1045;
	xor.b32  	%r1048, %r1046, %r958;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1048, 20;
	shr.b32 	%rhs, %r1048, 12;
	add.u32 	%r1049, %lhs, %rhs;
	}
	xor.b32  	%r1050, %r1047, %r992;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1050, 20;
	shr.b32 	%rhs, %r1050, 12;
	add.u32 	%r1051, %lhs, %rhs;
	}
	add.s32 	%r1053, %r1049, %r1035;
	add.s32 	%r1054, %r1053, %r1033;
	add.s32 	%r1056, %r1051, %r1036;
	add.s32 	%r1057, %r1056, %r1041;
	xor.b32  	%r1058, %r1054, %r1043;
	prmt.b32 	%r1059, %r1058, %r34, %r33;
	xor.b32  	%r1060, %r1057, %r1045;
	prmt.b32 	%r1061, %r1060, %r34, %r33;
	add.s32 	%r1062, %r1046, %r1059;
	add.s32 	%r1063, %r1047, %r1061;
	xor.b32  	%r1064, %r1062, %r1049;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1064, 25;
	shr.b32 	%rhs, %r1064, 7;
	add.u32 	%r1065, %lhs, %rhs;
	}
	xor.b32  	%r1066, %r1063, %r1051;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1066, 25;
	shr.b32 	%rhs, %r1066, 7;
	add.u32 	%r1067, %lhs, %rhs;
	}
	add.s32 	%r1069, %r1030, %r1037;
	add.s32 	%r1070, %r1069, %r1017;
	ld.const.v4.u32 	{%r1071, %r1072, %r1073, %r1074}, [c_xors+448];
	add.s32 	%r1076, %r1065, %r1071;
	add.s32 	%r1077, %r1076, %r1020;
	xor.b32  	%r1078, %r1070, %r1061;
	prmt.b32 	%r1079, %r1078, %r34, %r63;
	xor.b32  	%r1080, %r1077, %r1022;
	prmt.b32 	%r1081, %r1080, %r34, %r63;
	add.s32 	%r1082, %r1062, %r1079;
	add.s32 	%r1083, %r1063, %r1081;
	xor.b32  	%r1084, %r1082, %r1030;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1084, 20;
	shr.b32 	%rhs, %r1084, 12;
	add.u32 	%r1085, %lhs, %rhs;
	}
	xor.b32  	%r1086, %r1083, %r1065;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1086, 20;
	shr.b32 	%rhs, %r1086, 12;
	add.u32 	%r1087, %lhs, %rhs;
	}
	add.s32 	%r1089, %r1085, %r1072;
	add.s32 	%r1090, %r1089, %r1070;
	add.s32 	%r1092, %r1087, %r1073;
	add.s32 	%r1093, %r1092, %r1077;
	xor.b32  	%r1094, %r1090, %r1079;
	prmt.b32 	%r1095, %r1094, %r34, %r33;
	xor.b32  	%r1096, %r1093, %r1081;
	prmt.b32 	%r1097, %r1096, %r34, %r33;
	add.s32 	%r1098, %r1082, %r1095;
	add.s32 	%r1099, %r1083, %r1097;
	xor.b32  	%r1100, %r1098, %r1085;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1100, 25;
	shr.b32 	%rhs, %r1100, 7;
	add.u32 	%r1101, %lhs, %rhs;
	}
	xor.b32  	%r1102, %r1099, %r1087;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1102, 25;
	shr.b32 	%rhs, %r1102, 7;
	add.u32 	%r1103, %lhs, %rhs;
	}
	add.s32 	%r1105, %r1067, %r1074;
	add.s32 	%r1106, %r1105, %r1054;
	ld.const.v4.u32 	{%r1107, %r1108, %r1109, %r1110}, [c_xors+464];
	add.s32 	%r1112, %r1028, %r1107;
	add.s32 	%r1113, %r1112, %r1057;
	xor.b32  	%r1114, %r1106, %r1024;
	prmt.b32 	%r1115, %r1114, %r34, %r63;
	xor.b32  	%r1116, %r1113, %r1059;
	prmt.b32 	%r1117, %r1116, %r34, %r63;
	add.s32 	%r1118, %r1025, %r1115;
	add.s32 	%r1119, %r1026, %r1117;
	xor.b32  	%r1120, %r1118, %r1067;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1120, 20;
	shr.b32 	%rhs, %r1120, 12;
	add.u32 	%r1121, %lhs, %rhs;
	}
	xor.b32  	%r1122, %r1119, %r1028;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1122, 20;
	shr.b32 	%rhs, %r1122, 12;
	add.u32 	%r1123, %lhs, %rhs;
	}
	add.s32 	%r1125, %r1121, %r1108;
	add.s32 	%r1126, %r1125, %r1106;
	add.s32 	%r1128, %r1123, %r1109;
	add.s32 	%r1129, %r1128, %r1113;
	xor.b32  	%r1130, %r1126, %r1115;
	prmt.b32 	%r1131, %r1130, %r34, %r33;
	xor.b32  	%r1132, %r1129, %r1117;
	prmt.b32 	%r1133, %r1132, %r34, %r33;
	add.s32 	%r1134, %r1118, %r1131;
	add.s32 	%r1135, %r1119, %r1133;
	xor.b32  	%r1136, %r1134, %r1121;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1136, 25;
	shr.b32 	%rhs, %r1136, 7;
	add.u32 	%r1137, %lhs, %rhs;
	}
	xor.b32  	%r1138, %r1135, %r1123;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1138, 25;
	shr.b32 	%rhs, %r1138, 7;
	add.u32 	%r1139, %lhs, %rhs;
	}
	add.s32 	%r1141, %r1090, %r1110;
	add.s32 	%r1142, %r1141, %r1139;
	ld.const.v4.u32 	{%r1143, %r1144, %r1145, %r1146}, [c_xors+480];
	add.s32 	%r1148, %r1101, %r1143;
	add.s32 	%r1149, %r1148, %r1093;
	xor.b32  	%r1150, %r1142, %r1097;
	prmt.b32 	%r1151, %r1150, %r34, %r63;
	xor.b32  	%r1152, %r1149, %r1131;
	prmt.b32 	%r1153, %r1152, %r34, %r63;
	add.s32 	%r1154, %r1134, %r1151;
	add.s32 	%r1155, %r1135, %r1153;
	xor.b32  	%r1156, %r1154, %r1139;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1156, 20;
	shr.b32 	%rhs, %r1156, 12;
	add.u32 	%r1157, %lhs, %rhs;
	}
	xor.b32  	%r1158, %r1155, %r1101;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1158, 20;
	shr.b32 	%rhs, %r1158, 12;
	add.u32 	%r1159, %lhs, %rhs;
	}
	add.s32 	%r1161, %r1157, %r1144;
	add.s32 	%r1162, %r1161, %r1142;
	add.s32 	%r1164, %r1159, %r1145;
	add.s32 	%r1165, %r1164, %r1149;
	xor.b32  	%r1166, %r1162, %r1151;
	prmt.b32 	%r1167, %r1166, %r34, %r33;
	xor.b32  	%r1168, %r1165, %r1153;
	prmt.b32 	%r1169, %r1168, %r34, %r33;
	add.s32 	%r1170, %r1154, %r1167;
	add.s32 	%r1171, %r1155, %r1169;
	xor.b32  	%r1172, %r1170, %r1157;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1172, 25;
	shr.b32 	%rhs, %r1172, 7;
	add.u32 	%r1173, %lhs, %rhs;
	}
	xor.b32  	%r1174, %r1171, %r1159;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1174, 25;
	shr.b32 	%rhs, %r1174, 7;
	add.u32 	%r1175, %lhs, %rhs;
	}
	add.s32 	%r1177, %r1103, %r1146;
	add.s32 	%r1178, %r1177, %r1126;
	ld.const.v4.u32 	{%r1179, %r1180, %r1181, %r1182}, [c_xors+496];
	add.s32 	%r1184, %r1137, %r1179;
	add.s32 	%r1185, %r1184, %r1129;
	xor.b32  	%r1186, %r1178, %r1133;
	prmt.b32 	%r1187, %r1186, %r34, %r63;
	xor.b32  	%r1188, %r1185, %r1095;
	prmt.b32 	%r1189, %r1188, %r34, %r63;
	add.s32 	%r1190, %r1098, %r1187;
	add.s32 	%r1191, %r1099, %r1189;
	xor.b32  	%r1192, %r1190, %r1103;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1192, 20;
	shr.b32 	%rhs, %r1192, 12;
	add.u32 	%r1193, %lhs, %rhs;
	}
	xor.b32  	%r1194, %r1191, %r1137;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1194, 20;
	shr.b32 	%rhs, %r1194, 12;
	add.u32 	%r1195, %lhs, %rhs;
	}
	xor.b32  	%r1197, %r1180, %r2;
	add.s32 	%r1198, %r1197, %r1193;
	add.s32 	%r1199, %r1198, %r1178;
	add.s32 	%r1201, %r1195, %r1181;
	add.s32 	%r1202, %r1201, %r1185;
	xor.b32  	%r1203, %r1199, %r1187;
	prmt.b32 	%r1204, %r1203, %r34, %r33;
	xor.b32  	%r1205, %r1202, %r1189;
	prmt.b32 	%r1206, %r1205, %r34, %r33;
	add.s32 	%r1207, %r1190, %r1204;
	add.s32 	%r1208, %r1191, %r1206;
	xor.b32  	%r1209, %r1207, %r1193;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1209, 25;
	shr.b32 	%rhs, %r1209, 7;
	add.u32 	%r1210, %lhs, %rhs;
	}
	xor.b32  	%r1211, %r1208, %r1195;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1211, 25;
	shr.b32 	%rhs, %r1211, 7;
	add.u32 	%r1212, %lhs, %rhs;
	}
	add.s32 	%r1214, %r1175, %r1182;
	add.s32 	%r1215, %r1214, %r1162;
	ld.const.v4.u32 	{%r1216, %r1217, %r1218, %r1219}, [c_xors+512];
	add.s32 	%r1221, %r1210, %r1216;
	add.s32 	%r1222, %r1221, %r1165;
	xor.b32  	%r1223, %r1215, %r1206;
	prmt.b32 	%r1224, %r1223, %r34, %r63;
	xor.b32  	%r1225, %r1222, %r1167;
	prmt.b32 	%r1226, %r1225, %r34, %r63;
	add.s32 	%r1227, %r1207, %r1224;
	add.s32 	%r1228, %r1208, %r1226;
	xor.b32  	%r1229, %r1227, %r1175;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1229, 20;
	shr.b32 	%rhs, %r1229, 12;
	add.u32 	%r1230, %lhs, %rhs;
	}
	xor.b32  	%r1231, %r1228, %r1210;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1231, 20;
	shr.b32 	%rhs, %r1231, 12;
	add.u32 	%r1232, %lhs, %rhs;
	}
	add.s32 	%r1234, %r1230, %r1217;
	add.s32 	%r1235, %r1234, %r1215;
	add.s32 	%r1237, %r1232, %r1218;
	add.s32 	%r1238, %r1237, %r1222;
	xor.b32  	%r1239, %r1235, %r1224;
	prmt.b32 	%r1240, %r1239, %r34, %r33;
	xor.b32  	%r1241, %r1238, %r1226;
	prmt.b32 	%r1242, %r1241, %r34, %r33;
	add.s32 	%r1243, %r1227, %r1240;
	add.s32 	%r1244, %r1228, %r1242;
	xor.b32  	%r1245, %r1243, %r1230;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1245, 25;
	shr.b32 	%rhs, %r1245, 7;
	add.u32 	%r1246, %lhs, %rhs;
	}
	xor.b32  	%r1247, %r1244, %r1232;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1247, 25;
	shr.b32 	%rhs, %r1247, 7;
	add.u32 	%r1248, %lhs, %rhs;
	}
	add.s32 	%r1250, %r1212, %r1219;
	add.s32 	%r1251, %r1250, %r1199;
	ld.const.v4.u32 	{%r1252, %r1253, %r1254, %r1255}, [c_xors+528];
	add.s32 	%r1257, %r1173, %r1252;
	add.s32 	%r1258, %r1257, %r1202;
	xor.b32  	%r1259, %r1251, %r1169;
	prmt.b32 	%r1260, %r1259, %r34, %r63;
	xor.b32  	%r1261, %r1258, %r1204;
	prmt.b32 	%r1262, %r1261, %r34, %r63;
	add.s32 	%r1263, %r1170, %r1260;
	add.s32 	%r1264, %r1171, %r1262;
	xor.b32  	%r1265, %r1263, %r1212;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1265, 20;
	shr.b32 	%rhs, %r1265, 12;
	add.u32 	%r1266, %lhs, %rhs;
	}
	xor.b32  	%r1267, %r1264, %r1173;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1267, 20;
	shr.b32 	%rhs, %r1267, 12;
	add.u32 	%r1268, %lhs, %rhs;
	}
	add.s32 	%r1270, %r1266, %r1253;
	add.s32 	%r1271, %r1270, %r1251;
	add.s32 	%r1273, %r1268, %r1254;
	add.s32 	%r1274, %r1273, %r1258;
	xor.b32  	%r1275, %r1271, %r1260;
	prmt.b32 	%r1276, %r1275, %r34, %r33;
	xor.b32  	%r1277, %r1274, %r1262;
	prmt.b32 	%r1278, %r1277, %r34, %r33;
	add.s32 	%r1279, %r1263, %r1276;
	add.s32 	%r1280, %r1264, %r1278;
	xor.b32  	%r1281, %r1279, %r1266;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1281, 25;
	shr.b32 	%rhs, %r1281, 7;
	add.u32 	%r1282, %lhs, %rhs;
	}
	xor.b32  	%r1283, %r1280, %r1268;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1283, 25;
	shr.b32 	%rhs, %r1283, 7;
	add.u32 	%r1284, %lhs, %rhs;
	}
	add.s32 	%r1286, %r1235, %r1255;
	add.s32 	%r1287, %r1286, %r1284;
	ld.const.v4.u32 	{%r1288, %r1289, %r1290, %r1291}, [c_xors+544];
	add.s32 	%r1293, %r1246, %r1288;
	add.s32 	%r1294, %r1293, %r1238;
	xor.b32  	%r1295, %r1287, %r1242;
	prmt.b32 	%r1296, %r1295, %r34, %r63;
	xor.b32  	%r1297, %r1294, %r1276;
	prmt.b32 	%r1298, %r1297, %r34, %r63;
	add.s32 	%r1299, %r1279, %r1296;
	add.s32 	%r1300, %r1280, %r1298;
	xor.b32  	%r1301, %r1299, %r1284;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1301, 20;
	shr.b32 	%rhs, %r1301, 12;
	add.u32 	%r1302, %lhs, %rhs;
	}
	xor.b32  	%r1303, %r1300, %r1246;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1303, 20;
	shr.b32 	%rhs, %r1303, 12;
	add.u32 	%r1304, %lhs, %rhs;
	}
	add.s32 	%r1306, %r1302, %r1289;
	add.s32 	%r1307, %r1306, %r1287;
	add.s32 	%r1309, %r1304, %r1290;
	add.s32 	%r1310, %r1309, %r1294;
	xor.b32  	%r1311, %r1307, %r1296;
	prmt.b32 	%r1312, %r1311, %r34, %r33;
	xor.b32  	%r1313, %r1310, %r1298;
	prmt.b32 	%r1314, %r1313, %r34, %r33;
	add.s32 	%r1315, %r1299, %r1312;
	add.s32 	%r1316, %r1300, %r1314;
	xor.b32  	%r1317, %r1315, %r1302;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1317, 25;
	shr.b32 	%rhs, %r1317, 7;
	add.u32 	%r1318, %lhs, %rhs;
	}
	xor.b32  	%r1319, %r1316, %r1304;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1319, 25;
	shr.b32 	%rhs, %r1319, 7;
	add.u32 	%r1320, %lhs, %rhs;
	}
	add.s32 	%r1322, %r1248, %r1291;
	add.s32 	%r1323, %r1322, %r1271;
	ld.const.v4.u32 	{%r1324, %r1325, %r1326, %r1327}, [c_xors+560];
	add.s32 	%r1329, %r1282, %r1324;
	add.s32 	%r1330, %r1329, %r1274;
	xor.b32  	%r1331, %r1323, %r1278;
	prmt.b32 	%r1332, %r1331, %r34, %r63;
	xor.b32  	%r1333, %r1330, %r1240;
	prmt.b32 	%r1334, %r1333, %r34, %r63;
	add.s32 	%r1335, %r1243, %r1332;
	add.s32 	%r1336, %r1244, %r1334;
	xor.b32  	%r1337, %r1335, %r1248;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1337, 20;
	shr.b32 	%rhs, %r1337, 12;
	add.u32 	%r1338, %lhs, %rhs;
	}
	xor.b32  	%r1339, %r1336, %r1282;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1339, 20;
	shr.b32 	%rhs, %r1339, 12;
	add.u32 	%r1340, %lhs, %rhs;
	}
	add.s32 	%r1342, %r1338, %r1325;
	add.s32 	%r1343, %r1342, %r1323;
	add.s32 	%r1345, %r1340, %r1326;
	add.s32 	%r1346, %r1345, %r1330;
	xor.b32  	%r1347, %r1343, %r1332;
	prmt.b32 	%r1348, %r1347, %r34, %r33;
	xor.b32  	%r1349, %r1346, %r1334;
	prmt.b32 	%r1350, %r1349, %r34, %r33;
	add.s32 	%r1351, %r1335, %r1348;
	add.s32 	%r1352, %r1336, %r1350;
	xor.b32  	%r1353, %r1351, %r1338;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1353, 25;
	shr.b32 	%rhs, %r1353, 7;
	add.u32 	%r1354, %lhs, %rhs;
	}
	xor.b32  	%r1355, %r1352, %r1340;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1355, 25;
	shr.b32 	%rhs, %r1355, 7;
	add.u32 	%r1356, %lhs, %rhs;
	}
	add.s32 	%r1358, %r1320, %r1327;
	add.s32 	%r1359, %r1358, %r1307;
	ld.const.v4.u32 	{%r1360, %r1361, %r1362, %r1363}, [c_xors+576];
	add.s32 	%r1365, %r1354, %r1360;
	add.s32 	%r1366, %r1365, %r1310;
	xor.b32  	%r1367, %r1359, %r1350;
	prmt.b32 	%r1368, %r1367, %r34, %r63;
	xor.b32  	%r1369, %r1366, %r1312;
	prmt.b32 	%r1370, %r1369, %r34, %r63;
	add.s32 	%r1371, %r1351, %r1368;
	add.s32 	%r1372, %r1352, %r1370;
	xor.b32  	%r1373, %r1371, %r1320;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1373, 20;
	shr.b32 	%rhs, %r1373, 12;
	add.u32 	%r1374, %lhs, %rhs;
	}
	xor.b32  	%r1375, %r1372, %r1354;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1375, 20;
	shr.b32 	%rhs, %r1375, 12;
	add.u32 	%r1376, %lhs, %rhs;
	}
	add.s32 	%r1378, %r1374, %r1361;
	add.s32 	%r1379, %r1378, %r1359;
	add.s32 	%r1381, %r1376, %r1362;
	add.s32 	%r1382, %r1381, %r1366;
	xor.b32  	%r1383, %r1379, %r1368;
	prmt.b32 	%r1384, %r1383, %r34, %r33;
	xor.b32  	%r1385, %r1382, %r1370;
	prmt.b32 	%r1386, %r1385, %r34, %r33;
	add.s32 	%r1387, %r1371, %r1384;
	add.s32 	%r1388, %r1372, %r1386;
	xor.b32  	%r1389, %r1387, %r1374;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1389, 25;
	shr.b32 	%rhs, %r1389, 7;
	add.u32 	%r1390, %lhs, %rhs;
	}
	xor.b32  	%r1391, %r1388, %r1376;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1391, 25;
	shr.b32 	%rhs, %r1391, 7;
	add.u32 	%r1392, %lhs, %rhs;
	}
	xor.b32  	%r1394, %r1363, %r2;
	add.s32 	%r1395, %r1394, %r1356;
	add.s32 	%r1396, %r1395, %r1343;
	ld.const.v4.u32 	{%r1397, %r1398, %r1399, %r1400}, [c_xors+592];
	add.s32 	%r1402, %r1318, %r1397;
	add.s32 	%r1403, %r1402, %r1346;
	xor.b32  	%r1404, %r1396, %r1314;
	prmt.b32 	%r1405, %r1404, %r34, %r63;
	xor.b32  	%r1406, %r1403, %r1348;
	prmt.b32 	%r1407, %r1406, %r34, %r63;
	add.s32 	%r1408, %r1315, %r1405;
	add.s32 	%r1409, %r1316, %r1407;
	xor.b32  	%r1410, %r1408, %r1356;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1410, 20;
	shr.b32 	%rhs, %r1410, 12;
	add.u32 	%r1411, %lhs, %rhs;
	}
	xor.b32  	%r1412, %r1409, %r1318;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1412, 20;
	shr.b32 	%rhs, %r1412, 12;
	add.u32 	%r1413, %lhs, %rhs;
	}
	add.s32 	%r1415, %r1411, %r1398;
	add.s32 	%r1416, %r1415, %r1396;
	add.s32 	%r1418, %r1413, %r1399;
	add.s32 	%r1419, %r1418, %r1403;
	xor.b32  	%r1420, %r1416, %r1405;
	prmt.b32 	%r1421, %r1420, %r34, %r33;
	xor.b32  	%r1422, %r1419, %r1407;
	prmt.b32 	%r1423, %r1422, %r34, %r33;
	add.s32 	%r1424, %r1408, %r1421;
	add.s32 	%r1425, %r1409, %r1423;
	xor.b32  	%r1426, %r1424, %r1411;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1426, 25;
	shr.b32 	%rhs, %r1426, 7;
	add.u32 	%r1427, %lhs, %rhs;
	}
	xor.b32  	%r1428, %r1425, %r1413;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1428, 25;
	shr.b32 	%rhs, %r1428, 7;
	add.u32 	%r1429, %lhs, %rhs;
	}
	add.s32 	%r1431, %r1379, %r1400;
	add.s32 	%r1432, %r1431, %r1429;
	ld.const.v4.u32 	{%r1433, %r1434, %r1435, %r1436}, [c_xors+608];
	add.s32 	%r1438, %r1390, %r1433;
	add.s32 	%r1439, %r1438, %r1382;
	xor.b32  	%r1440, %r1432, %r1386;
	prmt.b32 	%r1441, %r1440, %r34, %r63;
	xor.b32  	%r1442, %r1439, %r1421;
	prmt.b32 	%r1443, %r1442, %r34, %r63;
	add.s32 	%r1444, %r1424, %r1441;
	add.s32 	%r1445, %r1425, %r1443;
	xor.b32  	%r1446, %r1444, %r1429;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1446, 20;
	shr.b32 	%rhs, %r1446, 12;
	add.u32 	%r1447, %lhs, %rhs;
	}
	xor.b32  	%r1448, %r1445, %r1390;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1448, 20;
	shr.b32 	%rhs, %r1448, 12;
	add.u32 	%r1449, %lhs, %rhs;
	}
	add.s32 	%r1451, %r1447, %r1434;
	add.s32 	%r1452, %r1451, %r1432;
	xor.b32  	%r1454, %r1435, %r2;
	add.s32 	%r1455, %r1454, %r1449;
	add.s32 	%r1456, %r1455, %r1439;
	xor.b32  	%r1457, %r1452, %r1441;
	prmt.b32 	%r1458, %r1457, %r34, %r33;
	xor.b32  	%r1459, %r1456, %r1443;
	prmt.b32 	%r1460, %r1459, %r34, %r33;
	add.s32 	%r1461, %r1444, %r1458;
	add.s32 	%r1462, %r1445, %r1460;
	xor.b32  	%r1463, %r1461, %r1447;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1463, 25;
	shr.b32 	%rhs, %r1463, 7;
	add.u32 	%r1464, %lhs, %rhs;
	}
	xor.b32  	%r1465, %r1462, %r1449;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1465, 25;
	shr.b32 	%rhs, %r1465, 7;
	add.u32 	%r1466, %lhs, %rhs;
	}
	add.s32 	%r1468, %r1392, %r1436;
	add.s32 	%r1469, %r1468, %r1416;
	ld.const.v4.u32 	{%r1470, %r1471, %r1472, %r1473}, [c_xors+624];
	add.s32 	%r1475, %r1427, %r1470;
	add.s32 	%r1476, %r1475, %r1419;
	xor.b32  	%r1477, %r1469, %r1423;
	prmt.b32 	%r1478, %r1477, %r34, %r63;
	xor.b32  	%r1479, %r1476, %r1384;
	prmt.b32 	%r1480, %r1479, %r34, %r63;
	add.s32 	%r1481, %r1387, %r1478;
	add.s32 	%r1482, %r1388, %r1480;
	xor.b32  	%r1483, %r1481, %r1392;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1483, 20;
	shr.b32 	%rhs, %r1483, 12;
	add.u32 	%r1484, %lhs, %rhs;
	}
	xor.b32  	%r1485, %r1482, %r1427;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1485, 20;
	shr.b32 	%rhs, %r1485, 12;
	add.u32 	%r1486, %lhs, %rhs;
	}
	add.s32 	%r1488, %r1484, %r1471;
	add.s32 	%r1489, %r1488, %r1469;
	add.s32 	%r1491, %r1486, %r1472;
	add.s32 	%r1492, %r1491, %r1476;
	xor.b32  	%r1493, %r1489, %r1478;
	prmt.b32 	%r1494, %r1493, %r34, %r33;
	xor.b32  	%r1495, %r1492, %r1480;
	prmt.b32 	%r1496, %r1495, %r34, %r33;
	add.s32 	%r1497, %r1481, %r1494;
	add.s32 	%r1498, %r1482, %r1496;
	xor.b32  	%r1499, %r1497, %r1484;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1499, 25;
	shr.b32 	%rhs, %r1499, 7;
	add.u32 	%r1500, %lhs, %rhs;
	}
	xor.b32  	%r1501, %r1498, %r1486;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1501, 25;
	shr.b32 	%rhs, %r1501, 7;
	add.u32 	%r1502, %lhs, %rhs;
	}
	add.s32 	%r1504, %r1466, %r1473;
	add.s32 	%r1505, %r1504, %r1452;
	ld.const.v4.u32 	{%r1506, %r1507, %r1508, %r1509}, [c_xors+640];
	add.s32 	%r1511, %r1500, %r1506;
	add.s32 	%r1512, %r1511, %r1456;
	xor.b32  	%r1513, %r1505, %r1496;
	prmt.b32 	%r1514, %r1513, %r34, %r63;
	xor.b32  	%r1515, %r1512, %r1458;
	prmt.b32 	%r1516, %r1515, %r34, %r63;
	add.s32 	%r1517, %r1497, %r1514;
	add.s32 	%r1518, %r1498, %r1516;
	xor.b32  	%r1519, %r1517, %r1466;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1519, 20;
	shr.b32 	%rhs, %r1519, 12;
	add.u32 	%r1520, %lhs, %rhs;
	}
	xor.b32  	%r1521, %r1518, %r1500;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1521, 20;
	shr.b32 	%rhs, %r1521, 12;
	add.u32 	%r1522, %lhs, %rhs;
	}
	add.s32 	%r1524, %r1520, %r1507;
	add.s32 	%r1525, %r1524, %r1505;
	add.s32 	%r1527, %r1522, %r1508;
	add.s32 	%r1528, %r1527, %r1512;
	xor.b32  	%r1529, %r1525, %r1514;
	prmt.b32 	%r1530, %r1529, %r34, %r33;
	xor.b32  	%r1531, %r1528, %r1516;
	prmt.b32 	%r1532, %r1531, %r34, %r33;
	add.s32 	%r1533, %r1517, %r1530;
	add.s32 	%r1534, %r1518, %r1532;
	xor.b32  	%r1535, %r1533, %r1520;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1535, 25;
	shr.b32 	%rhs, %r1535, 7;
	add.u32 	%r1536, %lhs, %rhs;
	}
	xor.b32  	%r1537, %r1534, %r1522;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1537, 25;
	shr.b32 	%rhs, %r1537, 7;
	add.u32 	%r1538, %lhs, %rhs;
	}
	add.s32 	%r1540, %r1502, %r1509;
	add.s32 	%r1541, %r1540, %r1489;
	ld.const.v4.u32 	{%r1542, %r1543, %r1544, %r1545}, [c_xors+656];
	add.s32 	%r1547, %r1464, %r1542;
	add.s32 	%r1548, %r1547, %r1492;
	xor.b32  	%r1549, %r1541, %r1460;
	prmt.b32 	%r1550, %r1549, %r34, %r63;
	xor.b32  	%r1551, %r1548, %r1494;
	prmt.b32 	%r1552, %r1551, %r34, %r63;
	add.s32 	%r1553, %r1461, %r1550;
	add.s32 	%r1554, %r1462, %r1552;
	xor.b32  	%r1555, %r1553, %r1502;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1555, 20;
	shr.b32 	%rhs, %r1555, 12;
	add.u32 	%r1556, %lhs, %rhs;
	}
	xor.b32  	%r1557, %r1554, %r1464;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1557, 20;
	shr.b32 	%rhs, %r1557, 12;
	add.u32 	%r1558, %lhs, %rhs;
	}
	add.s32 	%r1560, %r1556, %r1543;
	add.s32 	%r1561, %r1560, %r1541;
	add.s32 	%r1563, %r1558, %r1544;
	add.s32 	%r1564, %r1563, %r1548;
	xor.b32  	%r1565, %r1561, %r1550;
	prmt.b32 	%r1566, %r1565, %r34, %r33;
	xor.b32  	%r1567, %r1564, %r1552;
	prmt.b32 	%r1568, %r1567, %r34, %r33;
	add.s32 	%r1569, %r1553, %r1566;
	add.s32 	%r1570, %r1554, %r1568;
	xor.b32  	%r1571, %r1569, %r1556;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1571, 25;
	shr.b32 	%rhs, %r1571, 7;
	add.u32 	%r1572, %lhs, %rhs;
	}
	xor.b32  	%r1573, %r1570, %r1558;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1573, 25;
	shr.b32 	%rhs, %r1573, 7;
	add.u32 	%r1574, %lhs, %rhs;
	}
	add.s32 	%r1576, %r1525, %r1545;
	add.s32 	%r1577, %r1576, %r1574;
	ld.const.v4.u32 	{%r1578, %r1579, %r1580, %r1581}, [c_xors+672];
	add.s32 	%r1583, %r1536, %r1578;
	add.s32 	%r1584, %r1583, %r1528;
	xor.b32  	%r1585, %r1577, %r1532;
	prmt.b32 	%r1586, %r1585, %r34, %r63;
	xor.b32  	%r1587, %r1584, %r1566;
	prmt.b32 	%r1588, %r1587, %r34, %r63;
	add.s32 	%r1589, %r1569, %r1586;
	add.s32 	%r1590, %r1570, %r1588;
	xor.b32  	%r1591, %r1589, %r1574;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1591, 20;
	shr.b32 	%rhs, %r1591, 12;
	add.u32 	%r1592, %lhs, %rhs;
	}
	xor.b32  	%r1593, %r1590, %r1536;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1593, 20;
	shr.b32 	%rhs, %r1593, 12;
	add.u32 	%r1594, %lhs, %rhs;
	}
	add.s32 	%r1596, %r1592, %r1579;
	add.s32 	%r1597, %r1596, %r1577;
	add.s32 	%r1599, %r1594, %r1580;
	add.s32 	%r1600, %r1599, %r1584;
	xor.b32  	%r1601, %r1597, %r1586;
	prmt.b32 	%r1602, %r1601, %r34, %r33;
	xor.b32  	%r1603, %r1600, %r1588;
	prmt.b32 	%r1604, %r1603, %r34, %r33;
	add.s32 	%r1605, %r1589, %r1602;
	add.s32 	%r1606, %r1590, %r1604;
	xor.b32  	%r1607, %r1605, %r1592;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1607, 25;
	shr.b32 	%rhs, %r1607, 7;
	add.u32 	%r1608, %lhs, %rhs;
	}
	xor.b32  	%r1609, %r1606, %r1594;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1609, 25;
	shr.b32 	%rhs, %r1609, 7;
	add.u32 	%r1610, %lhs, %rhs;
	}
	add.s32 	%r1612, %r1538, %r1581;
	add.s32 	%r1613, %r1612, %r1561;
	ld.const.v4.u32 	{%r1614, %r1615, %r1616, %r1617}, [c_xors+688];
	add.s32 	%r1619, %r1572, %r1614;
	add.s32 	%r1620, %r1619, %r1564;
	xor.b32  	%r1621, %r1613, %r1568;
	prmt.b32 	%r1622, %r1621, %r34, %r63;
	xor.b32  	%r1623, %r1620, %r1530;
	prmt.b32 	%r1624, %r1623, %r34, %r63;
	add.s32 	%r1625, %r1533, %r1622;
	add.s32 	%r1626, %r1534, %r1624;
	xor.b32  	%r1627, %r1625, %r1538;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1627, 20;
	shr.b32 	%rhs, %r1627, 12;
	add.u32 	%r1628, %lhs, %rhs;
	}
	xor.b32  	%r1629, %r1626, %r1572;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1629, 20;
	shr.b32 	%rhs, %r1629, 12;
	add.u32 	%r1630, %lhs, %rhs;
	}
	add.s32 	%r1632, %r1628, %r1615;
	add.s32 	%r1633, %r1632, %r1613;
	add.s32 	%r1635, %r1630, %r1616;
	add.s32 	%r1636, %r1635, %r1620;
	xor.b32  	%r1637, %r1633, %r1622;
	prmt.b32 	%r1638, %r1637, %r34, %r33;
	xor.b32  	%r1639, %r1636, %r1624;
	prmt.b32 	%r1640, %r1639, %r34, %r33;
	add.s32 	%r1641, %r1625, %r1638;
	add.s32 	%r1642, %r1626, %r1640;
	xor.b32  	%r1643, %r1641, %r1628;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1643, 25;
	shr.b32 	%rhs, %r1643, 7;
	add.u32 	%r1644, %lhs, %rhs;
	}
	xor.b32  	%r1645, %r1642, %r1630;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1645, 25;
	shr.b32 	%rhs, %r1645, 7;
	add.u32 	%r1646, %lhs, %rhs;
	}
	add.s32 	%r1648, %r1610, %r1617;
	add.s32 	%r1649, %r1648, %r1597;
	ld.const.v4.u32 	{%r1650, %r1651, %r1652, %r1653}, [c_xors+704];
	add.s32 	%r1655, %r1644, %r1650;
	add.s32 	%r1656, %r1655, %r1600;
	xor.b32  	%r1657, %r1649, %r1640;
	prmt.b32 	%r1658, %r1657, %r34, %r63;
	xor.b32  	%r1659, %r1656, %r1602;
	prmt.b32 	%r1660, %r1659, %r34, %r63;
	add.s32 	%r1661, %r1641, %r1658;
	add.s32 	%r1662, %r1642, %r1660;
	xor.b32  	%r1663, %r1661, %r1610;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1663, 20;
	shr.b32 	%rhs, %r1663, 12;
	add.u32 	%r1664, %lhs, %rhs;
	}
	xor.b32  	%r1665, %r1662, %r1644;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1665, 20;
	shr.b32 	%rhs, %r1665, 12;
	add.u32 	%r1666, %lhs, %rhs;
	}
	add.s32 	%r1668, %r1664, %r1651;
	add.s32 	%r1669, %r1668, %r1649;
	add.s32 	%r1671, %r1666, %r1652;
	add.s32 	%r1672, %r1671, %r1656;
	xor.b32  	%r1673, %r1669, %r1658;
	prmt.b32 	%r1674, %r1673, %r34, %r33;
	xor.b32  	%r1675, %r1672, %r1660;
	prmt.b32 	%r1676, %r1675, %r34, %r33;
	add.s32 	%r1677, %r1661, %r1674;
	add.s32 	%r1678, %r1662, %r1676;
	xor.b32  	%r1679, %r1677, %r1664;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1679, 25;
	shr.b32 	%rhs, %r1679, 7;
	add.u32 	%r1680, %lhs, %rhs;
	}
	xor.b32  	%r1681, %r1678, %r1666;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1681, 25;
	shr.b32 	%rhs, %r1681, 7;
	add.u32 	%r1682, %lhs, %rhs;
	}
	add.s32 	%r1684, %r1646, %r1653;
	add.s32 	%r1685, %r1684, %r1633;
	ld.const.v4.u32 	{%r1686, %r1687, %r1688, %r1689}, [c_xors+720];
	add.s32 	%r1691, %r1608, %r1686;
	add.s32 	%r1692, %r1691, %r1636;
	xor.b32  	%r1693, %r1685, %r1604;
	prmt.b32 	%r1694, %r1693, %r34, %r63;
	xor.b32  	%r1695, %r1692, %r1638;
	prmt.b32 	%r1696, %r1695, %r34, %r63;
	add.s32 	%r1697, %r1605, %r1694;
	add.s32 	%r1698, %r1606, %r1696;
	xor.b32  	%r1699, %r1697, %r1646;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1699, 20;
	shr.b32 	%rhs, %r1699, 12;
	add.u32 	%r1700, %lhs, %rhs;
	}
	xor.b32  	%r1701, %r1698, %r1608;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1701, 20;
	shr.b32 	%rhs, %r1701, 12;
	add.u32 	%r1702, %lhs, %rhs;
	}
	add.s32 	%r1704, %r1700, %r1687;
	add.s32 	%r1705, %r1704, %r1685;
	xor.b32  	%r1707, %r1688, %r2;
	add.s32 	%r1708, %r1707, %r1702;
	add.s32 	%r1709, %r1708, %r1692;
	xor.b32  	%r1710, %r1705, %r1694;
	prmt.b32 	%r1711, %r1710, %r34, %r33;
	xor.b32  	%r1712, %r1709, %r1696;
	prmt.b32 	%r1713, %r1712, %r34, %r33;
	add.s32 	%r1714, %r1697, %r1711;
	add.s32 	%r1715, %r1698, %r1713;
	xor.b32  	%r1716, %r1714, %r1700;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1716, 25;
	shr.b32 	%rhs, %r1716, 7;
	add.u32 	%r1717, %lhs, %rhs;
	}
	xor.b32  	%r1718, %r1715, %r1702;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1718, 25;
	shr.b32 	%rhs, %r1718, 7;
	add.u32 	%r1719, %lhs, %rhs;
	}
	add.s32 	%r1721, %r1669, %r1689;
	add.s32 	%r1722, %r1721, %r1719;
	ld.const.v4.u32 	{%r1723, %r1724, %r1725, %r1726}, [c_xors+736];
	add.s32 	%r1728, %r1680, %r1723;
	add.s32 	%r1729, %r1728, %r1672;
	xor.b32  	%r1730, %r1722, %r1676;
	prmt.b32 	%r1731, %r1730, %r34, %r63;
	xor.b32  	%r1732, %r1729, %r1711;
	prmt.b32 	%r1733, %r1732, %r34, %r63;
	add.s32 	%r1734, %r1714, %r1731;
	add.s32 	%r1735, %r1715, %r1733;
	xor.b32  	%r1736, %r1734, %r1719;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1736, 20;
	shr.b32 	%rhs, %r1736, 12;
	add.u32 	%r1737, %lhs, %rhs;
	}
	xor.b32  	%r1738, %r1735, %r1680;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1738, 20;
	shr.b32 	%rhs, %r1738, 12;
	add.u32 	%r1739, %lhs, %rhs;
	}
	add.s32 	%r1741, %r1737, %r1724;
	add.s32 	%r1742, %r1741, %r1722;
	add.s32 	%r1744, %r1739, %r1725;
	add.s32 	%r1745, %r1744, %r1729;
	xor.b32  	%r1746, %r1742, %r1731;
	prmt.b32 	%r1747, %r1746, %r34, %r33;
	xor.b32  	%r1748, %r1745, %r1733;
	prmt.b32 	%r1749, %r1748, %r34, %r33;
	add.s32 	%r1750, %r1734, %r1747;
	add.s32 	%r1751, %r1735, %r1749;
	xor.b32  	%r1752, %r1750, %r1737;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1752, 25;
	shr.b32 	%rhs, %r1752, 7;
	add.u32 	%r1753, %lhs, %rhs;
	}
	xor.b32  	%r1754, %r1751, %r1739;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1754, 25;
	shr.b32 	%rhs, %r1754, 7;
	add.u32 	%r1755, %lhs, %rhs;
	}
	add.s32 	%r1757, %r1682, %r1726;
	add.s32 	%r1758, %r1757, %r1705;
	ld.const.v4.u32 	{%r1759, %r1760, %r1761, %r1762}, [c_xors+752];
	add.s32 	%r1764, %r1717, %r1759;
	add.s32 	%r1765, %r1764, %r1709;
	xor.b32  	%r1766, %r1758, %r1713;
	prmt.b32 	%r1767, %r1766, %r34, %r63;
	xor.b32  	%r1768, %r1765, %r1674;
	prmt.b32 	%r1769, %r1768, %r34, %r63;
	add.s32 	%r1770, %r1677, %r1767;
	add.s32 	%r1771, %r1678, %r1769;
	xor.b32  	%r1772, %r1770, %r1682;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1772, 20;
	shr.b32 	%rhs, %r1772, 12;
	add.u32 	%r1773, %lhs, %rhs;
	}
	xor.b32  	%r1774, %r1771, %r1717;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1774, 20;
	shr.b32 	%rhs, %r1774, 12;
	add.u32 	%r1775, %lhs, %rhs;
	}
	add.s32 	%r1777, %r1773, %r1760;
	add.s32 	%r1778, %r1777, %r1758;
	add.s32 	%r1780, %r1775, %r1761;
	add.s32 	%r1781, %r1780, %r1765;
	xor.b32  	%r1782, %r1778, %r1767;
	prmt.b32 	%r1783, %r1782, %r34, %r33;
	xor.b32  	%r1784, %r1781, %r1769;
	prmt.b32 	%r1785, %r1784, %r34, %r33;
	add.s32 	%r1786, %r1770, %r1783;
	add.s32 	%r1787, %r1771, %r1785;
	xor.b32  	%r1788, %r1786, %r1773;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1788, 25;
	shr.b32 	%rhs, %r1788, 7;
	add.u32 	%r1789, %lhs, %rhs;
	}
	xor.b32  	%r1790, %r1787, %r1775;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1790, 25;
	shr.b32 	%rhs, %r1790, 7;
	add.u32 	%r1791, %lhs, %rhs;
	}
	add.s32 	%r1793, %r1755, %r1762;
	add.s32 	%r1794, %r1793, %r1742;
	ld.const.v4.u32 	{%r1795, %r1796, %r1797, %r1798}, [c_xors+768];
	xor.b32  	%r1800, %r1795, %r2;
	add.s32 	%r1801, %r1800, %r1789;
	add.s32 	%r1802, %r1801, %r1745;
	xor.b32  	%r1803, %r1794, %r1785;
	prmt.b32 	%r1804, %r1803, %r34, %r63;
	xor.b32  	%r1805, %r1802, %r1747;
	prmt.b32 	%r1806, %r1805, %r34, %r63;
	add.s32 	%r1807, %r1786, %r1804;
	add.s32 	%r1808, %r1787, %r1806;
	xor.b32  	%r1809, %r1807, %r1755;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1809, 20;
	shr.b32 	%rhs, %r1809, 12;
	add.u32 	%r1810, %lhs, %rhs;
	}
	xor.b32  	%r1811, %r1808, %r1789;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1811, 20;
	shr.b32 	%rhs, %r1811, 12;
	add.u32 	%r1812, %lhs, %rhs;
	}
	add.s32 	%r1814, %r1810, %r1796;
	add.s32 	%r1815, %r1814, %r1794;
	add.s32 	%r1817, %r1812, %r1797;
	add.s32 	%r1818, %r1817, %r1802;
	xor.b32  	%r1819, %r1815, %r1804;
	prmt.b32 	%r1820, %r1819, %r34, %r33;
	xor.b32  	%r1821, %r1818, %r1806;
	prmt.b32 	%r1822, %r1821, %r34, %r33;
	add.s32 	%r1823, %r1807, %r1820;
	add.s32 	%r1824, %r1808, %r1822;
	xor.b32  	%r1825, %r1823, %r1810;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1825, 25;
	shr.b32 	%rhs, %r1825, 7;
	add.u32 	%r1826, %lhs, %rhs;
	}
	xor.b32  	%r1827, %r1824, %r1812;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1827, 25;
	shr.b32 	%rhs, %r1827, 7;
	add.u32 	%r1828, %lhs, %rhs;
	}
	add.s32 	%r1830, %r1791, %r1798;
	add.s32 	%r1831, %r1830, %r1778;
	ld.const.v4.u32 	{%r1832, %r1833, %r1834, %r1835}, [c_xors+784];
	add.s32 	%r1837, %r1753, %r1832;
	add.s32 	%r1838, %r1837, %r1781;
	xor.b32  	%r1839, %r1831, %r1749;
	prmt.b32 	%r1840, %r1839, %r34, %r63;
	xor.b32  	%r1841, %r1838, %r1783;
	prmt.b32 	%r1842, %r1841, %r34, %r63;
	add.s32 	%r1843, %r1750, %r1840;
	add.s32 	%r1844, %r1751, %r1842;
	xor.b32  	%r1845, %r1843, %r1791;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1845, 20;
	shr.b32 	%rhs, %r1845, 12;
	add.u32 	%r1846, %lhs, %rhs;
	}
	xor.b32  	%r1847, %r1844, %r1753;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1847, 20;
	shr.b32 	%rhs, %r1847, 12;
	add.u32 	%r1848, %lhs, %rhs;
	}
	add.s32 	%r1850, %r1846, %r1833;
	add.s32 	%r1851, %r1850, %r1831;
	add.s32 	%r1853, %r1848, %r1834;
	add.s32 	%r1854, %r1853, %r1838;
	xor.b32  	%r1855, %r1851, %r1840;
	prmt.b32 	%r1856, %r1855, %r34, %r33;
	xor.b32  	%r1857, %r1854, %r1842;
	prmt.b32 	%r1858, %r1857, %r34, %r33;
	add.s32 	%r1859, %r1843, %r1856;
	add.s32 	%r1860, %r1844, %r1858;
	xor.b32  	%r1861, %r1859, %r1846;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1861, 25;
	shr.b32 	%rhs, %r1861, 7;
	add.u32 	%r1862, %lhs, %rhs;
	}
	xor.b32  	%r1863, %r1860, %r1848;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1863, 25;
	shr.b32 	%rhs, %r1863, 7;
	add.u32 	%r1864, %lhs, %rhs;
	}
	add.s32 	%r1866, %r1815, %r1835;
	add.s32 	%r1867, %r1866, %r1864;
	ld.const.v4.u32 	{%r1868, %r1869, %r1870, %r1871}, [c_xors+800];
	xor.b32  	%r1873, %r1868, %r2;
	add.s32 	%r1874, %r1873, %r1826;
	add.s32 	%r1875, %r1874, %r1818;
	xor.b32  	%r1876, %r1867, %r1822;
	prmt.b32 	%r1877, %r1876, %r34, %r63;
	xor.b32  	%r1878, %r1875, %r1856;
	prmt.b32 	%r1879, %r1878, %r34, %r63;
	add.s32 	%r1880, %r1859, %r1877;
	add.s32 	%r1881, %r1860, %r1879;
	xor.b32  	%r1882, %r1880, %r1864;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1882, 20;
	shr.b32 	%rhs, %r1882, 12;
	add.u32 	%r1883, %lhs, %rhs;
	}
	xor.b32  	%r1884, %r1881, %r1826;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1884, 20;
	shr.b32 	%rhs, %r1884, 12;
	add.u32 	%r1885, %lhs, %rhs;
	}
	add.s32 	%r1887, %r1883, %r1869;
	add.s32 	%r1888, %r1887, %r1867;
	add.s32 	%r1890, %r1885, %r1870;
	add.s32 	%r1891, %r1890, %r1875;
	xor.b32  	%r1892, %r1888, %r1877;
	prmt.b32 	%r1893, %r1892, %r34, %r33;
	xor.b32  	%r1894, %r1891, %r1879;
	prmt.b32 	%r1895, %r1894, %r34, %r33;
	add.s32 	%r1896, %r1880, %r1893;
	add.s32 	%r3, %r1881, %r1895;
	xor.b32  	%r1897, %r1896, %r1883;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1897, 25;
	shr.b32 	%rhs, %r1897, 7;
	add.u32 	%r4, %lhs, %rhs;
	}
	xor.b32  	%r1898, %r3, %r1885;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1898, 25;
	shr.b32 	%rhs, %r1898, 7;
	add.u32 	%r1899, %lhs, %rhs;
	}
	add.s32 	%r1901, %r1828, %r1871;
	add.s32 	%r1902, %r1901, %r1851;
	ld.const.v4.u32 	{%r1903, %r1904, %r1905, %r1906}, [c_xors+816];
	add.s32 	%r1908, %r1862, %r1903;
	add.s32 	%r1909, %r1908, %r1854;
	xor.b32  	%r1910, %r1902, %r1858;
	prmt.b32 	%r1911, %r1910, %r34, %r63;
	xor.b32  	%r1912, %r1909, %r1820;
	prmt.b32 	%r1913, %r1912, %r34, %r63;
	add.s32 	%r1914, %r1823, %r1911;
	add.s32 	%r1915, %r1824, %r1913;
	xor.b32  	%r1916, %r1914, %r1828;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1916, 20;
	shr.b32 	%rhs, %r1916, 12;
	add.u32 	%r1917, %lhs, %rhs;
	}
	xor.b32  	%r1918, %r1915, %r1862;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1918, 20;
	shr.b32 	%rhs, %r1918, 12;
	add.u32 	%r1919, %lhs, %rhs;
	}
	add.s32 	%r1921, %r1917, %r1904;
	add.s32 	%r1922, %r1921, %r1902;
	add.s32 	%r1924, %r1919, %r1905;
	add.s32 	%r5, %r1924, %r1909;
	xor.b32  	%r1925, %r1922, %r1911;
	prmt.b32 	%r6, %r1925, %r34, %r33;
	xor.b32  	%r1926, %r5, %r1913;
	prmt.b32 	%r1927, %r1926, %r34, %r33;
	add.s32 	%r1928, %r1914, %r6;
	add.s32 	%r1929, %r1915, %r1927;
	xor.b32  	%r1930, %r1928, %r1917;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1930, 25;
	shr.b32 	%rhs, %r1930, 7;
	add.u32 	%r1931, %lhs, %rhs;
	}
	xor.b32  	%r1932, %r1929, %r1919;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1932, 25;
	shr.b32 	%rhs, %r1932, 7;
	add.u32 	%r1933, %lhs, %rhs;
	}
	add.s32 	%r1935, %r1899, %r1906;
	add.s32 	%r1936, %r1935, %r1888;
	ld.const.v4.u32 	{%r1937, %r1938, %r1939, %r1940}, [c_xors+832];
	add.s32 	%r1942, %r1931, %r1937;
	add.s32 	%r1943, %r1942, %r1891;
	xor.b32  	%r1944, %r1936, %r1927;
	prmt.b32 	%r1945, %r1944, %r34, %r63;
	xor.b32  	%r1946, %r1943, %r1893;
	prmt.b32 	%r1947, %r1946, %r34, %r63;
	add.s32 	%r1948, %r1928, %r1945;
	add.s32 	%r1949, %r1929, %r1947;
	xor.b32  	%r1950, %r1948, %r1899;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1950, 20;
	shr.b32 	%rhs, %r1950, 12;
	add.u32 	%r1951, %lhs, %rhs;
	}
	xor.b32  	%r1952, %r1949, %r1931;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1952, 20;
	shr.b32 	%rhs, %r1952, 12;
	add.u32 	%r1953, %lhs, %rhs;
	}
	add.s32 	%r1955, %r1951, %r1938;
	add.s32 	%r1956, %r1955, %r1936;
	add.s32 	%r1958, %r1953, %r1939;
	add.s32 	%r1959, %r1958, %r1943;
	xor.b32  	%r1960, %r1956, %r1945;
	prmt.b32 	%r1961, %r1960, %r34, %r33;
	xor.b32  	%r1962, %r1959, %r1947;
	prmt.b32 	%r1963, %r1962, %r34, %r33;
	add.s32 	%r1964, %r1949, %r1963;
	xor.b32  	%r7, %r1964, %r1953;
	add.s32 	%r1966, %r1933, %r1940;
	add.s32 	%r1967, %r1966, %r1922;
	xor.b32  	%r1968, %r1895, %r1967;
	prmt.b32 	%r1969, %r1968, %r34, %r63;
	add.s32 	%r1970, %r1896, %r1969;
	xor.b32  	%r1971, %r1933, %r1970;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1971, 20;
	shr.b32 	%rhs, %r1971, 12;
	add.u32 	%r1972, %lhs, %rhs;
	}
	ld.const.u64 	%rd2, [c_xors+848];
	cvt.u32.u64	%r1973, %rd2;
	add.s32 	%r1974, %r1967, %r1973;
	add.s32 	%r1975, %r1974, %r1972;
	xor.b32  	%r1976, %r1975, %r1969;
	prmt.b32 	%r1977, %r1976, %r34, %r33;
	add.s32 	%r1978, %r1970, %r1977;
	xor.b32  	%r1979, %r1972, %r1978;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1979, 25;
	shr.b32 	%rhs, %r1979, 7;
	add.u32 	%r1980, %lhs, %rhs;
	}
	ld.const.u32 	%r1981, [c_h+4];
	xor.b32  	%r1982, %r1961, %r1981;
	setp.ne.s32	%p2, %r1982, %r1980;
	@%p2 bra 	BB0_4;

	ld.param.u32 	%r2007, [_Z21decred_gpu_hash_noncejjPjj_param_3];
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r7, 25;
	shr.b32 	%rhs, %r7, 7;
	add.u32 	%r1983, %lhs, %rhs;
	}
	shr.u64 	%rd4, %rd2, 32;
	cvt.u32.u64	%r1984, %rd4;
	add.s32 	%r1985, %r4, %r1984;
	add.s32 	%r1986, %r1985, %r5;
	xor.b32  	%r1987, %r6, %r1986;
	prmt.b32 	%r1990, %r1987, %r34, %r63;
	add.s32 	%r1991, %r3, %r1990;
	xor.b32  	%r1992, %r4, %r1991;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1992, 20;
	shr.b32 	%rhs, %r1992, 12;
	add.u32 	%r1993, %lhs, %rhs;
	}
	ld.const.u32 	%r1994, [c_xors+856];
	add.s32 	%r1995, %r1986, %r1994;
	add.s32 	%r1996, %r1995, %r1993;
	xor.b32  	%r1997, %r1996, %r1990;
	prmt.b32 	%r1999, %r1997, %r34, %r33;
	ld.const.u32 	%r2000, [c_h];
	xor.b32  	%r2001, %r2000, %r1999;
	xor.b32  	%r2002, %r2001, %r1983;
	mov.u32 	%r2003, 291;
	prmt.b32 	%r2004, %r2002, %r2002, %r2003;
	setp.gt.u32	%p3, %r2004, %r2007;
	@%p3 bra 	BB0_4;

	ld.param.u64 	%rd8, [_Z21decred_gpu_hash_noncejjPjj_param_2];
	cvta.to.global.u64 	%rd7, %rd8;
	atom.global.inc.u32 	%r2005, [%rd7], -1;
	add.s32 	%r2006, %r2005, 1;
	mul.wide.u32 	%rd5, %r2006, 4;
	add.s64 	%rd6, %rd7, %rd5;
	st.global.u32 	[%rd6], %r2;

BB0_4:
	ret;
}


