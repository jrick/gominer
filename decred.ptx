//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19856038
// Cuda compilation tools, release 7.5, V7.5.17
// Based on LLVM 3.4svn
//

.version 4.3
.target sm_20
.address_size 64

	// .globl	decred_gpu_hash_nonce
.const .align 16 .b8 c_h[8];
.const .align 16 .b8 c_data[128];
.const .align 16 .b8 c_xors[860];

.visible .entry decred_gpu_hash_nonce(
	.param .u32 decred_gpu_hash_nonce_param_0,
	.param .u32 decred_gpu_hash_nonce_param_1,
	.param .u64 decred_gpu_hash_nonce_param_2,
	.param .u32 decred_gpu_hash_nonce_param_3
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<1961>;
	.reg .b64 	%rd<6>;


	ld.param.u32 	%r4, [decred_gpu_hash_nonce_param_0];
	ld.param.u32 	%r3, [decred_gpu_hash_nonce_param_1];
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %ntid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r1, %r5, %r6, %r7;
	setp.ge.u32	%p1, %r1, %r4;
	@%p1 bra 	BB0_3;

	ld.const.v4.u32 	{%r8, %r9, %r10, %r11}, [c_data];
	add.s32 	%r2, %r1, %r3;
	xor.b32  	%r16, %r2, 320440878;
	add.s32 	%r17, %r9, %r16;
	ld.const.v4.u32 	{%r18, %r19, %r20, %r21}, [c_data+48];
	xor.b32  	%r26, %r19, %r17;
	mov.u32 	%r27, 801;
	mov.u32 	%r28, 0;
	prmt.b32 	%r29, %r26, %r28, %r27;
	ld.const.v4.u32 	{%r30, %r31, %r32, %r33}, [c_data+32];
	add.s32 	%r38, %r31, %r29;
	ld.const.v4.u32 	{%r39, %r40, %r41, %r42}, [c_data+16];
	xor.b32  	%r47, %r40, %r38;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r47, 25;
	shr.b32 	%rhs, %r47, 7;
	add.u32 	%r48, %lhs, %rhs;
	}
	ld.const.v4.u32 	{%r49, %r50, %r51, %r52}, [c_xors];
	add.s32 	%r54, %r17, %r49;
	add.s32 	%r55, %r8, %r48;
	xor.b32  	%r56, %r54, %r18;
	mov.u32 	%r57, 4146;
	prmt.b32 	%r58, %r56, %r28, %r57;
	xor.b32  	%r59, %r55, %r21;
	prmt.b32 	%r60, %r59, %r28, %r57;
	add.s32 	%r61, %r33, %r58;
	add.s32 	%r62, %r32, %r60;
	xor.b32  	%r63, %r61, %r41;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r63, 20;
	shr.b32 	%rhs, %r63, 12;
	add.u32 	%r64, %lhs, %rhs;
	}
	xor.b32  	%r65, %r62, %r48;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r65, 20;
	shr.b32 	%rhs, %r65, 12;
	add.u32 	%r66, %lhs, %rhs;
	}
	add.s32 	%r68, %r64, %r50;
	add.s32 	%r69, %r68, %r54;
	add.s32 	%r71, %r66, %r51;
	add.s32 	%r72, %r71, %r55;
	xor.b32  	%r73, %r69, %r58;
	prmt.b32 	%r74, %r73, %r28, %r27;
	xor.b32  	%r75, %r72, %r60;
	prmt.b32 	%r76, %r75, %r28, %r27;
	add.s32 	%r77, %r61, %r74;
	add.s32 	%r78, %r62, %r76;
	xor.b32  	%r79, %r77, %r64;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r79, 25;
	shr.b32 	%rhs, %r79, 7;
	add.u32 	%r80, %lhs, %rhs;
	}
	xor.b32  	%r81, %r78, %r66;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r81, 25;
	shr.b32 	%rhs, %r81, 7;
	add.u32 	%r82, %lhs, %rhs;
	}
	add.s32 	%r84, %r42, %r52;
	add.s32 	%r85, %r84, %r10;
	ld.const.v4.u32 	{%r86, %r87, %r88, %r89}, [c_xors+16];
	add.s32 	%r91, %r39, %r86;
	add.s32 	%r92, %r91, %r11;
	xor.b32  	%r93, %r85, %r29;
	prmt.b32 	%r94, %r93, %r28, %r57;
	xor.b32  	%r95, %r92, %r20;
	prmt.b32 	%r96, %r95, %r28, %r57;
	add.s32 	%r97, %r30, %r94;
	add.s32 	%r98, %r38, %r96;
	xor.b32  	%r99, %r97, %r42;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r99, 20;
	shr.b32 	%rhs, %r99, 12;
	add.u32 	%r100, %lhs, %rhs;
	}
	xor.b32  	%r101, %r98, %r39;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r101, 20;
	shr.b32 	%rhs, %r101, 12;
	add.u32 	%r102, %lhs, %rhs;
	}
	add.s32 	%r104, %r100, %r87;
	add.s32 	%r105, %r104, %r85;
	add.s32 	%r107, %r102, %r88;
	add.s32 	%r108, %r107, %r92;
	xor.b32  	%r109, %r105, %r94;
	prmt.b32 	%r110, %r109, %r28, %r27;
	xor.b32  	%r111, %r108, %r96;
	prmt.b32 	%r112, %r111, %r28, %r27;
	add.s32 	%r113, %r97, %r110;
	add.s32 	%r114, %r98, %r112;
	xor.b32  	%r115, %r113, %r100;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r115, 25;
	shr.b32 	%rhs, %r115, 7;
	add.u32 	%r116, %lhs, %rhs;
	}
	xor.b32  	%r117, %r114, %r102;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r117, 25;
	shr.b32 	%rhs, %r117, 7;
	add.u32 	%r118, %lhs, %rhs;
	}
	add.s32 	%r120, %r72, %r89;
	add.s32 	%r121, %r120, %r118;
	ld.const.v4.u32 	{%r122, %r123, %r124, %r125}, [c_xors+32];
	add.s32 	%r127, %r82, %r122;
	add.s32 	%r128, %r127, %r69;
	xor.b32  	%r129, %r121, %r74;
	prmt.b32 	%r130, %r129, %r28, %r57;
	xor.b32  	%r131, %r128, %r110;
	prmt.b32 	%r132, %r131, %r28, %r57;
	add.s32 	%r133, %r113, %r130;
	add.s32 	%r134, %r114, %r132;
	xor.b32  	%r135, %r133, %r118;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r135, 20;
	shr.b32 	%rhs, %r135, 12;
	add.u32 	%r136, %lhs, %rhs;
	}
	xor.b32  	%r137, %r134, %r82;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r137, 20;
	shr.b32 	%rhs, %r137, 12;
	add.u32 	%r138, %lhs, %rhs;
	}
	add.s32 	%r140, %r136, %r123;
	add.s32 	%r141, %r140, %r121;
	add.s32 	%r143, %r138, %r124;
	add.s32 	%r144, %r143, %r128;
	xor.b32  	%r145, %r141, %r130;
	prmt.b32 	%r146, %r145, %r28, %r27;
	xor.b32  	%r147, %r144, %r132;
	prmt.b32 	%r148, %r147, %r28, %r27;
	add.s32 	%r149, %r133, %r146;
	add.s32 	%r150, %r134, %r148;
	xor.b32  	%r151, %r149, %r136;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r151, 25;
	shr.b32 	%rhs, %r151, 7;
	add.u32 	%r152, %lhs, %rhs;
	}
	xor.b32  	%r153, %r150, %r138;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r153, 25;
	shr.b32 	%rhs, %r153, 7;
	add.u32 	%r154, %lhs, %rhs;
	}
	add.s32 	%r156, %r80, %r125;
	add.s32 	%r157, %r156, %r105;
	ld.const.v4.u32 	{%r158, %r159, %r160, %r161}, [c_xors+48];
	add.s32 	%r163, %r116, %r158;
	add.s32 	%r164, %r163, %r108;
	xor.b32  	%r165, %r157, %r112;
	prmt.b32 	%r166, %r165, %r28, %r57;
	xor.b32  	%r167, %r164, %r76;
	prmt.b32 	%r168, %r167, %r28, %r57;
	add.s32 	%r169, %r78, %r166;
	add.s32 	%r170, %r77, %r168;
	xor.b32  	%r171, %r169, %r80;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r171, 20;
	shr.b32 	%rhs, %r171, 12;
	add.u32 	%r172, %lhs, %rhs;
	}
	xor.b32  	%r173, %r170, %r116;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r173, 20;
	shr.b32 	%rhs, %r173, 12;
	add.u32 	%r174, %lhs, %rhs;
	}
	add.s32 	%r176, %r172, %r159;
	add.s32 	%r177, %r176, %r157;
	add.s32 	%r179, %r174, %r160;
	add.s32 	%r180, %r179, %r164;
	xor.b32  	%r181, %r177, %r166;
	prmt.b32 	%r182, %r181, %r28, %r27;
	xor.b32  	%r183, %r180, %r168;
	prmt.b32 	%r184, %r183, %r28, %r27;
	add.s32 	%r185, %r169, %r182;
	add.s32 	%r186, %r170, %r184;
	xor.b32  	%r187, %r185, %r172;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r187, 25;
	shr.b32 	%rhs, %r187, 7;
	add.u32 	%r188, %lhs, %rhs;
	}
	xor.b32  	%r189, %r186, %r174;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r189, 25;
	shr.b32 	%rhs, %r189, 7;
	add.u32 	%r190, %lhs, %rhs;
	}
	add.s32 	%r192, %r154, %r161;
	add.s32 	%r193, %r192, %r141;
	ld.const.v4.u32 	{%r194, %r195, %r196, %r197}, [c_xors+64];
	add.s32 	%r199, %r188, %r194;
	add.s32 	%r200, %r199, %r144;
	xor.b32  	%r201, %r193, %r184;
	prmt.b32 	%r202, %r201, %r28, %r57;
	xor.b32  	%r203, %r200, %r146;
	prmt.b32 	%r204, %r203, %r28, %r57;
	add.s32 	%r205, %r185, %r202;
	add.s32 	%r206, %r186, %r204;
	xor.b32  	%r207, %r205, %r154;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r207, 20;
	shr.b32 	%rhs, %r207, 12;
	add.u32 	%r208, %lhs, %rhs;
	}
	xor.b32  	%r209, %r206, %r188;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r209, 20;
	shr.b32 	%rhs, %r209, 12;
	add.u32 	%r210, %lhs, %rhs;
	}
	add.s32 	%r212, %r208, %r195;
	add.s32 	%r213, %r212, %r193;
	add.s32 	%r215, %r210, %r196;
	add.s32 	%r216, %r215, %r200;
	xor.b32  	%r217, %r213, %r202;
	prmt.b32 	%r218, %r217, %r28, %r27;
	xor.b32  	%r219, %r216, %r204;
	prmt.b32 	%r220, %r219, %r28, %r27;
	add.s32 	%r221, %r205, %r218;
	add.s32 	%r222, %r206, %r220;
	xor.b32  	%r223, %r221, %r208;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r223, 25;
	shr.b32 	%rhs, %r223, 7;
	add.u32 	%r224, %lhs, %rhs;
	}
	xor.b32  	%r225, %r222, %r210;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r225, 25;
	shr.b32 	%rhs, %r225, 7;
	add.u32 	%r226, %lhs, %rhs;
	}
	add.s32 	%r228, %r190, %r197;
	add.s32 	%r229, %r228, %r177;
	ld.const.v4.u32 	{%r230, %r231, %r232, %r233}, [c_xors+80];
	add.s32 	%r235, %r152, %r230;
	add.s32 	%r236, %r235, %r180;
	xor.b32  	%r237, %r229, %r148;
	prmt.b32 	%r238, %r237, %r28, %r57;
	xor.b32  	%r239, %r236, %r182;
	prmt.b32 	%r240, %r239, %r28, %r57;
	add.s32 	%r241, %r149, %r238;
	add.s32 	%r242, %r150, %r240;
	xor.b32  	%r243, %r241, %r190;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r243, 20;
	shr.b32 	%rhs, %r243, 12;
	add.u32 	%r244, %lhs, %rhs;
	}
	xor.b32  	%r245, %r242, %r152;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r245, 20;
	shr.b32 	%rhs, %r245, 12;
	add.u32 	%r246, %lhs, %rhs;
	}
	add.s32 	%r248, %r244, %r231;
	add.s32 	%r249, %r248, %r229;
	xor.b32  	%r251, %r232, %r2;
	add.s32 	%r252, %r251, %r246;
	add.s32 	%r253, %r252, %r236;
	xor.b32  	%r254, %r249, %r238;
	prmt.b32 	%r255, %r254, %r28, %r27;
	xor.b32  	%r256, %r253, %r240;
	prmt.b32 	%r257, %r256, %r28, %r27;
	add.s32 	%r258, %r241, %r255;
	add.s32 	%r259, %r242, %r257;
	xor.b32  	%r260, %r258, %r244;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r260, 25;
	shr.b32 	%rhs, %r260, 7;
	add.u32 	%r261, %lhs, %rhs;
	}
	xor.b32  	%r262, %r259, %r246;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r262, 25;
	shr.b32 	%rhs, %r262, 7;
	add.u32 	%r263, %lhs, %rhs;
	}
	add.s32 	%r265, %r213, %r233;
	add.s32 	%r266, %r265, %r263;
	ld.const.v4.u32 	{%r267, %r268, %r269, %r270}, [c_xors+96];
	add.s32 	%r272, %r224, %r267;
	add.s32 	%r273, %r272, %r216;
	xor.b32  	%r274, %r266, %r220;
	prmt.b32 	%r275, %r274, %r28, %r57;
	xor.b32  	%r276, %r273, %r255;
	prmt.b32 	%r277, %r276, %r28, %r57;
	add.s32 	%r278, %r258, %r275;
	add.s32 	%r279, %r259, %r277;
	xor.b32  	%r280, %r278, %r263;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r280, 20;
	shr.b32 	%rhs, %r280, 12;
	add.u32 	%r281, %lhs, %rhs;
	}
	xor.b32  	%r282, %r279, %r224;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r282, 20;
	shr.b32 	%rhs, %r282, 12;
	add.u32 	%r283, %lhs, %rhs;
	}
	add.s32 	%r285, %r281, %r268;
	add.s32 	%r286, %r285, %r266;
	add.s32 	%r288, %r283, %r269;
	add.s32 	%r289, %r288, %r273;
	xor.b32  	%r290, %r286, %r275;
	prmt.b32 	%r291, %r290, %r28, %r27;
	xor.b32  	%r292, %r289, %r277;
	prmt.b32 	%r293, %r292, %r28, %r27;
	add.s32 	%r294, %r278, %r291;
	add.s32 	%r295, %r279, %r293;
	xor.b32  	%r296, %r294, %r281;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r296, 25;
	shr.b32 	%rhs, %r296, 7;
	add.u32 	%r297, %lhs, %rhs;
	}
	xor.b32  	%r298, %r295, %r283;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r298, 25;
	shr.b32 	%rhs, %r298, 7;
	add.u32 	%r299, %lhs, %rhs;
	}
	add.s32 	%r301, %r226, %r270;
	add.s32 	%r302, %r301, %r249;
	ld.const.v4.u32 	{%r303, %r304, %r305, %r306}, [c_xors+112];
	add.s32 	%r308, %r261, %r303;
	add.s32 	%r309, %r308, %r253;
	xor.b32  	%r310, %r302, %r257;
	prmt.b32 	%r311, %r310, %r28, %r57;
	xor.b32  	%r312, %r309, %r218;
	prmt.b32 	%r313, %r312, %r28, %r57;
	add.s32 	%r314, %r221, %r311;
	add.s32 	%r315, %r222, %r313;
	xor.b32  	%r316, %r314, %r226;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r316, 20;
	shr.b32 	%rhs, %r316, 12;
	add.u32 	%r317, %lhs, %rhs;
	}
	xor.b32  	%r318, %r315, %r261;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r318, 20;
	shr.b32 	%rhs, %r318, 12;
	add.u32 	%r319, %lhs, %rhs;
	}
	add.s32 	%r321, %r317, %r304;
	add.s32 	%r322, %r321, %r302;
	add.s32 	%r324, %r319, %r305;
	add.s32 	%r325, %r324, %r309;
	xor.b32  	%r326, %r322, %r311;
	prmt.b32 	%r327, %r326, %r28, %r27;
	xor.b32  	%r328, %r325, %r313;
	prmt.b32 	%r329, %r328, %r28, %r27;
	add.s32 	%r330, %r314, %r327;
	add.s32 	%r331, %r315, %r329;
	xor.b32  	%r332, %r330, %r317;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r332, 25;
	shr.b32 	%rhs, %r332, 7;
	add.u32 	%r333, %lhs, %rhs;
	}
	xor.b32  	%r334, %r331, %r319;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r334, 25;
	shr.b32 	%rhs, %r334, 7;
	add.u32 	%r335, %lhs, %rhs;
	}
	add.s32 	%r337, %r299, %r306;
	add.s32 	%r338, %r337, %r286;
	ld.const.v4.u32 	{%r339, %r340, %r341, %r342}, [c_xors+128];
	xor.b32  	%r344, %r339, %r2;
	add.s32 	%r345, %r344, %r333;
	add.s32 	%r346, %r345, %r289;
	xor.b32  	%r347, %r338, %r329;
	prmt.b32 	%r348, %r347, %r28, %r57;
	xor.b32  	%r349, %r346, %r291;
	prmt.b32 	%r350, %r349, %r28, %r57;
	add.s32 	%r351, %r330, %r348;
	add.s32 	%r352, %r331, %r350;
	xor.b32  	%r353, %r351, %r299;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r353, 20;
	shr.b32 	%rhs, %r353, 12;
	add.u32 	%r354, %lhs, %rhs;
	}
	xor.b32  	%r355, %r352, %r333;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r355, 20;
	shr.b32 	%rhs, %r355, 12;
	add.u32 	%r356, %lhs, %rhs;
	}
	add.s32 	%r358, %r354, %r340;
	add.s32 	%r359, %r358, %r338;
	add.s32 	%r361, %r356, %r341;
	add.s32 	%r362, %r361, %r346;
	xor.b32  	%r363, %r359, %r348;
	prmt.b32 	%r364, %r363, %r28, %r27;
	xor.b32  	%r365, %r362, %r350;
	prmt.b32 	%r366, %r365, %r28, %r27;
	add.s32 	%r367, %r351, %r364;
	add.s32 	%r368, %r352, %r366;
	xor.b32  	%r369, %r367, %r354;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r369, 25;
	shr.b32 	%rhs, %r369, 7;
	add.u32 	%r370, %lhs, %rhs;
	}
	xor.b32  	%r371, %r368, %r356;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r371, 25;
	shr.b32 	%rhs, %r371, 7;
	add.u32 	%r372, %lhs, %rhs;
	}
	add.s32 	%r374, %r335, %r342;
	add.s32 	%r375, %r374, %r322;
	ld.const.v4.u32 	{%r376, %r377, %r378, %r379}, [c_xors+144];
	add.s32 	%r381, %r297, %r376;
	add.s32 	%r382, %r381, %r325;
	xor.b32  	%r383, %r375, %r293;
	prmt.b32 	%r384, %r383, %r28, %r57;
	xor.b32  	%r385, %r382, %r327;
	prmt.b32 	%r386, %r385, %r28, %r57;
	add.s32 	%r387, %r294, %r384;
	add.s32 	%r388, %r295, %r386;
	xor.b32  	%r389, %r387, %r335;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r389, 20;
	shr.b32 	%rhs, %r389, 12;
	add.u32 	%r390, %lhs, %rhs;
	}
	xor.b32  	%r391, %r388, %r297;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r391, 20;
	shr.b32 	%rhs, %r391, 12;
	add.u32 	%r392, %lhs, %rhs;
	}
	add.s32 	%r394, %r390, %r377;
	add.s32 	%r395, %r394, %r375;
	add.s32 	%r397, %r392, %r378;
	add.s32 	%r398, %r397, %r382;
	xor.b32  	%r399, %r395, %r384;
	prmt.b32 	%r400, %r399, %r28, %r27;
	xor.b32  	%r401, %r398, %r386;
	prmt.b32 	%r402, %r401, %r28, %r27;
	add.s32 	%r403, %r387, %r400;
	add.s32 	%r404, %r388, %r402;
	xor.b32  	%r405, %r403, %r390;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r405, 25;
	shr.b32 	%rhs, %r405, 7;
	add.u32 	%r406, %lhs, %rhs;
	}
	xor.b32  	%r407, %r404, %r392;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r407, 25;
	shr.b32 	%rhs, %r407, 7;
	add.u32 	%r408, %lhs, %rhs;
	}
	add.s32 	%r410, %r359, %r379;
	add.s32 	%r411, %r410, %r408;
	ld.const.v4.u32 	{%r412, %r413, %r414, %r415}, [c_xors+160];
	xor.b32  	%r417, %r412, %r2;
	add.s32 	%r418, %r417, %r370;
	add.s32 	%r419, %r418, %r362;
	xor.b32  	%r420, %r411, %r366;
	prmt.b32 	%r421, %r420, %r28, %r57;
	xor.b32  	%r422, %r419, %r400;
	prmt.b32 	%r423, %r422, %r28, %r57;
	add.s32 	%r424, %r403, %r421;
	add.s32 	%r425, %r404, %r423;
	xor.b32  	%r426, %r424, %r408;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r426, 20;
	shr.b32 	%rhs, %r426, 12;
	add.u32 	%r427, %lhs, %rhs;
	}
	xor.b32  	%r428, %r425, %r370;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r428, 20;
	shr.b32 	%rhs, %r428, 12;
	add.u32 	%r429, %lhs, %rhs;
	}
	add.s32 	%r431, %r427, %r413;
	add.s32 	%r432, %r431, %r411;
	add.s32 	%r434, %r429, %r414;
	add.s32 	%r435, %r434, %r419;
	xor.b32  	%r436, %r432, %r421;
	prmt.b32 	%r437, %r436, %r28, %r27;
	xor.b32  	%r438, %r435, %r423;
	prmt.b32 	%r439, %r438, %r28, %r27;
	add.s32 	%r440, %r424, %r437;
	add.s32 	%r441, %r425, %r439;
	xor.b32  	%r442, %r440, %r427;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r442, 25;
	shr.b32 	%rhs, %r442, 7;
	add.u32 	%r443, %lhs, %rhs;
	}
	xor.b32  	%r444, %r441, %r429;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r444, 25;
	shr.b32 	%rhs, %r444, 7;
	add.u32 	%r445, %lhs, %rhs;
	}
	add.s32 	%r447, %r372, %r415;
	add.s32 	%r448, %r447, %r395;
	ld.const.v4.u32 	{%r449, %r450, %r451, %r452}, [c_xors+176];
	add.s32 	%r454, %r406, %r449;
	add.s32 	%r455, %r454, %r398;
	xor.b32  	%r456, %r448, %r402;
	prmt.b32 	%r457, %r456, %r28, %r57;
	xor.b32  	%r458, %r455, %r364;
	prmt.b32 	%r459, %r458, %r28, %r57;
	add.s32 	%r460, %r367, %r457;
	add.s32 	%r461, %r368, %r459;
	xor.b32  	%r462, %r460, %r372;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r462, 20;
	shr.b32 	%rhs, %r462, 12;
	add.u32 	%r463, %lhs, %rhs;
	}
	xor.b32  	%r464, %r461, %r406;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r464, 20;
	shr.b32 	%rhs, %r464, 12;
	add.u32 	%r465, %lhs, %rhs;
	}
	add.s32 	%r467, %r463, %r450;
	add.s32 	%r468, %r467, %r448;
	add.s32 	%r470, %r465, %r451;
	add.s32 	%r471, %r470, %r455;
	xor.b32  	%r472, %r468, %r457;
	prmt.b32 	%r473, %r472, %r28, %r27;
	xor.b32  	%r474, %r471, %r459;
	prmt.b32 	%r475, %r474, %r28, %r27;
	add.s32 	%r476, %r460, %r473;
	add.s32 	%r477, %r461, %r475;
	xor.b32  	%r478, %r476, %r463;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r478, 25;
	shr.b32 	%rhs, %r478, 7;
	add.u32 	%r479, %lhs, %rhs;
	}
	xor.b32  	%r480, %r477, %r465;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r480, 25;
	shr.b32 	%rhs, %r480, 7;
	add.u32 	%r481, %lhs, %rhs;
	}
	add.s32 	%r483, %r445, %r452;
	add.s32 	%r484, %r483, %r432;
	ld.const.v4.u32 	{%r485, %r486, %r487, %r488}, [c_xors+192];
	add.s32 	%r490, %r479, %r485;
	add.s32 	%r491, %r490, %r435;
	xor.b32  	%r492, %r484, %r475;
	prmt.b32 	%r493, %r492, %r28, %r57;
	xor.b32  	%r494, %r491, %r437;
	prmt.b32 	%r495, %r494, %r28, %r57;
	add.s32 	%r496, %r476, %r493;
	add.s32 	%r497, %r477, %r495;
	xor.b32  	%r498, %r496, %r445;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r498, 20;
	shr.b32 	%rhs, %r498, 12;
	add.u32 	%r499, %lhs, %rhs;
	}
	xor.b32  	%r500, %r497, %r479;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r500, 20;
	shr.b32 	%rhs, %r500, 12;
	add.u32 	%r501, %lhs, %rhs;
	}
	add.s32 	%r503, %r499, %r486;
	add.s32 	%r504, %r503, %r484;
	add.s32 	%r506, %r501, %r487;
	add.s32 	%r507, %r506, %r491;
	xor.b32  	%r508, %r504, %r493;
	prmt.b32 	%r509, %r508, %r28, %r27;
	xor.b32  	%r510, %r507, %r495;
	prmt.b32 	%r511, %r510, %r28, %r27;
	add.s32 	%r512, %r496, %r509;
	add.s32 	%r513, %r497, %r511;
	xor.b32  	%r514, %r512, %r499;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r514, 25;
	shr.b32 	%rhs, %r514, 7;
	add.u32 	%r515, %lhs, %rhs;
	}
	xor.b32  	%r516, %r513, %r501;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r516, 25;
	shr.b32 	%rhs, %r516, 7;
	add.u32 	%r517, %lhs, %rhs;
	}
	add.s32 	%r519, %r481, %r488;
	add.s32 	%r520, %r519, %r468;
	ld.const.v4.u32 	{%r521, %r522, %r523, %r524}, [c_xors+208];
	add.s32 	%r526, %r443, %r521;
	add.s32 	%r527, %r526, %r471;
	xor.b32  	%r528, %r520, %r439;
	prmt.b32 	%r529, %r528, %r28, %r57;
	xor.b32  	%r530, %r527, %r473;
	prmt.b32 	%r531, %r530, %r28, %r57;
	add.s32 	%r532, %r440, %r529;
	add.s32 	%r533, %r441, %r531;
	xor.b32  	%r534, %r532, %r481;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r534, 20;
	shr.b32 	%rhs, %r534, 12;
	add.u32 	%r535, %lhs, %rhs;
	}
	xor.b32  	%r536, %r533, %r443;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r536, 20;
	shr.b32 	%rhs, %r536, 12;
	add.u32 	%r537, %lhs, %rhs;
	}
	add.s32 	%r539, %r535, %r522;
	add.s32 	%r540, %r539, %r520;
	add.s32 	%r542, %r537, %r523;
	add.s32 	%r543, %r542, %r527;
	xor.b32  	%r544, %r540, %r529;
	prmt.b32 	%r545, %r544, %r28, %r27;
	xor.b32  	%r546, %r543, %r531;
	prmt.b32 	%r547, %r546, %r28, %r27;
	add.s32 	%r548, %r532, %r545;
	add.s32 	%r549, %r533, %r547;
	xor.b32  	%r550, %r548, %r535;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r550, 25;
	shr.b32 	%rhs, %r550, 7;
	add.u32 	%r551, %lhs, %rhs;
	}
	xor.b32  	%r552, %r549, %r537;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r552, 25;
	shr.b32 	%rhs, %r552, 7;
	add.u32 	%r553, %lhs, %rhs;
	}
	add.s32 	%r555, %r504, %r524;
	add.s32 	%r556, %r555, %r553;
	ld.const.v4.u32 	{%r557, %r558, %r559, %r560}, [c_xors+224];
	add.s32 	%r562, %r515, %r557;
	add.s32 	%r563, %r562, %r507;
	xor.b32  	%r564, %r556, %r511;
	prmt.b32 	%r565, %r564, %r28, %r57;
	xor.b32  	%r566, %r563, %r545;
	prmt.b32 	%r567, %r566, %r28, %r57;
	add.s32 	%r568, %r548, %r565;
	add.s32 	%r569, %r549, %r567;
	xor.b32  	%r570, %r568, %r553;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r570, 20;
	shr.b32 	%rhs, %r570, 12;
	add.u32 	%r571, %lhs, %rhs;
	}
	xor.b32  	%r572, %r569, %r515;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r572, 20;
	shr.b32 	%rhs, %r572, 12;
	add.u32 	%r573, %lhs, %rhs;
	}
	add.s32 	%r575, %r571, %r558;
	add.s32 	%r576, %r575, %r556;
	add.s32 	%r578, %r573, %r559;
	add.s32 	%r579, %r578, %r563;
	xor.b32  	%r580, %r576, %r565;
	prmt.b32 	%r581, %r580, %r28, %r27;
	xor.b32  	%r582, %r579, %r567;
	prmt.b32 	%r583, %r582, %r28, %r27;
	add.s32 	%r584, %r568, %r581;
	add.s32 	%r585, %r569, %r583;
	xor.b32  	%r586, %r584, %r571;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r586, 25;
	shr.b32 	%rhs, %r586, 7;
	add.u32 	%r587, %lhs, %rhs;
	}
	xor.b32  	%r588, %r585, %r573;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r588, 25;
	shr.b32 	%rhs, %r588, 7;
	add.u32 	%r589, %lhs, %rhs;
	}
	add.s32 	%r591, %r517, %r560;
	add.s32 	%r592, %r591, %r540;
	ld.const.v4.u32 	{%r593, %r594, %r595, %r596}, [c_xors+240];
	add.s32 	%r598, %r551, %r593;
	add.s32 	%r599, %r598, %r543;
	xor.b32  	%r600, %r592, %r547;
	prmt.b32 	%r601, %r600, %r28, %r57;
	xor.b32  	%r602, %r599, %r509;
	prmt.b32 	%r603, %r602, %r28, %r57;
	add.s32 	%r604, %r512, %r601;
	add.s32 	%r605, %r513, %r603;
	xor.b32  	%r606, %r604, %r517;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r606, 20;
	shr.b32 	%rhs, %r606, 12;
	add.u32 	%r607, %lhs, %rhs;
	}
	xor.b32  	%r608, %r605, %r551;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r608, 20;
	shr.b32 	%rhs, %r608, 12;
	add.u32 	%r609, %lhs, %rhs;
	}
	add.s32 	%r611, %r607, %r594;
	add.s32 	%r612, %r611, %r592;
	add.s32 	%r614, %r609, %r595;
	add.s32 	%r615, %r614, %r599;
	xor.b32  	%r616, %r612, %r601;
	prmt.b32 	%r617, %r616, %r28, %r27;
	xor.b32  	%r618, %r615, %r603;
	prmt.b32 	%r619, %r618, %r28, %r27;
	add.s32 	%r620, %r604, %r617;
	add.s32 	%r621, %r605, %r619;
	xor.b32  	%r622, %r620, %r607;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r622, 25;
	shr.b32 	%rhs, %r622, 7;
	add.u32 	%r623, %lhs, %rhs;
	}
	xor.b32  	%r624, %r621, %r609;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r624, 25;
	shr.b32 	%rhs, %r624, 7;
	add.u32 	%r625, %lhs, %rhs;
	}
	add.s32 	%r627, %r589, %r596;
	add.s32 	%r628, %r627, %r576;
	ld.const.v4.u32 	{%r629, %r630, %r631, %r632}, [c_xors+256];
	add.s32 	%r634, %r623, %r629;
	add.s32 	%r635, %r634, %r579;
	xor.b32  	%r636, %r628, %r619;
	prmt.b32 	%r637, %r636, %r28, %r57;
	xor.b32  	%r638, %r635, %r581;
	prmt.b32 	%r639, %r638, %r28, %r57;
	add.s32 	%r640, %r620, %r637;
	add.s32 	%r641, %r621, %r639;
	xor.b32  	%r642, %r640, %r589;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r642, 20;
	shr.b32 	%rhs, %r642, 12;
	add.u32 	%r643, %lhs, %rhs;
	}
	xor.b32  	%r644, %r641, %r623;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r644, 20;
	shr.b32 	%rhs, %r644, 12;
	add.u32 	%r645, %lhs, %rhs;
	}
	add.s32 	%r647, %r643, %r630;
	add.s32 	%r648, %r647, %r628;
	add.s32 	%r650, %r645, %r631;
	add.s32 	%r651, %r650, %r635;
	xor.b32  	%r652, %r648, %r637;
	prmt.b32 	%r653, %r652, %r28, %r27;
	xor.b32  	%r654, %r651, %r639;
	prmt.b32 	%r655, %r654, %r28, %r27;
	add.s32 	%r656, %r640, %r653;
	add.s32 	%r657, %r641, %r655;
	xor.b32  	%r658, %r656, %r643;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r658, 25;
	shr.b32 	%rhs, %r658, 7;
	add.u32 	%r659, %lhs, %rhs;
	}
	xor.b32  	%r660, %r657, %r645;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r660, 25;
	shr.b32 	%rhs, %r660, 7;
	add.u32 	%r661, %lhs, %rhs;
	}
	add.s32 	%r663, %r625, %r632;
	add.s32 	%r664, %r663, %r612;
	ld.const.v4.u32 	{%r665, %r666, %r667, %r668}, [c_xors+272];
	xor.b32  	%r670, %r665, %r2;
	add.s32 	%r671, %r670, %r587;
	add.s32 	%r672, %r671, %r615;
	xor.b32  	%r673, %r664, %r583;
	prmt.b32 	%r674, %r673, %r28, %r57;
	xor.b32  	%r675, %r672, %r617;
	prmt.b32 	%r676, %r675, %r28, %r57;
	add.s32 	%r677, %r584, %r674;
	add.s32 	%r678, %r585, %r676;
	xor.b32  	%r679, %r677, %r625;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r679, 20;
	shr.b32 	%rhs, %r679, 12;
	add.u32 	%r680, %lhs, %rhs;
	}
	xor.b32  	%r681, %r678, %r587;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r681, 20;
	shr.b32 	%rhs, %r681, 12;
	add.u32 	%r682, %lhs, %rhs;
	}
	add.s32 	%r684, %r680, %r666;
	add.s32 	%r685, %r684, %r664;
	add.s32 	%r687, %r682, %r667;
	add.s32 	%r688, %r687, %r672;
	xor.b32  	%r689, %r685, %r674;
	prmt.b32 	%r690, %r689, %r28, %r27;
	xor.b32  	%r691, %r688, %r676;
	prmt.b32 	%r692, %r691, %r28, %r27;
	add.s32 	%r693, %r677, %r690;
	add.s32 	%r694, %r678, %r692;
	xor.b32  	%r695, %r693, %r680;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r695, 25;
	shr.b32 	%rhs, %r695, 7;
	add.u32 	%r696, %lhs, %rhs;
	}
	xor.b32  	%r697, %r694, %r682;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r697, 25;
	shr.b32 	%rhs, %r697, 7;
	add.u32 	%r698, %lhs, %rhs;
	}
	add.s32 	%r700, %r648, %r668;
	add.s32 	%r701, %r700, %r698;
	ld.const.v4.u32 	{%r702, %r703, %r704, %r705}, [c_xors+288];
	add.s32 	%r707, %r659, %r702;
	add.s32 	%r708, %r707, %r651;
	xor.b32  	%r709, %r701, %r655;
	prmt.b32 	%r710, %r709, %r28, %r57;
	xor.b32  	%r711, %r708, %r690;
	prmt.b32 	%r712, %r711, %r28, %r57;
	add.s32 	%r713, %r693, %r710;
	add.s32 	%r714, %r694, %r712;
	xor.b32  	%r715, %r713, %r698;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r715, 20;
	shr.b32 	%rhs, %r715, 12;
	add.u32 	%r716, %lhs, %rhs;
	}
	xor.b32  	%r717, %r714, %r659;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r717, 20;
	shr.b32 	%rhs, %r717, 12;
	add.u32 	%r718, %lhs, %rhs;
	}
	add.s32 	%r720, %r716, %r703;
	add.s32 	%r721, %r720, %r701;
	add.s32 	%r723, %r718, %r704;
	add.s32 	%r724, %r723, %r708;
	xor.b32  	%r725, %r721, %r710;
	prmt.b32 	%r726, %r725, %r28, %r27;
	xor.b32  	%r727, %r724, %r712;
	prmt.b32 	%r728, %r727, %r28, %r27;
	add.s32 	%r729, %r713, %r726;
	add.s32 	%r730, %r714, %r728;
	xor.b32  	%r731, %r729, %r716;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r731, 25;
	shr.b32 	%rhs, %r731, 7;
	add.u32 	%r732, %lhs, %rhs;
	}
	xor.b32  	%r733, %r730, %r718;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r733, 25;
	shr.b32 	%rhs, %r733, 7;
	add.u32 	%r734, %lhs, %rhs;
	}
	add.s32 	%r736, %r661, %r705;
	add.s32 	%r737, %r736, %r685;
	ld.const.v4.u32 	{%r738, %r739, %r740, %r741}, [c_xors+304];
	add.s32 	%r743, %r696, %r738;
	add.s32 	%r744, %r743, %r688;
	xor.b32  	%r745, %r737, %r692;
	prmt.b32 	%r746, %r745, %r28, %r57;
	xor.b32  	%r747, %r744, %r653;
	prmt.b32 	%r748, %r747, %r28, %r57;
	add.s32 	%r749, %r656, %r746;
	add.s32 	%r750, %r657, %r748;
	xor.b32  	%r751, %r749, %r661;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r751, 20;
	shr.b32 	%rhs, %r751, 12;
	add.u32 	%r752, %lhs, %rhs;
	}
	xor.b32  	%r753, %r750, %r696;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r753, 20;
	shr.b32 	%rhs, %r753, 12;
	add.u32 	%r754, %lhs, %rhs;
	}
	add.s32 	%r756, %r752, %r739;
	add.s32 	%r757, %r756, %r737;
	xor.b32  	%r759, %r740, %r2;
	add.s32 	%r760, %r759, %r754;
	add.s32 	%r761, %r760, %r744;
	xor.b32  	%r762, %r757, %r746;
	prmt.b32 	%r763, %r762, %r28, %r27;
	xor.b32  	%r764, %r761, %r748;
	prmt.b32 	%r765, %r764, %r28, %r27;
	add.s32 	%r766, %r749, %r763;
	add.s32 	%r767, %r750, %r765;
	xor.b32  	%r768, %r766, %r752;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r768, 25;
	shr.b32 	%rhs, %r768, 7;
	add.u32 	%r769, %lhs, %rhs;
	}
	xor.b32  	%r770, %r767, %r754;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r770, 25;
	shr.b32 	%rhs, %r770, 7;
	add.u32 	%r771, %lhs, %rhs;
	}
	add.s32 	%r773, %r734, %r741;
	add.s32 	%r774, %r773, %r721;
	ld.const.v4.u32 	{%r775, %r776, %r777, %r778}, [c_xors+320];
	add.s32 	%r780, %r769, %r775;
	add.s32 	%r781, %r780, %r724;
	xor.b32  	%r782, %r774, %r765;
	prmt.b32 	%r783, %r782, %r28, %r57;
	xor.b32  	%r784, %r781, %r726;
	prmt.b32 	%r785, %r784, %r28, %r57;
	add.s32 	%r786, %r766, %r783;
	add.s32 	%r787, %r767, %r785;
	xor.b32  	%r788, %r786, %r734;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r788, 20;
	shr.b32 	%rhs, %r788, 12;
	add.u32 	%r789, %lhs, %rhs;
	}
	xor.b32  	%r790, %r787, %r769;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r790, 20;
	shr.b32 	%rhs, %r790, 12;
	add.u32 	%r791, %lhs, %rhs;
	}
	add.s32 	%r793, %r789, %r776;
	add.s32 	%r794, %r793, %r774;
	add.s32 	%r796, %r791, %r777;
	add.s32 	%r797, %r796, %r781;
	xor.b32  	%r798, %r794, %r783;
	prmt.b32 	%r799, %r798, %r28, %r27;
	xor.b32  	%r800, %r797, %r785;
	prmt.b32 	%r801, %r800, %r28, %r27;
	add.s32 	%r802, %r786, %r799;
	add.s32 	%r803, %r787, %r801;
	xor.b32  	%r804, %r802, %r789;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r804, 25;
	shr.b32 	%rhs, %r804, 7;
	add.u32 	%r805, %lhs, %rhs;
	}
	xor.b32  	%r806, %r803, %r791;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r806, 25;
	shr.b32 	%rhs, %r806, 7;
	add.u32 	%r807, %lhs, %rhs;
	}
	add.s32 	%r809, %r771, %r778;
	add.s32 	%r810, %r809, %r757;
	ld.const.v4.u32 	{%r811, %r812, %r813, %r814}, [c_xors+336];
	add.s32 	%r816, %r732, %r811;
	add.s32 	%r817, %r816, %r761;
	xor.b32  	%r818, %r810, %r728;
	prmt.b32 	%r819, %r818, %r28, %r57;
	xor.b32  	%r820, %r817, %r763;
	prmt.b32 	%r821, %r820, %r28, %r57;
	add.s32 	%r822, %r729, %r819;
	add.s32 	%r823, %r730, %r821;
	xor.b32  	%r824, %r822, %r771;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r824, 20;
	shr.b32 	%rhs, %r824, 12;
	add.u32 	%r825, %lhs, %rhs;
	}
	xor.b32  	%r826, %r823, %r732;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r826, 20;
	shr.b32 	%rhs, %r826, 12;
	add.u32 	%r827, %lhs, %rhs;
	}
	add.s32 	%r829, %r825, %r812;
	add.s32 	%r830, %r829, %r810;
	add.s32 	%r832, %r827, %r813;
	add.s32 	%r833, %r832, %r817;
	xor.b32  	%r834, %r830, %r819;
	prmt.b32 	%r835, %r834, %r28, %r27;
	xor.b32  	%r836, %r833, %r821;
	prmt.b32 	%r837, %r836, %r28, %r27;
	add.s32 	%r838, %r822, %r835;
	add.s32 	%r839, %r823, %r837;
	xor.b32  	%r840, %r838, %r825;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r840, 25;
	shr.b32 	%rhs, %r840, 7;
	add.u32 	%r841, %lhs, %rhs;
	}
	xor.b32  	%r842, %r839, %r827;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r842, 25;
	shr.b32 	%rhs, %r842, 7;
	add.u32 	%r843, %lhs, %rhs;
	}
	add.s32 	%r845, %r794, %r814;
	add.s32 	%r846, %r845, %r843;
	ld.const.v4.u32 	{%r847, %r848, %r849, %r850}, [c_xors+352];
	add.s32 	%r852, %r805, %r847;
	add.s32 	%r853, %r852, %r797;
	xor.b32  	%r854, %r846, %r801;
	prmt.b32 	%r855, %r854, %r28, %r57;
	xor.b32  	%r856, %r853, %r835;
	prmt.b32 	%r857, %r856, %r28, %r57;
	add.s32 	%r858, %r838, %r855;
	add.s32 	%r859, %r839, %r857;
	xor.b32  	%r860, %r858, %r843;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r860, 20;
	shr.b32 	%rhs, %r860, 12;
	add.u32 	%r861, %lhs, %rhs;
	}
	xor.b32  	%r862, %r859, %r805;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r862, 20;
	shr.b32 	%rhs, %r862, 12;
	add.u32 	%r863, %lhs, %rhs;
	}
	add.s32 	%r865, %r861, %r848;
	add.s32 	%r866, %r865, %r846;
	add.s32 	%r868, %r863, %r849;
	add.s32 	%r869, %r868, %r853;
	xor.b32  	%r870, %r866, %r855;
	prmt.b32 	%r871, %r870, %r28, %r27;
	xor.b32  	%r872, %r869, %r857;
	prmt.b32 	%r873, %r872, %r28, %r27;
	add.s32 	%r874, %r858, %r871;
	add.s32 	%r875, %r859, %r873;
	xor.b32  	%r876, %r874, %r861;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r876, 25;
	shr.b32 	%rhs, %r876, 7;
	add.u32 	%r877, %lhs, %rhs;
	}
	xor.b32  	%r878, %r875, %r863;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r878, 25;
	shr.b32 	%rhs, %r878, 7;
	add.u32 	%r879, %lhs, %rhs;
	}
	add.s32 	%r881, %r807, %r850;
	add.s32 	%r882, %r881, %r830;
	ld.const.v4.u32 	{%r883, %r884, %r885, %r886}, [c_xors+368];
	add.s32 	%r888, %r841, %r883;
	add.s32 	%r889, %r888, %r833;
	xor.b32  	%r890, %r882, %r837;
	prmt.b32 	%r891, %r890, %r28, %r57;
	xor.b32  	%r892, %r889, %r799;
	prmt.b32 	%r893, %r892, %r28, %r57;
	add.s32 	%r894, %r802, %r891;
	add.s32 	%r895, %r803, %r893;
	xor.b32  	%r896, %r894, %r807;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r896, 20;
	shr.b32 	%rhs, %r896, 12;
	add.u32 	%r897, %lhs, %rhs;
	}
	xor.b32  	%r898, %r895, %r841;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r898, 20;
	shr.b32 	%rhs, %r898, 12;
	add.u32 	%r899, %lhs, %rhs;
	}
	add.s32 	%r901, %r897, %r884;
	add.s32 	%r902, %r901, %r882;
	add.s32 	%r904, %r899, %r885;
	add.s32 	%r905, %r904, %r889;
	xor.b32  	%r906, %r902, %r891;
	prmt.b32 	%r907, %r906, %r28, %r27;
	xor.b32  	%r908, %r905, %r893;
	prmt.b32 	%r909, %r908, %r28, %r27;
	add.s32 	%r910, %r894, %r907;
	add.s32 	%r911, %r895, %r909;
	xor.b32  	%r912, %r910, %r897;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r912, 25;
	shr.b32 	%rhs, %r912, 7;
	add.u32 	%r913, %lhs, %rhs;
	}
	xor.b32  	%r914, %r911, %r899;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r914, 25;
	shr.b32 	%rhs, %r914, 7;
	add.u32 	%r915, %lhs, %rhs;
	}
	add.s32 	%r917, %r879, %r886;
	add.s32 	%r918, %r917, %r866;
	ld.const.v4.u32 	{%r919, %r920, %r921, %r922}, [c_xors+384];
	add.s32 	%r924, %r913, %r919;
	add.s32 	%r925, %r924, %r869;
	xor.b32  	%r926, %r918, %r909;
	prmt.b32 	%r927, %r926, %r28, %r57;
	xor.b32  	%r928, %r925, %r871;
	prmt.b32 	%r929, %r928, %r28, %r57;
	add.s32 	%r930, %r910, %r927;
	add.s32 	%r931, %r911, %r929;
	xor.b32  	%r932, %r930, %r879;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r932, 20;
	shr.b32 	%rhs, %r932, 12;
	add.u32 	%r933, %lhs, %rhs;
	}
	xor.b32  	%r934, %r931, %r913;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r934, 20;
	shr.b32 	%rhs, %r934, 12;
	add.u32 	%r935, %lhs, %rhs;
	}
	add.s32 	%r937, %r933, %r920;
	add.s32 	%r938, %r937, %r918;
	xor.b32  	%r940, %r921, %r2;
	add.s32 	%r941, %r940, %r935;
	add.s32 	%r942, %r941, %r925;
	xor.b32  	%r943, %r938, %r927;
	prmt.b32 	%r944, %r943, %r28, %r27;
	xor.b32  	%r945, %r942, %r929;
	prmt.b32 	%r946, %r945, %r28, %r27;
	add.s32 	%r947, %r930, %r944;
	add.s32 	%r948, %r931, %r946;
	xor.b32  	%r949, %r947, %r933;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r949, 25;
	shr.b32 	%rhs, %r949, 7;
	add.u32 	%r950, %lhs, %rhs;
	}
	xor.b32  	%r951, %r948, %r935;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r951, 25;
	shr.b32 	%rhs, %r951, 7;
	add.u32 	%r952, %lhs, %rhs;
	}
	add.s32 	%r954, %r915, %r922;
	add.s32 	%r955, %r954, %r902;
	ld.const.v4.u32 	{%r956, %r957, %r958, %r959}, [c_xors+400];
	add.s32 	%r961, %r877, %r956;
	add.s32 	%r962, %r961, %r905;
	xor.b32  	%r963, %r955, %r873;
	prmt.b32 	%r964, %r963, %r28, %r57;
	xor.b32  	%r965, %r962, %r907;
	prmt.b32 	%r966, %r965, %r28, %r57;
	add.s32 	%r967, %r874, %r964;
	add.s32 	%r968, %r875, %r966;
	xor.b32  	%r969, %r967, %r915;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r969, 20;
	shr.b32 	%rhs, %r969, 12;
	add.u32 	%r970, %lhs, %rhs;
	}
	xor.b32  	%r971, %r968, %r877;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r971, 20;
	shr.b32 	%rhs, %r971, 12;
	add.u32 	%r972, %lhs, %rhs;
	}
	add.s32 	%r974, %r970, %r957;
	add.s32 	%r975, %r974, %r955;
	add.s32 	%r977, %r972, %r958;
	add.s32 	%r978, %r977, %r962;
	xor.b32  	%r979, %r975, %r964;
	prmt.b32 	%r980, %r979, %r28, %r27;
	xor.b32  	%r981, %r978, %r966;
	prmt.b32 	%r982, %r981, %r28, %r27;
	add.s32 	%r983, %r967, %r980;
	add.s32 	%r984, %r968, %r982;
	xor.b32  	%r985, %r983, %r970;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r985, 25;
	shr.b32 	%rhs, %r985, 7;
	add.u32 	%r986, %lhs, %rhs;
	}
	xor.b32  	%r987, %r984, %r972;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r987, 25;
	shr.b32 	%rhs, %r987, 7;
	add.u32 	%r988, %lhs, %rhs;
	}
	add.s32 	%r990, %r938, %r959;
	add.s32 	%r991, %r990, %r988;
	ld.const.v4.u32 	{%r992, %r993, %r994, %r995}, [c_xors+416];
	add.s32 	%r997, %r950, %r992;
	add.s32 	%r998, %r997, %r942;
	xor.b32  	%r999, %r991, %r946;
	prmt.b32 	%r1000, %r999, %r28, %r57;
	xor.b32  	%r1001, %r998, %r980;
	prmt.b32 	%r1002, %r1001, %r28, %r57;
	add.s32 	%r1003, %r983, %r1000;
	add.s32 	%r1004, %r984, %r1002;
	xor.b32  	%r1005, %r1003, %r988;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1005, 20;
	shr.b32 	%rhs, %r1005, 12;
	add.u32 	%r1006, %lhs, %rhs;
	}
	xor.b32  	%r1007, %r1004, %r950;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1007, 20;
	shr.b32 	%rhs, %r1007, 12;
	add.u32 	%r1008, %lhs, %rhs;
	}
	add.s32 	%r1010, %r1006, %r993;
	add.s32 	%r1011, %r1010, %r991;
	add.s32 	%r1013, %r1008, %r994;
	add.s32 	%r1014, %r1013, %r998;
	xor.b32  	%r1015, %r1011, %r1000;
	prmt.b32 	%r1016, %r1015, %r28, %r27;
	xor.b32  	%r1017, %r1014, %r1002;
	prmt.b32 	%r1018, %r1017, %r28, %r27;
	add.s32 	%r1019, %r1003, %r1016;
	add.s32 	%r1020, %r1004, %r1018;
	xor.b32  	%r1021, %r1019, %r1006;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1021, 25;
	shr.b32 	%rhs, %r1021, 7;
	add.u32 	%r1022, %lhs, %rhs;
	}
	xor.b32  	%r1023, %r1020, %r1008;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1023, 25;
	shr.b32 	%rhs, %r1023, 7;
	add.u32 	%r1024, %lhs, %rhs;
	}
	add.s32 	%r1026, %r952, %r995;
	add.s32 	%r1027, %r1026, %r975;
	ld.const.v4.u32 	{%r1028, %r1029, %r1030, %r1031}, [c_xors+432];
	xor.b32  	%r1033, %r1028, %r2;
	add.s32 	%r1034, %r1033, %r986;
	add.s32 	%r1035, %r1034, %r978;
	xor.b32  	%r1036, %r1027, %r982;
	prmt.b32 	%r1037, %r1036, %r28, %r57;
	xor.b32  	%r1038, %r1035, %r944;
	prmt.b32 	%r1039, %r1038, %r28, %r57;
	add.s32 	%r1040, %r947, %r1037;
	add.s32 	%r1041, %r948, %r1039;
	xor.b32  	%r1042, %r1040, %r952;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1042, 20;
	shr.b32 	%rhs, %r1042, 12;
	add.u32 	%r1043, %lhs, %rhs;
	}
	xor.b32  	%r1044, %r1041, %r986;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1044, 20;
	shr.b32 	%rhs, %r1044, 12;
	add.u32 	%r1045, %lhs, %rhs;
	}
	add.s32 	%r1047, %r1043, %r1029;
	add.s32 	%r1048, %r1047, %r1027;
	add.s32 	%r1050, %r1045, %r1030;
	add.s32 	%r1051, %r1050, %r1035;
	xor.b32  	%r1052, %r1048, %r1037;
	prmt.b32 	%r1053, %r1052, %r28, %r27;
	xor.b32  	%r1054, %r1051, %r1039;
	prmt.b32 	%r1055, %r1054, %r28, %r27;
	add.s32 	%r1056, %r1040, %r1053;
	add.s32 	%r1057, %r1041, %r1055;
	xor.b32  	%r1058, %r1056, %r1043;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1058, 25;
	shr.b32 	%rhs, %r1058, 7;
	add.u32 	%r1059, %lhs, %rhs;
	}
	xor.b32  	%r1060, %r1057, %r1045;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1060, 25;
	shr.b32 	%rhs, %r1060, 7;
	add.u32 	%r1061, %lhs, %rhs;
	}
	add.s32 	%r1063, %r1024, %r1031;
	add.s32 	%r1064, %r1063, %r1011;
	ld.const.v4.u32 	{%r1065, %r1066, %r1067, %r1068}, [c_xors+448];
	add.s32 	%r1070, %r1059, %r1065;
	add.s32 	%r1071, %r1070, %r1014;
	xor.b32  	%r1072, %r1064, %r1055;
	prmt.b32 	%r1073, %r1072, %r28, %r57;
	xor.b32  	%r1074, %r1071, %r1016;
	prmt.b32 	%r1075, %r1074, %r28, %r57;
	add.s32 	%r1076, %r1056, %r1073;
	add.s32 	%r1077, %r1057, %r1075;
	xor.b32  	%r1078, %r1076, %r1024;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1078, 20;
	shr.b32 	%rhs, %r1078, 12;
	add.u32 	%r1079, %lhs, %rhs;
	}
	xor.b32  	%r1080, %r1077, %r1059;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1080, 20;
	shr.b32 	%rhs, %r1080, 12;
	add.u32 	%r1081, %lhs, %rhs;
	}
	add.s32 	%r1083, %r1079, %r1066;
	add.s32 	%r1084, %r1083, %r1064;
	add.s32 	%r1086, %r1081, %r1067;
	add.s32 	%r1087, %r1086, %r1071;
	xor.b32  	%r1088, %r1084, %r1073;
	prmt.b32 	%r1089, %r1088, %r28, %r27;
	xor.b32  	%r1090, %r1087, %r1075;
	prmt.b32 	%r1091, %r1090, %r28, %r27;
	add.s32 	%r1092, %r1076, %r1089;
	add.s32 	%r1093, %r1077, %r1091;
	xor.b32  	%r1094, %r1092, %r1079;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1094, 25;
	shr.b32 	%rhs, %r1094, 7;
	add.u32 	%r1095, %lhs, %rhs;
	}
	xor.b32  	%r1096, %r1093, %r1081;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1096, 25;
	shr.b32 	%rhs, %r1096, 7;
	add.u32 	%r1097, %lhs, %rhs;
	}
	add.s32 	%r1099, %r1061, %r1068;
	add.s32 	%r1100, %r1099, %r1048;
	ld.const.v4.u32 	{%r1101, %r1102, %r1103, %r1104}, [c_xors+464];
	add.s32 	%r1106, %r1022, %r1101;
	add.s32 	%r1107, %r1106, %r1051;
	xor.b32  	%r1108, %r1100, %r1018;
	prmt.b32 	%r1109, %r1108, %r28, %r57;
	xor.b32  	%r1110, %r1107, %r1053;
	prmt.b32 	%r1111, %r1110, %r28, %r57;
	add.s32 	%r1112, %r1019, %r1109;
	add.s32 	%r1113, %r1020, %r1111;
	xor.b32  	%r1114, %r1112, %r1061;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1114, 20;
	shr.b32 	%rhs, %r1114, 12;
	add.u32 	%r1115, %lhs, %rhs;
	}
	xor.b32  	%r1116, %r1113, %r1022;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1116, 20;
	shr.b32 	%rhs, %r1116, 12;
	add.u32 	%r1117, %lhs, %rhs;
	}
	add.s32 	%r1119, %r1115, %r1102;
	add.s32 	%r1120, %r1119, %r1100;
	add.s32 	%r1122, %r1117, %r1103;
	add.s32 	%r1123, %r1122, %r1107;
	xor.b32  	%r1124, %r1120, %r1109;
	prmt.b32 	%r1125, %r1124, %r28, %r27;
	xor.b32  	%r1126, %r1123, %r1111;
	prmt.b32 	%r1127, %r1126, %r28, %r27;
	add.s32 	%r1128, %r1112, %r1125;
	add.s32 	%r1129, %r1113, %r1127;
	xor.b32  	%r1130, %r1128, %r1115;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1130, 25;
	shr.b32 	%rhs, %r1130, 7;
	add.u32 	%r1131, %lhs, %rhs;
	}
	xor.b32  	%r1132, %r1129, %r1117;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1132, 25;
	shr.b32 	%rhs, %r1132, 7;
	add.u32 	%r1133, %lhs, %rhs;
	}
	add.s32 	%r1135, %r1084, %r1104;
	add.s32 	%r1136, %r1135, %r1133;
	ld.const.v4.u32 	{%r1137, %r1138, %r1139, %r1140}, [c_xors+480];
	add.s32 	%r1142, %r1095, %r1137;
	add.s32 	%r1143, %r1142, %r1087;
	xor.b32  	%r1144, %r1136, %r1091;
	prmt.b32 	%r1145, %r1144, %r28, %r57;
	xor.b32  	%r1146, %r1143, %r1125;
	prmt.b32 	%r1147, %r1146, %r28, %r57;
	add.s32 	%r1148, %r1128, %r1145;
	add.s32 	%r1149, %r1129, %r1147;
	xor.b32  	%r1150, %r1148, %r1133;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1150, 20;
	shr.b32 	%rhs, %r1150, 12;
	add.u32 	%r1151, %lhs, %rhs;
	}
	xor.b32  	%r1152, %r1149, %r1095;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1152, 20;
	shr.b32 	%rhs, %r1152, 12;
	add.u32 	%r1153, %lhs, %rhs;
	}
	add.s32 	%r1155, %r1151, %r1138;
	add.s32 	%r1156, %r1155, %r1136;
	add.s32 	%r1158, %r1153, %r1139;
	add.s32 	%r1159, %r1158, %r1143;
	xor.b32  	%r1160, %r1156, %r1145;
	prmt.b32 	%r1161, %r1160, %r28, %r27;
	xor.b32  	%r1162, %r1159, %r1147;
	prmt.b32 	%r1163, %r1162, %r28, %r27;
	add.s32 	%r1164, %r1148, %r1161;
	add.s32 	%r1165, %r1149, %r1163;
	xor.b32  	%r1166, %r1164, %r1151;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1166, 25;
	shr.b32 	%rhs, %r1166, 7;
	add.u32 	%r1167, %lhs, %rhs;
	}
	xor.b32  	%r1168, %r1165, %r1153;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1168, 25;
	shr.b32 	%rhs, %r1168, 7;
	add.u32 	%r1169, %lhs, %rhs;
	}
	add.s32 	%r1171, %r1097, %r1140;
	add.s32 	%r1172, %r1171, %r1120;
	ld.const.v4.u32 	{%r1173, %r1174, %r1175, %r1176}, [c_xors+496];
	add.s32 	%r1178, %r1131, %r1173;
	add.s32 	%r1179, %r1178, %r1123;
	xor.b32  	%r1180, %r1172, %r1127;
	prmt.b32 	%r1181, %r1180, %r28, %r57;
	xor.b32  	%r1182, %r1179, %r1089;
	prmt.b32 	%r1183, %r1182, %r28, %r57;
	add.s32 	%r1184, %r1092, %r1181;
	add.s32 	%r1185, %r1093, %r1183;
	xor.b32  	%r1186, %r1184, %r1097;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1186, 20;
	shr.b32 	%rhs, %r1186, 12;
	add.u32 	%r1187, %lhs, %rhs;
	}
	xor.b32  	%r1188, %r1185, %r1131;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1188, 20;
	shr.b32 	%rhs, %r1188, 12;
	add.u32 	%r1189, %lhs, %rhs;
	}
	xor.b32  	%r1191, %r1174, %r2;
	add.s32 	%r1192, %r1191, %r1187;
	add.s32 	%r1193, %r1192, %r1172;
	add.s32 	%r1195, %r1189, %r1175;
	add.s32 	%r1196, %r1195, %r1179;
	xor.b32  	%r1197, %r1193, %r1181;
	prmt.b32 	%r1198, %r1197, %r28, %r27;
	xor.b32  	%r1199, %r1196, %r1183;
	prmt.b32 	%r1200, %r1199, %r28, %r27;
	add.s32 	%r1201, %r1184, %r1198;
	add.s32 	%r1202, %r1185, %r1200;
	xor.b32  	%r1203, %r1201, %r1187;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1203, 25;
	shr.b32 	%rhs, %r1203, 7;
	add.u32 	%r1204, %lhs, %rhs;
	}
	xor.b32  	%r1205, %r1202, %r1189;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1205, 25;
	shr.b32 	%rhs, %r1205, 7;
	add.u32 	%r1206, %lhs, %rhs;
	}
	add.s32 	%r1208, %r1169, %r1176;
	add.s32 	%r1209, %r1208, %r1156;
	ld.const.v4.u32 	{%r1210, %r1211, %r1212, %r1213}, [c_xors+512];
	add.s32 	%r1215, %r1204, %r1210;
	add.s32 	%r1216, %r1215, %r1159;
	xor.b32  	%r1217, %r1209, %r1200;
	prmt.b32 	%r1218, %r1217, %r28, %r57;
	xor.b32  	%r1219, %r1216, %r1161;
	prmt.b32 	%r1220, %r1219, %r28, %r57;
	add.s32 	%r1221, %r1201, %r1218;
	add.s32 	%r1222, %r1202, %r1220;
	xor.b32  	%r1223, %r1221, %r1169;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1223, 20;
	shr.b32 	%rhs, %r1223, 12;
	add.u32 	%r1224, %lhs, %rhs;
	}
	xor.b32  	%r1225, %r1222, %r1204;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1225, 20;
	shr.b32 	%rhs, %r1225, 12;
	add.u32 	%r1226, %lhs, %rhs;
	}
	add.s32 	%r1228, %r1224, %r1211;
	add.s32 	%r1229, %r1228, %r1209;
	add.s32 	%r1231, %r1226, %r1212;
	add.s32 	%r1232, %r1231, %r1216;
	xor.b32  	%r1233, %r1229, %r1218;
	prmt.b32 	%r1234, %r1233, %r28, %r27;
	xor.b32  	%r1235, %r1232, %r1220;
	prmt.b32 	%r1236, %r1235, %r28, %r27;
	add.s32 	%r1237, %r1221, %r1234;
	add.s32 	%r1238, %r1222, %r1236;
	xor.b32  	%r1239, %r1237, %r1224;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1239, 25;
	shr.b32 	%rhs, %r1239, 7;
	add.u32 	%r1240, %lhs, %rhs;
	}
	xor.b32  	%r1241, %r1238, %r1226;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1241, 25;
	shr.b32 	%rhs, %r1241, 7;
	add.u32 	%r1242, %lhs, %rhs;
	}
	add.s32 	%r1244, %r1206, %r1213;
	add.s32 	%r1245, %r1244, %r1193;
	ld.const.v4.u32 	{%r1246, %r1247, %r1248, %r1249}, [c_xors+528];
	add.s32 	%r1251, %r1167, %r1246;
	add.s32 	%r1252, %r1251, %r1196;
	xor.b32  	%r1253, %r1245, %r1163;
	prmt.b32 	%r1254, %r1253, %r28, %r57;
	xor.b32  	%r1255, %r1252, %r1198;
	prmt.b32 	%r1256, %r1255, %r28, %r57;
	add.s32 	%r1257, %r1164, %r1254;
	add.s32 	%r1258, %r1165, %r1256;
	xor.b32  	%r1259, %r1257, %r1206;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1259, 20;
	shr.b32 	%rhs, %r1259, 12;
	add.u32 	%r1260, %lhs, %rhs;
	}
	xor.b32  	%r1261, %r1258, %r1167;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1261, 20;
	shr.b32 	%rhs, %r1261, 12;
	add.u32 	%r1262, %lhs, %rhs;
	}
	add.s32 	%r1264, %r1260, %r1247;
	add.s32 	%r1265, %r1264, %r1245;
	add.s32 	%r1267, %r1262, %r1248;
	add.s32 	%r1268, %r1267, %r1252;
	xor.b32  	%r1269, %r1265, %r1254;
	prmt.b32 	%r1270, %r1269, %r28, %r27;
	xor.b32  	%r1271, %r1268, %r1256;
	prmt.b32 	%r1272, %r1271, %r28, %r27;
	add.s32 	%r1273, %r1257, %r1270;
	add.s32 	%r1274, %r1258, %r1272;
	xor.b32  	%r1275, %r1273, %r1260;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1275, 25;
	shr.b32 	%rhs, %r1275, 7;
	add.u32 	%r1276, %lhs, %rhs;
	}
	xor.b32  	%r1277, %r1274, %r1262;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1277, 25;
	shr.b32 	%rhs, %r1277, 7;
	add.u32 	%r1278, %lhs, %rhs;
	}
	add.s32 	%r1280, %r1229, %r1249;
	add.s32 	%r1281, %r1280, %r1278;
	ld.const.v4.u32 	{%r1282, %r1283, %r1284, %r1285}, [c_xors+544];
	add.s32 	%r1287, %r1240, %r1282;
	add.s32 	%r1288, %r1287, %r1232;
	xor.b32  	%r1289, %r1281, %r1236;
	prmt.b32 	%r1290, %r1289, %r28, %r57;
	xor.b32  	%r1291, %r1288, %r1270;
	prmt.b32 	%r1292, %r1291, %r28, %r57;
	add.s32 	%r1293, %r1273, %r1290;
	add.s32 	%r1294, %r1274, %r1292;
	xor.b32  	%r1295, %r1293, %r1278;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1295, 20;
	shr.b32 	%rhs, %r1295, 12;
	add.u32 	%r1296, %lhs, %rhs;
	}
	xor.b32  	%r1297, %r1294, %r1240;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1297, 20;
	shr.b32 	%rhs, %r1297, 12;
	add.u32 	%r1298, %lhs, %rhs;
	}
	add.s32 	%r1300, %r1296, %r1283;
	add.s32 	%r1301, %r1300, %r1281;
	add.s32 	%r1303, %r1298, %r1284;
	add.s32 	%r1304, %r1303, %r1288;
	xor.b32  	%r1305, %r1301, %r1290;
	prmt.b32 	%r1306, %r1305, %r28, %r27;
	xor.b32  	%r1307, %r1304, %r1292;
	prmt.b32 	%r1308, %r1307, %r28, %r27;
	add.s32 	%r1309, %r1293, %r1306;
	add.s32 	%r1310, %r1294, %r1308;
	xor.b32  	%r1311, %r1309, %r1296;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1311, 25;
	shr.b32 	%rhs, %r1311, 7;
	add.u32 	%r1312, %lhs, %rhs;
	}
	xor.b32  	%r1313, %r1310, %r1298;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1313, 25;
	shr.b32 	%rhs, %r1313, 7;
	add.u32 	%r1314, %lhs, %rhs;
	}
	add.s32 	%r1316, %r1242, %r1285;
	add.s32 	%r1317, %r1316, %r1265;
	ld.const.v4.u32 	{%r1318, %r1319, %r1320, %r1321}, [c_xors+560];
	add.s32 	%r1323, %r1276, %r1318;
	add.s32 	%r1324, %r1323, %r1268;
	xor.b32  	%r1325, %r1317, %r1272;
	prmt.b32 	%r1326, %r1325, %r28, %r57;
	xor.b32  	%r1327, %r1324, %r1234;
	prmt.b32 	%r1328, %r1327, %r28, %r57;
	add.s32 	%r1329, %r1237, %r1326;
	add.s32 	%r1330, %r1238, %r1328;
	xor.b32  	%r1331, %r1329, %r1242;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1331, 20;
	shr.b32 	%rhs, %r1331, 12;
	add.u32 	%r1332, %lhs, %rhs;
	}
	xor.b32  	%r1333, %r1330, %r1276;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1333, 20;
	shr.b32 	%rhs, %r1333, 12;
	add.u32 	%r1334, %lhs, %rhs;
	}
	add.s32 	%r1336, %r1332, %r1319;
	add.s32 	%r1337, %r1336, %r1317;
	add.s32 	%r1339, %r1334, %r1320;
	add.s32 	%r1340, %r1339, %r1324;
	xor.b32  	%r1341, %r1337, %r1326;
	prmt.b32 	%r1342, %r1341, %r28, %r27;
	xor.b32  	%r1343, %r1340, %r1328;
	prmt.b32 	%r1344, %r1343, %r28, %r27;
	add.s32 	%r1345, %r1329, %r1342;
	add.s32 	%r1346, %r1330, %r1344;
	xor.b32  	%r1347, %r1345, %r1332;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1347, 25;
	shr.b32 	%rhs, %r1347, 7;
	add.u32 	%r1348, %lhs, %rhs;
	}
	xor.b32  	%r1349, %r1346, %r1334;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1349, 25;
	shr.b32 	%rhs, %r1349, 7;
	add.u32 	%r1350, %lhs, %rhs;
	}
	add.s32 	%r1352, %r1314, %r1321;
	add.s32 	%r1353, %r1352, %r1301;
	ld.const.v4.u32 	{%r1354, %r1355, %r1356, %r1357}, [c_xors+576];
	add.s32 	%r1359, %r1348, %r1354;
	add.s32 	%r1360, %r1359, %r1304;
	xor.b32  	%r1361, %r1353, %r1344;
	prmt.b32 	%r1362, %r1361, %r28, %r57;
	xor.b32  	%r1363, %r1360, %r1306;
	prmt.b32 	%r1364, %r1363, %r28, %r57;
	add.s32 	%r1365, %r1345, %r1362;
	add.s32 	%r1366, %r1346, %r1364;
	xor.b32  	%r1367, %r1365, %r1314;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1367, 20;
	shr.b32 	%rhs, %r1367, 12;
	add.u32 	%r1368, %lhs, %rhs;
	}
	xor.b32  	%r1369, %r1366, %r1348;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1369, 20;
	shr.b32 	%rhs, %r1369, 12;
	add.u32 	%r1370, %lhs, %rhs;
	}
	add.s32 	%r1372, %r1368, %r1355;
	add.s32 	%r1373, %r1372, %r1353;
	add.s32 	%r1375, %r1370, %r1356;
	add.s32 	%r1376, %r1375, %r1360;
	xor.b32  	%r1377, %r1373, %r1362;
	prmt.b32 	%r1378, %r1377, %r28, %r27;
	xor.b32  	%r1379, %r1376, %r1364;
	prmt.b32 	%r1380, %r1379, %r28, %r27;
	add.s32 	%r1381, %r1365, %r1378;
	add.s32 	%r1382, %r1366, %r1380;
	xor.b32  	%r1383, %r1381, %r1368;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1383, 25;
	shr.b32 	%rhs, %r1383, 7;
	add.u32 	%r1384, %lhs, %rhs;
	}
	xor.b32  	%r1385, %r1382, %r1370;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1385, 25;
	shr.b32 	%rhs, %r1385, 7;
	add.u32 	%r1386, %lhs, %rhs;
	}
	xor.b32  	%r1388, %r1357, %r2;
	add.s32 	%r1389, %r1388, %r1350;
	add.s32 	%r1390, %r1389, %r1337;
	ld.const.v4.u32 	{%r1391, %r1392, %r1393, %r1394}, [c_xors+592];
	add.s32 	%r1396, %r1312, %r1391;
	add.s32 	%r1397, %r1396, %r1340;
	xor.b32  	%r1398, %r1390, %r1308;
	prmt.b32 	%r1399, %r1398, %r28, %r57;
	xor.b32  	%r1400, %r1397, %r1342;
	prmt.b32 	%r1401, %r1400, %r28, %r57;
	add.s32 	%r1402, %r1309, %r1399;
	add.s32 	%r1403, %r1310, %r1401;
	xor.b32  	%r1404, %r1402, %r1350;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1404, 20;
	shr.b32 	%rhs, %r1404, 12;
	add.u32 	%r1405, %lhs, %rhs;
	}
	xor.b32  	%r1406, %r1403, %r1312;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1406, 20;
	shr.b32 	%rhs, %r1406, 12;
	add.u32 	%r1407, %lhs, %rhs;
	}
	add.s32 	%r1409, %r1405, %r1392;
	add.s32 	%r1410, %r1409, %r1390;
	add.s32 	%r1412, %r1407, %r1393;
	add.s32 	%r1413, %r1412, %r1397;
	xor.b32  	%r1414, %r1410, %r1399;
	prmt.b32 	%r1415, %r1414, %r28, %r27;
	xor.b32  	%r1416, %r1413, %r1401;
	prmt.b32 	%r1417, %r1416, %r28, %r27;
	add.s32 	%r1418, %r1402, %r1415;
	add.s32 	%r1419, %r1403, %r1417;
	xor.b32  	%r1420, %r1418, %r1405;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1420, 25;
	shr.b32 	%rhs, %r1420, 7;
	add.u32 	%r1421, %lhs, %rhs;
	}
	xor.b32  	%r1422, %r1419, %r1407;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1422, 25;
	shr.b32 	%rhs, %r1422, 7;
	add.u32 	%r1423, %lhs, %rhs;
	}
	add.s32 	%r1425, %r1373, %r1394;
	add.s32 	%r1426, %r1425, %r1423;
	ld.const.v4.u32 	{%r1427, %r1428, %r1429, %r1430}, [c_xors+608];
	add.s32 	%r1432, %r1384, %r1427;
	add.s32 	%r1433, %r1432, %r1376;
	xor.b32  	%r1434, %r1426, %r1380;
	prmt.b32 	%r1435, %r1434, %r28, %r57;
	xor.b32  	%r1436, %r1433, %r1415;
	prmt.b32 	%r1437, %r1436, %r28, %r57;
	add.s32 	%r1438, %r1418, %r1435;
	add.s32 	%r1439, %r1419, %r1437;
	xor.b32  	%r1440, %r1438, %r1423;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1440, 20;
	shr.b32 	%rhs, %r1440, 12;
	add.u32 	%r1441, %lhs, %rhs;
	}
	xor.b32  	%r1442, %r1439, %r1384;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1442, 20;
	shr.b32 	%rhs, %r1442, 12;
	add.u32 	%r1443, %lhs, %rhs;
	}
	add.s32 	%r1445, %r1441, %r1428;
	add.s32 	%r1446, %r1445, %r1426;
	xor.b32  	%r1448, %r1429, %r2;
	add.s32 	%r1449, %r1448, %r1443;
	add.s32 	%r1450, %r1449, %r1433;
	xor.b32  	%r1451, %r1446, %r1435;
	prmt.b32 	%r1452, %r1451, %r28, %r27;
	xor.b32  	%r1453, %r1450, %r1437;
	prmt.b32 	%r1454, %r1453, %r28, %r27;
	add.s32 	%r1455, %r1438, %r1452;
	add.s32 	%r1456, %r1439, %r1454;
	xor.b32  	%r1457, %r1455, %r1441;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1457, 25;
	shr.b32 	%rhs, %r1457, 7;
	add.u32 	%r1458, %lhs, %rhs;
	}
	xor.b32  	%r1459, %r1456, %r1443;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1459, 25;
	shr.b32 	%rhs, %r1459, 7;
	add.u32 	%r1460, %lhs, %rhs;
	}
	add.s32 	%r1462, %r1386, %r1430;
	add.s32 	%r1463, %r1462, %r1410;
	ld.const.v4.u32 	{%r1464, %r1465, %r1466, %r1467}, [c_xors+624];
	add.s32 	%r1469, %r1421, %r1464;
	add.s32 	%r1470, %r1469, %r1413;
	xor.b32  	%r1471, %r1463, %r1417;
	prmt.b32 	%r1472, %r1471, %r28, %r57;
	xor.b32  	%r1473, %r1470, %r1378;
	prmt.b32 	%r1474, %r1473, %r28, %r57;
	add.s32 	%r1475, %r1381, %r1472;
	add.s32 	%r1476, %r1382, %r1474;
	xor.b32  	%r1477, %r1475, %r1386;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1477, 20;
	shr.b32 	%rhs, %r1477, 12;
	add.u32 	%r1478, %lhs, %rhs;
	}
	xor.b32  	%r1479, %r1476, %r1421;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1479, 20;
	shr.b32 	%rhs, %r1479, 12;
	add.u32 	%r1480, %lhs, %rhs;
	}
	add.s32 	%r1482, %r1478, %r1465;
	add.s32 	%r1483, %r1482, %r1463;
	add.s32 	%r1485, %r1480, %r1466;
	add.s32 	%r1486, %r1485, %r1470;
	xor.b32  	%r1487, %r1483, %r1472;
	prmt.b32 	%r1488, %r1487, %r28, %r27;
	xor.b32  	%r1489, %r1486, %r1474;
	prmt.b32 	%r1490, %r1489, %r28, %r27;
	add.s32 	%r1491, %r1475, %r1488;
	add.s32 	%r1492, %r1476, %r1490;
	xor.b32  	%r1493, %r1491, %r1478;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1493, 25;
	shr.b32 	%rhs, %r1493, 7;
	add.u32 	%r1494, %lhs, %rhs;
	}
	xor.b32  	%r1495, %r1492, %r1480;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1495, 25;
	shr.b32 	%rhs, %r1495, 7;
	add.u32 	%r1496, %lhs, %rhs;
	}
	add.s32 	%r1498, %r1460, %r1467;
	add.s32 	%r1499, %r1498, %r1446;
	ld.const.v4.u32 	{%r1500, %r1501, %r1502, %r1503}, [c_xors+640];
	add.s32 	%r1505, %r1494, %r1500;
	add.s32 	%r1506, %r1505, %r1450;
	xor.b32  	%r1507, %r1499, %r1490;
	prmt.b32 	%r1508, %r1507, %r28, %r57;
	xor.b32  	%r1509, %r1506, %r1452;
	prmt.b32 	%r1510, %r1509, %r28, %r57;
	add.s32 	%r1511, %r1491, %r1508;
	add.s32 	%r1512, %r1492, %r1510;
	xor.b32  	%r1513, %r1511, %r1460;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1513, 20;
	shr.b32 	%rhs, %r1513, 12;
	add.u32 	%r1514, %lhs, %rhs;
	}
	xor.b32  	%r1515, %r1512, %r1494;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1515, 20;
	shr.b32 	%rhs, %r1515, 12;
	add.u32 	%r1516, %lhs, %rhs;
	}
	add.s32 	%r1518, %r1514, %r1501;
	add.s32 	%r1519, %r1518, %r1499;
	add.s32 	%r1521, %r1516, %r1502;
	add.s32 	%r1522, %r1521, %r1506;
	xor.b32  	%r1523, %r1519, %r1508;
	prmt.b32 	%r1524, %r1523, %r28, %r27;
	xor.b32  	%r1525, %r1522, %r1510;
	prmt.b32 	%r1526, %r1525, %r28, %r27;
	add.s32 	%r1527, %r1511, %r1524;
	add.s32 	%r1528, %r1512, %r1526;
	xor.b32  	%r1529, %r1527, %r1514;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1529, 25;
	shr.b32 	%rhs, %r1529, 7;
	add.u32 	%r1530, %lhs, %rhs;
	}
	xor.b32  	%r1531, %r1528, %r1516;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1531, 25;
	shr.b32 	%rhs, %r1531, 7;
	add.u32 	%r1532, %lhs, %rhs;
	}
	add.s32 	%r1534, %r1496, %r1503;
	add.s32 	%r1535, %r1534, %r1483;
	ld.const.v4.u32 	{%r1536, %r1537, %r1538, %r1539}, [c_xors+656];
	add.s32 	%r1541, %r1458, %r1536;
	add.s32 	%r1542, %r1541, %r1486;
	xor.b32  	%r1543, %r1535, %r1454;
	prmt.b32 	%r1544, %r1543, %r28, %r57;
	xor.b32  	%r1545, %r1542, %r1488;
	prmt.b32 	%r1546, %r1545, %r28, %r57;
	add.s32 	%r1547, %r1455, %r1544;
	add.s32 	%r1548, %r1456, %r1546;
	xor.b32  	%r1549, %r1547, %r1496;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1549, 20;
	shr.b32 	%rhs, %r1549, 12;
	add.u32 	%r1550, %lhs, %rhs;
	}
	xor.b32  	%r1551, %r1548, %r1458;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1551, 20;
	shr.b32 	%rhs, %r1551, 12;
	add.u32 	%r1552, %lhs, %rhs;
	}
	add.s32 	%r1554, %r1550, %r1537;
	add.s32 	%r1555, %r1554, %r1535;
	add.s32 	%r1557, %r1552, %r1538;
	add.s32 	%r1558, %r1557, %r1542;
	xor.b32  	%r1559, %r1555, %r1544;
	prmt.b32 	%r1560, %r1559, %r28, %r27;
	xor.b32  	%r1561, %r1558, %r1546;
	prmt.b32 	%r1562, %r1561, %r28, %r27;
	add.s32 	%r1563, %r1547, %r1560;
	add.s32 	%r1564, %r1548, %r1562;
	xor.b32  	%r1565, %r1563, %r1550;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1565, 25;
	shr.b32 	%rhs, %r1565, 7;
	add.u32 	%r1566, %lhs, %rhs;
	}
	xor.b32  	%r1567, %r1564, %r1552;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1567, 25;
	shr.b32 	%rhs, %r1567, 7;
	add.u32 	%r1568, %lhs, %rhs;
	}
	add.s32 	%r1570, %r1519, %r1539;
	add.s32 	%r1571, %r1570, %r1568;
	ld.const.v4.u32 	{%r1572, %r1573, %r1574, %r1575}, [c_xors+672];
	add.s32 	%r1577, %r1530, %r1572;
	add.s32 	%r1578, %r1577, %r1522;
	xor.b32  	%r1579, %r1571, %r1526;
	prmt.b32 	%r1580, %r1579, %r28, %r57;
	xor.b32  	%r1581, %r1578, %r1560;
	prmt.b32 	%r1582, %r1581, %r28, %r57;
	add.s32 	%r1583, %r1563, %r1580;
	add.s32 	%r1584, %r1564, %r1582;
	xor.b32  	%r1585, %r1583, %r1568;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1585, 20;
	shr.b32 	%rhs, %r1585, 12;
	add.u32 	%r1586, %lhs, %rhs;
	}
	xor.b32  	%r1587, %r1584, %r1530;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1587, 20;
	shr.b32 	%rhs, %r1587, 12;
	add.u32 	%r1588, %lhs, %rhs;
	}
	add.s32 	%r1590, %r1586, %r1573;
	add.s32 	%r1591, %r1590, %r1571;
	add.s32 	%r1593, %r1588, %r1574;
	add.s32 	%r1594, %r1593, %r1578;
	xor.b32  	%r1595, %r1591, %r1580;
	prmt.b32 	%r1596, %r1595, %r28, %r27;
	xor.b32  	%r1597, %r1594, %r1582;
	prmt.b32 	%r1598, %r1597, %r28, %r27;
	add.s32 	%r1599, %r1583, %r1596;
	add.s32 	%r1600, %r1584, %r1598;
	xor.b32  	%r1601, %r1599, %r1586;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1601, 25;
	shr.b32 	%rhs, %r1601, 7;
	add.u32 	%r1602, %lhs, %rhs;
	}
	xor.b32  	%r1603, %r1600, %r1588;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1603, 25;
	shr.b32 	%rhs, %r1603, 7;
	add.u32 	%r1604, %lhs, %rhs;
	}
	add.s32 	%r1606, %r1532, %r1575;
	add.s32 	%r1607, %r1606, %r1555;
	ld.const.v4.u32 	{%r1608, %r1609, %r1610, %r1611}, [c_xors+688];
	add.s32 	%r1613, %r1566, %r1608;
	add.s32 	%r1614, %r1613, %r1558;
	xor.b32  	%r1615, %r1607, %r1562;
	prmt.b32 	%r1616, %r1615, %r28, %r57;
	xor.b32  	%r1617, %r1614, %r1524;
	prmt.b32 	%r1618, %r1617, %r28, %r57;
	add.s32 	%r1619, %r1527, %r1616;
	add.s32 	%r1620, %r1528, %r1618;
	xor.b32  	%r1621, %r1619, %r1532;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1621, 20;
	shr.b32 	%rhs, %r1621, 12;
	add.u32 	%r1622, %lhs, %rhs;
	}
	xor.b32  	%r1623, %r1620, %r1566;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1623, 20;
	shr.b32 	%rhs, %r1623, 12;
	add.u32 	%r1624, %lhs, %rhs;
	}
	add.s32 	%r1626, %r1622, %r1609;
	add.s32 	%r1627, %r1626, %r1607;
	add.s32 	%r1629, %r1624, %r1610;
	add.s32 	%r1630, %r1629, %r1614;
	xor.b32  	%r1631, %r1627, %r1616;
	prmt.b32 	%r1632, %r1631, %r28, %r27;
	xor.b32  	%r1633, %r1630, %r1618;
	prmt.b32 	%r1634, %r1633, %r28, %r27;
	add.s32 	%r1635, %r1619, %r1632;
	add.s32 	%r1636, %r1620, %r1634;
	xor.b32  	%r1637, %r1635, %r1622;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1637, 25;
	shr.b32 	%rhs, %r1637, 7;
	add.u32 	%r1638, %lhs, %rhs;
	}
	xor.b32  	%r1639, %r1636, %r1624;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1639, 25;
	shr.b32 	%rhs, %r1639, 7;
	add.u32 	%r1640, %lhs, %rhs;
	}
	add.s32 	%r1642, %r1604, %r1611;
	add.s32 	%r1643, %r1642, %r1591;
	ld.const.v4.u32 	{%r1644, %r1645, %r1646, %r1647}, [c_xors+704];
	add.s32 	%r1649, %r1638, %r1644;
	add.s32 	%r1650, %r1649, %r1594;
	xor.b32  	%r1651, %r1643, %r1634;
	prmt.b32 	%r1652, %r1651, %r28, %r57;
	xor.b32  	%r1653, %r1650, %r1596;
	prmt.b32 	%r1654, %r1653, %r28, %r57;
	add.s32 	%r1655, %r1635, %r1652;
	add.s32 	%r1656, %r1636, %r1654;
	xor.b32  	%r1657, %r1655, %r1604;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1657, 20;
	shr.b32 	%rhs, %r1657, 12;
	add.u32 	%r1658, %lhs, %rhs;
	}
	xor.b32  	%r1659, %r1656, %r1638;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1659, 20;
	shr.b32 	%rhs, %r1659, 12;
	add.u32 	%r1660, %lhs, %rhs;
	}
	add.s32 	%r1662, %r1658, %r1645;
	add.s32 	%r1663, %r1662, %r1643;
	add.s32 	%r1665, %r1660, %r1646;
	add.s32 	%r1666, %r1665, %r1650;
	xor.b32  	%r1667, %r1663, %r1652;
	prmt.b32 	%r1668, %r1667, %r28, %r27;
	xor.b32  	%r1669, %r1666, %r1654;
	prmt.b32 	%r1670, %r1669, %r28, %r27;
	add.s32 	%r1671, %r1655, %r1668;
	add.s32 	%r1672, %r1656, %r1670;
	xor.b32  	%r1673, %r1671, %r1658;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1673, 25;
	shr.b32 	%rhs, %r1673, 7;
	add.u32 	%r1674, %lhs, %rhs;
	}
	xor.b32  	%r1675, %r1672, %r1660;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1675, 25;
	shr.b32 	%rhs, %r1675, 7;
	add.u32 	%r1676, %lhs, %rhs;
	}
	add.s32 	%r1678, %r1640, %r1647;
	add.s32 	%r1679, %r1678, %r1627;
	ld.const.v4.u32 	{%r1680, %r1681, %r1682, %r1683}, [c_xors+720];
	add.s32 	%r1685, %r1602, %r1680;
	add.s32 	%r1686, %r1685, %r1630;
	xor.b32  	%r1687, %r1679, %r1598;
	prmt.b32 	%r1688, %r1687, %r28, %r57;
	xor.b32  	%r1689, %r1686, %r1632;
	prmt.b32 	%r1690, %r1689, %r28, %r57;
	add.s32 	%r1691, %r1599, %r1688;
	add.s32 	%r1692, %r1600, %r1690;
	xor.b32  	%r1693, %r1691, %r1640;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1693, 20;
	shr.b32 	%rhs, %r1693, 12;
	add.u32 	%r1694, %lhs, %rhs;
	}
	xor.b32  	%r1695, %r1692, %r1602;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1695, 20;
	shr.b32 	%rhs, %r1695, 12;
	add.u32 	%r1696, %lhs, %rhs;
	}
	add.s32 	%r1698, %r1694, %r1681;
	add.s32 	%r1699, %r1698, %r1679;
	xor.b32  	%r1701, %r1682, %r2;
	add.s32 	%r1702, %r1701, %r1696;
	add.s32 	%r1703, %r1702, %r1686;
	xor.b32  	%r1704, %r1699, %r1688;
	prmt.b32 	%r1705, %r1704, %r28, %r27;
	xor.b32  	%r1706, %r1703, %r1690;
	prmt.b32 	%r1707, %r1706, %r28, %r27;
	add.s32 	%r1708, %r1691, %r1705;
	add.s32 	%r1709, %r1692, %r1707;
	xor.b32  	%r1710, %r1708, %r1694;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1710, 25;
	shr.b32 	%rhs, %r1710, 7;
	add.u32 	%r1711, %lhs, %rhs;
	}
	xor.b32  	%r1712, %r1709, %r1696;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1712, 25;
	shr.b32 	%rhs, %r1712, 7;
	add.u32 	%r1713, %lhs, %rhs;
	}
	add.s32 	%r1715, %r1663, %r1683;
	add.s32 	%r1716, %r1715, %r1713;
	ld.const.v4.u32 	{%r1717, %r1718, %r1719, %r1720}, [c_xors+736];
	add.s32 	%r1722, %r1674, %r1717;
	add.s32 	%r1723, %r1722, %r1666;
	xor.b32  	%r1724, %r1716, %r1670;
	prmt.b32 	%r1725, %r1724, %r28, %r57;
	xor.b32  	%r1726, %r1723, %r1705;
	prmt.b32 	%r1727, %r1726, %r28, %r57;
	add.s32 	%r1728, %r1708, %r1725;
	add.s32 	%r1729, %r1709, %r1727;
	xor.b32  	%r1730, %r1728, %r1713;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1730, 20;
	shr.b32 	%rhs, %r1730, 12;
	add.u32 	%r1731, %lhs, %rhs;
	}
	xor.b32  	%r1732, %r1729, %r1674;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1732, 20;
	shr.b32 	%rhs, %r1732, 12;
	add.u32 	%r1733, %lhs, %rhs;
	}
	add.s32 	%r1735, %r1731, %r1718;
	add.s32 	%r1736, %r1735, %r1716;
	add.s32 	%r1738, %r1733, %r1719;
	add.s32 	%r1739, %r1738, %r1723;
	xor.b32  	%r1740, %r1736, %r1725;
	prmt.b32 	%r1741, %r1740, %r28, %r27;
	xor.b32  	%r1742, %r1739, %r1727;
	prmt.b32 	%r1743, %r1742, %r28, %r27;
	add.s32 	%r1744, %r1728, %r1741;
	add.s32 	%r1745, %r1729, %r1743;
	xor.b32  	%r1746, %r1744, %r1731;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1746, 25;
	shr.b32 	%rhs, %r1746, 7;
	add.u32 	%r1747, %lhs, %rhs;
	}
	xor.b32  	%r1748, %r1745, %r1733;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1748, 25;
	shr.b32 	%rhs, %r1748, 7;
	add.u32 	%r1749, %lhs, %rhs;
	}
	add.s32 	%r1751, %r1676, %r1720;
	add.s32 	%r1752, %r1751, %r1699;
	ld.const.v4.u32 	{%r1753, %r1754, %r1755, %r1756}, [c_xors+752];
	add.s32 	%r1758, %r1711, %r1753;
	add.s32 	%r1759, %r1758, %r1703;
	xor.b32  	%r1760, %r1752, %r1707;
	prmt.b32 	%r1761, %r1760, %r28, %r57;
	xor.b32  	%r1762, %r1759, %r1668;
	prmt.b32 	%r1763, %r1762, %r28, %r57;
	add.s32 	%r1764, %r1671, %r1761;
	add.s32 	%r1765, %r1672, %r1763;
	xor.b32  	%r1766, %r1764, %r1676;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1766, 20;
	shr.b32 	%rhs, %r1766, 12;
	add.u32 	%r1767, %lhs, %rhs;
	}
	xor.b32  	%r1768, %r1765, %r1711;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1768, 20;
	shr.b32 	%rhs, %r1768, 12;
	add.u32 	%r1769, %lhs, %rhs;
	}
	add.s32 	%r1771, %r1767, %r1754;
	add.s32 	%r1772, %r1771, %r1752;
	add.s32 	%r1774, %r1769, %r1755;
	add.s32 	%r1775, %r1774, %r1759;
	xor.b32  	%r1776, %r1772, %r1761;
	prmt.b32 	%r1777, %r1776, %r28, %r27;
	xor.b32  	%r1778, %r1775, %r1763;
	prmt.b32 	%r1779, %r1778, %r28, %r27;
	add.s32 	%r1780, %r1764, %r1777;
	add.s32 	%r1781, %r1765, %r1779;
	xor.b32  	%r1782, %r1780, %r1767;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1782, 25;
	shr.b32 	%rhs, %r1782, 7;
	add.u32 	%r1783, %lhs, %rhs;
	}
	xor.b32  	%r1784, %r1781, %r1769;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1784, 25;
	shr.b32 	%rhs, %r1784, 7;
	add.u32 	%r1785, %lhs, %rhs;
	}
	add.s32 	%r1787, %r1749, %r1756;
	add.s32 	%r1788, %r1787, %r1736;
	ld.const.v4.u32 	{%r1789, %r1790, %r1791, %r1792}, [c_xors+768];
	xor.b32  	%r1794, %r1789, %r2;
	add.s32 	%r1795, %r1794, %r1783;
	add.s32 	%r1796, %r1795, %r1739;
	xor.b32  	%r1797, %r1788, %r1779;
	prmt.b32 	%r1798, %r1797, %r28, %r57;
	xor.b32  	%r1799, %r1796, %r1741;
	prmt.b32 	%r1800, %r1799, %r28, %r57;
	add.s32 	%r1801, %r1780, %r1798;
	add.s32 	%r1802, %r1781, %r1800;
	xor.b32  	%r1803, %r1801, %r1749;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1803, 20;
	shr.b32 	%rhs, %r1803, 12;
	add.u32 	%r1804, %lhs, %rhs;
	}
	xor.b32  	%r1805, %r1802, %r1783;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1805, 20;
	shr.b32 	%rhs, %r1805, 12;
	add.u32 	%r1806, %lhs, %rhs;
	}
	add.s32 	%r1808, %r1804, %r1790;
	add.s32 	%r1809, %r1808, %r1788;
	add.s32 	%r1811, %r1806, %r1791;
	add.s32 	%r1812, %r1811, %r1796;
	xor.b32  	%r1813, %r1809, %r1798;
	prmt.b32 	%r1814, %r1813, %r28, %r27;
	xor.b32  	%r1815, %r1812, %r1800;
	prmt.b32 	%r1816, %r1815, %r28, %r27;
	add.s32 	%r1817, %r1801, %r1814;
	add.s32 	%r1818, %r1802, %r1816;
	xor.b32  	%r1819, %r1817, %r1804;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1819, 25;
	shr.b32 	%rhs, %r1819, 7;
	add.u32 	%r1820, %lhs, %rhs;
	}
	xor.b32  	%r1821, %r1818, %r1806;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1821, 25;
	shr.b32 	%rhs, %r1821, 7;
	add.u32 	%r1822, %lhs, %rhs;
	}
	add.s32 	%r1824, %r1785, %r1792;
	add.s32 	%r1825, %r1824, %r1772;
	ld.const.v4.u32 	{%r1826, %r1827, %r1828, %r1829}, [c_xors+784];
	add.s32 	%r1831, %r1747, %r1826;
	add.s32 	%r1832, %r1831, %r1775;
	xor.b32  	%r1833, %r1825, %r1743;
	prmt.b32 	%r1834, %r1833, %r28, %r57;
	xor.b32  	%r1835, %r1832, %r1777;
	prmt.b32 	%r1836, %r1835, %r28, %r57;
	add.s32 	%r1837, %r1744, %r1834;
	add.s32 	%r1838, %r1745, %r1836;
	xor.b32  	%r1839, %r1837, %r1785;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1839, 20;
	shr.b32 	%rhs, %r1839, 12;
	add.u32 	%r1840, %lhs, %rhs;
	}
	xor.b32  	%r1841, %r1838, %r1747;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1841, 20;
	shr.b32 	%rhs, %r1841, 12;
	add.u32 	%r1842, %lhs, %rhs;
	}
	add.s32 	%r1844, %r1840, %r1827;
	add.s32 	%r1845, %r1844, %r1825;
	add.s32 	%r1847, %r1842, %r1828;
	add.s32 	%r1848, %r1847, %r1832;
	xor.b32  	%r1849, %r1845, %r1834;
	prmt.b32 	%r1850, %r1849, %r28, %r27;
	xor.b32  	%r1851, %r1848, %r1836;
	prmt.b32 	%r1852, %r1851, %r28, %r27;
	add.s32 	%r1853, %r1837, %r1850;
	add.s32 	%r1854, %r1838, %r1852;
	xor.b32  	%r1855, %r1853, %r1840;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1855, 25;
	shr.b32 	%rhs, %r1855, 7;
	add.u32 	%r1856, %lhs, %rhs;
	}
	xor.b32  	%r1857, %r1854, %r1842;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1857, 25;
	shr.b32 	%rhs, %r1857, 7;
	add.u32 	%r1858, %lhs, %rhs;
	}
	add.s32 	%r1860, %r1809, %r1829;
	add.s32 	%r1861, %r1860, %r1858;
	ld.const.v4.u32 	{%r1862, %r1863, %r1864, %r1865}, [c_xors+800];
	xor.b32  	%r1867, %r1862, %r2;
	add.s32 	%r1868, %r1867, %r1820;
	add.s32 	%r1869, %r1868, %r1812;
	xor.b32  	%r1870, %r1861, %r1816;
	prmt.b32 	%r1871, %r1870, %r28, %r57;
	xor.b32  	%r1872, %r1869, %r1850;
	prmt.b32 	%r1873, %r1872, %r28, %r57;
	add.s32 	%r1874, %r1853, %r1871;
	add.s32 	%r1875, %r1854, %r1873;
	xor.b32  	%r1876, %r1874, %r1858;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1876, 20;
	shr.b32 	%rhs, %r1876, 12;
	add.u32 	%r1877, %lhs, %rhs;
	}
	xor.b32  	%r1878, %r1875, %r1820;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1878, 20;
	shr.b32 	%rhs, %r1878, 12;
	add.u32 	%r1879, %lhs, %rhs;
	}
	add.s32 	%r1881, %r1877, %r1863;
	add.s32 	%r1882, %r1881, %r1861;
	add.s32 	%r1884, %r1879, %r1864;
	add.s32 	%r1885, %r1884, %r1869;
	xor.b32  	%r1886, %r1882, %r1871;
	prmt.b32 	%r1887, %r1886, %r28, %r27;
	xor.b32  	%r1888, %r1885, %r1873;
	prmt.b32 	%r1889, %r1888, %r28, %r27;
	add.s32 	%r1890, %r1874, %r1887;
	add.s32 	%r1891, %r1875, %r1889;
	xor.b32  	%r1892, %r1891, %r1879;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1892, 25;
	shr.b32 	%rhs, %r1892, 7;
	add.u32 	%r1893, %lhs, %rhs;
	}
	add.s32 	%r1895, %r1822, %r1865;
	add.s32 	%r1896, %r1895, %r1845;
	ld.const.v4.u32 	{%r1897, %r1898, %r1899, %r1900}, [c_xors+816];
	add.s32 	%r1902, %r1856, %r1897;
	add.s32 	%r1903, %r1902, %r1848;
	xor.b32  	%r1904, %r1896, %r1852;
	prmt.b32 	%r1905, %r1904, %r28, %r57;
	xor.b32  	%r1906, %r1903, %r1814;
	prmt.b32 	%r1907, %r1906, %r28, %r57;
	add.s32 	%r1908, %r1817, %r1905;
	add.s32 	%r1909, %r1818, %r1907;
	xor.b32  	%r1910, %r1908, %r1822;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1910, 20;
	shr.b32 	%rhs, %r1910, 12;
	add.u32 	%r1911, %lhs, %rhs;
	}
	xor.b32  	%r1912, %r1909, %r1856;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1912, 20;
	shr.b32 	%rhs, %r1912, 12;
	add.u32 	%r1913, %lhs, %rhs;
	}
	add.s32 	%r1915, %r1911, %r1898;
	add.s32 	%r1916, %r1915, %r1896;
	add.s32 	%r1918, %r1913, %r1899;
	add.s32 	%r1919, %r1918, %r1903;
	xor.b32  	%r1920, %r1916, %r1905;
	prmt.b32 	%r1921, %r1920, %r28, %r27;
	xor.b32  	%r1922, %r1919, %r1907;
	prmt.b32 	%r1923, %r1922, %r28, %r27;
	add.s32 	%r1924, %r1908, %r1921;
	add.s32 	%r1925, %r1909, %r1923;
	xor.b32  	%r1926, %r1925, %r1913;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1926, 25;
	shr.b32 	%rhs, %r1926, 7;
	add.u32 	%r1927, %lhs, %rhs;
	}
	add.s32 	%r1929, %r1893, %r1900;
	add.s32 	%r1930, %r1929, %r1882;
	xor.b32  	%r1931, %r1930, %r1923;
	prmt.b32 	%r1932, %r1931, %r28, %r57;
	add.s32 	%r1933, %r1924, %r1932;
	xor.b32  	%r1934, %r1933, %r1893;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1934, 20;
	shr.b32 	%rhs, %r1934, 12;
	add.u32 	%r1935, %lhs, %rhs;
	}
	ld.const.u32 	%r1936, [c_xors+836];
	add.s32 	%r1937, %r1935, %r1936;
	add.s32 	%r1938, %r1937, %r1930;
	xor.b32  	%r1939, %r1938, %r1932;
	prmt.b32 	%r1940, %r1939, %r28, %r27;
	ld.const.u32 	%r1941, [c_xors+844];
	add.s32 	%r1942, %r1927, %r1941;
	add.s32 	%r1943, %r1942, %r1916;
	xor.b32  	%r1944, %r1889, %r1943;
	prmt.b32 	%r1945, %r1944, %r28, %r57;
	add.s32 	%r1946, %r1890, %r1945;
	xor.b32  	%r1947, %r1927, %r1946;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1947, 20;
	shr.b32 	%rhs, %r1947, 12;
	add.u32 	%r1948, %lhs, %rhs;
	}
	ld.const.u32 	%r1949, [c_xors+848];
	add.s32 	%r1950, %r1943, %r1949;
	add.s32 	%r1951, %r1950, %r1948;
	xor.b32  	%r1952, %r1951, %r1945;
	prmt.b32 	%r1953, %r1952, %r28, %r27;
	add.s32 	%r1954, %r1946, %r1953;
	xor.b32  	%r1955, %r1948, %r1954;
	{
	.reg .b32 %lhs;
	.reg .b32 %rhs;
	shl.b32 	%lhs, %r1955, 25;
	shr.b32 	%rhs, %r1955, 7;
	add.u32 	%r1956, %lhs, %rhs;
	}
	ld.const.u32 	%r1957, [c_h+4];
	xor.b32  	%r1958, %r1940, %r1957;
	setp.ne.s32	%p2, %r1958, %r1956;
	@%p2 bra 	BB0_3;

	ld.param.u64 	%rd5, [decred_gpu_hash_nonce_param_2];
	cvta.to.global.u64 	%rd2, %rd5;
	atom.global.inc.u32 	%r1959, [%rd2], -1;
	add.s32 	%r1960, %r1959, 1;
	mul.wide.u32 	%rd3, %r1960, 4;
	add.s64 	%rd4, %rd2, %rd3;
	st.global.u32 	[%rd4], %r2;

BB0_3:
	ret;
}


